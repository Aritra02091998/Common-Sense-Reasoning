{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b35b92",
   "metadata": {},
   "source": [
    "###### -----------------START--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e4e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b320d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1bf8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd56a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c5e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = '/home/aritra/cric/train_questions.json'\n",
    "val_file_path = '/home/aritra/cric/val_questions.json'\n",
    "test_file_path = '/home/aritra/cric/test_v1_questions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236c7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "\n",
    "with open(train_file_path, \"r\") as file:\n",
    "     train_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2e0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "\n",
    "with open(val_file_path, \"r\") as file:\n",
    "     val_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e00100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "\n",
    "with open(test_file_path, \"r\") as file:\n",
    "     test_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48972cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15c9341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa20f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fab983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which brown animal walking in the field could be used for transporting people'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa56b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b16491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is there an object that is a type of public transports'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5dfd026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can the ceramic bird spread wings'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7e75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8190c199",
   "metadata": {},
   "source": [
    "### ------------------------------Extracting Data of Training Set-------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ae6c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList = []\n",
    "answerList = []\n",
    "imgList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cdf3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[2]['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0248032",
   "metadata": {},
   "source": [
    "#### iter 1: from 0 , 149000 -> error1.txt -> 159\n",
    "#### iter 2: from 150000 , 240000 -> error2.txt -> 34\n",
    "#### iter 3: from 240000 , 365235 ->error3.txt -> 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b63642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying\n",
    "indexToExclude = []\n",
    "\n",
    "with open('error1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)\n",
    "        \n",
    "with open('error2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)\n",
    "        \n",
    "with open('error3.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d4ed441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexToExclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c8a79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 365235/365235 [00:01<00:00, 319729.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_json))):\n",
    "    \n",
    "    if i in indexToExclude:\n",
    "        continue\n",
    "        \n",
    "    pointer = train_json[i]\n",
    "    \n",
    "    questionList.append(pointer['question'])\n",
    "    answerList.append(pointer['answer'])\n",
    "    imgList.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5bc92f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364921, 364921, 364921)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questionList), len(answerList), len(imgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf2a90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(answerList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6261",
   "metadata": {},
   "source": [
    "### ---------------------------------------Map Creation--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3638995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findUnique(targetList):\n",
    "    \n",
    "    uniqueList = []\n",
    "    \n",
    "    for word in targetList:\n",
    "        if word not in uniqueList:\n",
    "            uniqueList.append(word)\n",
    "    \n",
    "    return uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05afbb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(findUnique(answerList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b38e9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word to number mapping\n",
    "\n",
    "mapping = {}\n",
    "counter = 0\n",
    "\n",
    "uniqueAnsList = findUnique(answerList)\n",
    "\n",
    "for word in uniqueAnsList:\n",
    "    \n",
    "    if word not in mapping:\n",
    "        \n",
    "        mapping[word] = counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00bfa346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'small', 'picture', 'table', 'bookshelf']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueAnsList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "143b6127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfClasses = max(mapping.values())\n",
    "numOfClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815b20fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4811265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating number to word mapping\n",
    "\n",
    "reverse_mapping = dict([(value, key) for key, value in mapping.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8749a",
   "metadata": {},
   "source": [
    "### --------------------------------------Processing of Training Set--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23e781d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for i in range(len(answerList)):\n",
    "    labels.append( mapping[ answerList[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f9d1248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364921"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c03fdb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 364921/364921 [00:03<00:00, 91805.66it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in tqdm(range(len(answerList))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList[i]] ] = 1\n",
    "    \n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bab7b57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364921"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65951dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 364921/364921 [00:00<00:00, 767628.01it/s]\n"
     ]
    }
   ],
   "source": [
    "imgPathList = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList))):\n",
    "    \n",
    "    imgName = str(imgList[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b75bbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import datasets\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0afea404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1000.jpg',\n",
       " '/home/aritra/cric/images/img/1005.jpg',\n",
       " '/home/aritra/cric/images/img/1005.jpg',\n",
       " '/home/aritra/cric/images/img/1005.jpg',\n",
       " '/home/aritra/cric/images/img/1008.jpg']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "158e26b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364921"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgPathList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65956469",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDictionary = {'questions':questionList, 'labels': labels, 'scores': scores, 'images':imgPathList}\n",
    "modified_train_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe569437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath to images in the directory\n",
    "\n",
    "modified_train_set = modified_train_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01a43c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'labels', 'scores', 'images'],\n",
       "    num_rows: 364921\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b28f14",
   "metadata": {},
   "source": [
    "## -----------------------------------Extracting Validation Set---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acc81bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_val = []\n",
    "answerList_val = []\n",
    "imgList_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce77628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting the index containing errorneous images\n",
    "\n",
    "indexToExcludeVal = []\n",
    "with open('error_validation.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeVal.append(number)\n",
    "\n",
    "with open('error_validation2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())  # Convert the read line to an integer\n",
    "        indexToExcludeVal.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08e36650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 43112/43112 [00:02<00:00, 16205.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# excluding the index containing errorneous images\n",
    "\n",
    "for i in tqdm(range(len(val_json))):\n",
    "    \n",
    "    if (i in indexToExcludeVal):\n",
    "        continue\n",
    "        \n",
    "    pointer = val_json[i]\n",
    "    \n",
    "    questionList_val.append(pointer['question'])\n",
    "    answerList_val.append(pointer['answer'])\n",
    "    imgList_val.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f547b",
   "metadata": {},
   "source": [
    "43112 -> 43068 -> 33175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77490cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33175, 33175, 33175)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questionList_val), len(answerList_val), len(imgList_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e215d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueAnswerListVal = list(set(answerList_val))\n",
    "len(uniqueAnswerListVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2927cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_val)):\n",
    "    \n",
    "    word = answerList_val[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdfb2dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33175"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff358202",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------Processing Validation Set-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23e8a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = []\n",
    "\n",
    "for i in range(len(answerList_val)):\n",
    "    labels_val.append( mapping[ answerList_val[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0da89dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33175"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "008b0916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 33175/33175 [00:00<00:00, 92510.18it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_val = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_val))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_val[i]] ] = 1\n",
    "    \n",
    "    scores_val.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "def663bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33175"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b18cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 33175/33175 [00:00<00:00, 762001.44it/s]\n"
     ]
    }
   ],
   "source": [
    "imgPathList_val = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_val))):\n",
    "    \n",
    "    imgName = str(imgList_val[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_val.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae9e0ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1003.jpg',\n",
       " '/home/aritra/cric/images/img/1003.jpg',\n",
       " '/home/aritra/cric/images/img/1018.jpg',\n",
       " '/home/aritra/cric/images/img/1018.jpg',\n",
       " '/home/aritra/cric/images/img/1027.jpg']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList_val[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6dc43b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of Val_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_val, 'labels':labels_val, 'scores':scores_val, 'images':imgPathList_val}\n",
    "modified_val_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0596e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of Val Set to images in the directory\n",
    "\n",
    "modified_val_set = modified_val_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afaee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66774985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02470fa5",
   "metadata": {},
   "source": [
    "### -------------------------------------------Extracting Color Questions Set-------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e6ecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color questions of the train set is stored in this file.\n",
    "# objective is to train a fresh model on only color based questions\n",
    "\n",
    "indices = []\n",
    "with open('./text_files/color_questions_indices_train_set.txt', 'r') as file:\n",
    "    for number in file:\n",
    "        number = int(number.strip())\n",
    "        indices.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f59d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 16, 29, 32]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5be6b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_color = []\n",
    "answerList_color = []\n",
    "imgList_color = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db25419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the predefined list of color indices of the train set here the questions,answer,img is being copied \n",
    "\n",
    "for i in indices:\n",
    "                \n",
    "    questionList_color.append( questionList[i] )\n",
    "    answerList_color.append( answerList[i] )\n",
    "    imgList_color.append( imgList[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e47d4607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['which green thing near the green house could be opened or closed',\n",
       " 'what type of object is on back of the tan object that I can use for sitting on',\n",
       " 'can the black electronic device that is wearing the hand control small electrical appliance',\n",
       " 'which color is the object that is on back of the seat and is a type of electronic device',\n",
       " 'is there a yellow vehicle that can travel on road']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionList_color[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eeaace19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149163, 149163, 149163)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questionList_color), len(answerList_color), len(imgList_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "198eac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1065"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueAnswerListColor = list(set(answerList_color))\n",
    "len(uniqueAnswerListColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aaf9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_color)):\n",
    "    \n",
    "    word = answerList_color[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "440bab36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149163"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac129630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing of color set\n",
    "\n",
    "labels_color = []\n",
    "\n",
    "for i in range(len(answerList_color)):\n",
    "    labels_color.append( mapping[ answerList_color[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32ffe2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149163"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c360089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 149163/149163 [00:01<00:00, 90223.22it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_color = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_color))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_color[i]] ] = 1\n",
    "    \n",
    "    scores_color.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a8ca55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149163"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88facc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 149163/149163 [00:00<00:00, 769226.47it/s]\n"
     ]
    }
   ],
   "source": [
    "imgPathList_color = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_color))):\n",
    "    \n",
    "    imgName = str(imgList_color[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_color.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc839cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149163"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgPathList_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "831ee0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1003.jpg',\n",
       " '/home/aritra/cric/images/img/1003.jpg',\n",
       " '/home/aritra/cric/images/img/1018.jpg',\n",
       " '/home/aritra/cric/images/img/1018.jpg',\n",
       " '/home/aritra/cric/images/img/1027.jpg']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList_val[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d99e7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of Val_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_color, 'labels':labels_color, 'scores':scores_color, 'images':imgPathList_color}\n",
    "train_color_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1664fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of Val Set to images in the directory\n",
    "\n",
    "train_color_set = train_color_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16aecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a75d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e854bad",
   "metadata": {},
   "source": [
    "### -------------------------------------------Extracting Test Set-------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61abaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_test = []\n",
    "answerList_test = []\n",
    "imgList_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0c136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToExcludeTest = []\n",
    "\n",
    "with open('error_testSet1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeTest.append(number)\n",
    "        \n",
    "with open('errorTestSet2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeTest.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "171595e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14150"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexToExcludeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7964cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 86003/86003 [00:07<00:00, 11041.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_json))):\n",
    "    \n",
    "    if i in indexToExcludeTest:\n",
    "        continue\n",
    "        \n",
    "    pointer = test_json[i]\n",
    "    \n",
    "    questionList_test.append(pointer['question'])\n",
    "    answerList_test.append(pointer['answer'])\n",
    "    imgList_test.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2107405",
   "metadata": {},
   "source": [
    "86003 -> 71863"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4885eea",
   "metadata": {},
   "source": [
    "### -------------------------------------- Processing Test Set ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd02d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_test)):\n",
    "    \n",
    "    word = answerList_test[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5c6bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20bca53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "\n",
    "for i in range(len(answerList_test)):\n",
    "    labels_test.append( mapping[ answerList_test[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c325e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a603312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 71863/71863 [00:00<00:00, 90940.69it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_test = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_test))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_test[i]] ] = 1\n",
    "    \n",
    "    scores_test.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa0bce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b3ef009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 71863/71863 [00:00<00:00, 774324.92it/s]\n"
     ]
    }
   ],
   "source": [
    "imgPathList_test = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_test))):\n",
    "    \n",
    "    imgName = str(imgList_test[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_test.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "450290c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgPathList_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ac7c315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cac47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of test_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_test, 'labels':labels_test, 'scores':scores_test, 'images':imgPathList_test}\n",
    "modified_test_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a74c0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of test Set to images in the directory\n",
    "\n",
    "modified_test_set = modified_test_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607636d1",
   "metadata": {},
   "source": [
    "### -------------------------------End of Processing----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e4eb76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor, ViltForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a8d574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltConfig\n",
    "config = ViltConfig.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0441da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f0e3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "276bc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViltForQuestionAnswering.from_pretrained(\"model_chkpts/vilt-mlm-classification-model/vilt_mlm_mod_e4_cric_trained/\", id2label = reverse_mapping, label2id = mapping).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dfafe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "303430b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cric_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, processor):\n",
    "        self.processor = processor\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        #print(idx)\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        #print(item)\n",
    "        \n",
    "        encodings = self.processor(images = item[\"images\"], text = item[\"questions\"], padding=\"max_length\", truncation=True, return_tensors = \"pt\")\n",
    "        encodings = {k:v.squeeze() for k,v in encodings.items()}\n",
    "                                \n",
    "        encodings['labels'] = torch.tensor(item['scores'], dtype = torch.float32)\n",
    "        \n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa27f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_object = cric_dataset(modified_train_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5fd2761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_object = cric_dataset(modified_val_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a27f70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_object = cric_dataset(modified_test_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e5a2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dataset_object = cric_dataset(train_color_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b548a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  \n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    pixel_values = [item['pixel_values'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "        \n",
    "    # create padded pixel values and corresponding pixel mask\n",
    "    \n",
    "    encoding = processor.image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "    # create new batch\n",
    "    \n",
    "    batch = {}\n",
    "    \n",
    "    batch['input_ids'] = torch.stack(input_ids)\n",
    "    batch['attention_mask'] = torch.stack(attention_mask)\n",
    "    batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "    batch['pixel_values'] = encoding['pixel_values']\n",
    "    batch['pixel_mask'] = encoding['pixel_mask']\n",
    "    batch['labels'] = torch.stack(labels, dim = 0 )\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fec6556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(color_dataset_object, collate_fn = collate_fn, shuffle = True, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed4ff26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "925fb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([32, 40])\n",
      "\n",
      "attention_mask torch.Size([32, 40])\n",
      "\n",
      "token_type_ids torch.Size([32, 40])\n",
      "\n",
      "pixel_values torch.Size([32, 3, 608, 608])\n",
      "\n",
      "pixel_mask torch.Size([32, 608, 608])\n",
      "\n",
      "labels torch.Size([32, 1442])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in batch.items():\n",
    "    print(k, v.shape)\n",
    "    print()\n",
    "    \n",
    "#print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "34bf59a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4662"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_number_of_steps = len(train_dataloader)\n",
    "tot_number_of_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ec481fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp16 precision\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d848387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Visualisation for this Test Notebook\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fb8f5",
   "metadata": {},
   "source": [
    "## Model Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99dcaabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aritra/miniconda3/envs/blip_vqa_base_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> Loss: 0.5371490716934204\n",
      "1 -> Loss: 0.23276397585868835\n",
      "2 -> Loss: 0.35655367374420166\n",
      "3 -> Loss: 0.49922704696655273\n",
      "4 -> Loss: 0.6733691692352295\n",
      "5 -> Loss: 0.5433361530303955\n",
      "6 -> Loss: 1.0520079135894775\n",
      "7 -> Loss: 0.4814547300338745\n",
      "8 -> Loss: 0.4572630524635315\n",
      "9 -> Loss: 0.3161604404449463\n",
      "10 -> Loss: 0.5157613754272461\n",
      "11 -> Loss: 0.5291028618812561\n",
      "12 -> Loss: 0.4964756965637207\n",
      "13 -> Loss: 0.5185451507568359\n",
      "14 -> Loss: 0.04080929234623909\n",
      "15 -> Loss: 0.5630484819412231\n",
      "16 -> Loss: 0.32479608058929443\n",
      "17 -> Loss: 0.6960514783859253\n",
      "18 -> Loss: 0.7995201349258423\n",
      "19 -> Loss: 0.44206932187080383\n",
      "20 -> Loss: 0.3656335175037384\n",
      "21 -> Loss: 0.4552389681339264\n",
      "22 -> Loss: 0.2756907045841217\n",
      "23 -> Loss: 0.42417505383491516\n",
      "24 -> Loss: 0.8510345816612244\n",
      "25 -> Loss: 0.26363715529441833\n",
      "26 -> Loss: 0.4432034194469452\n",
      "27 -> Loss: 0.705394446849823\n",
      "28 -> Loss: 0.5126279592514038\n",
      "29 -> Loss: 0.7259231805801392\n",
      "30 -> Loss: 0.4939831495285034\n",
      "31 -> Loss: 0.7674992680549622\n",
      "32 -> Loss: 0.9951698184013367\n",
      "33 -> Loss: 0.5446061491966248\n",
      "34 -> Loss: 0.4161984920501709\n",
      "35 -> Loss: 0.835091233253479\n",
      "36 -> Loss: 1.2143913507461548\n",
      "37 -> Loss: 0.6682695150375366\n",
      "38 -> Loss: 0.4717005789279938\n",
      "39 -> Loss: 0.5548806190490723\n",
      "40 -> Loss: 0.3425726294517517\n",
      "41 -> Loss: 0.5438669323921204\n",
      "42 -> Loss: 0.4631010591983795\n",
      "43 -> Loss: 0.38561904430389404\n",
      "44 -> Loss: 0.39621400833129883\n",
      "45 -> Loss: 0.4707508981227875\n",
      "46 -> Loss: 0.5206893086433411\n",
      "47 -> Loss: 0.4847804307937622\n",
      "48 -> Loss: 0.4055193364620209\n",
      "49 -> Loss: 0.38933131098747253\n",
      "50 -> Loss: 0.6484901905059814\n",
      "51 -> Loss: 0.9977962374687195\n",
      "52 -> Loss: 0.21049350500106812\n",
      "53 -> Loss: 0.5113383531570435\n",
      "54 -> Loss: 0.4260404109954834\n",
      "55 -> Loss: 0.6645930409431458\n",
      "56 -> Loss: 0.3740578293800354\n",
      "57 -> Loss: 0.2733341157436371\n",
      "58 -> Loss: 1.0385112762451172\n",
      "59 -> Loss: 0.2449331432580948\n",
      "60 -> Loss: 0.65546053647995\n",
      "61 -> Loss: 0.7358627319335938\n",
      "62 -> Loss: 0.14947399497032166\n",
      "63 -> Loss: 0.4813939929008484\n",
      "64 -> Loss: 0.9518936276435852\n",
      "65 -> Loss: 0.6971006989479065\n",
      "66 -> Loss: 0.39738863706588745\n",
      "67 -> Loss: 0.6555653810501099\n",
      "68 -> Loss: 0.2698460817337036\n",
      "69 -> Loss: 0.30206912755966187\n",
      "70 -> Loss: 0.6210123300552368\n",
      "71 -> Loss: 0.853202223777771\n",
      "72 -> Loss: 0.5816762447357178\n",
      "73 -> Loss: 0.9096732139587402\n",
      "74 -> Loss: 0.22035075724124908\n",
      "75 -> Loss: 0.457903116941452\n",
      "76 -> Loss: 0.32809221744537354\n",
      "77 -> Loss: 0.44138914346694946\n",
      "78 -> Loss: 0.4183560907840729\n",
      "79 -> Loss: 0.2426428347826004\n",
      "80 -> Loss: 0.7228618264198303\n",
      "81 -> Loss: 0.40360578894615173\n",
      "82 -> Loss: 0.5538272857666016\n",
      "83 -> Loss: 0.461961567401886\n",
      "84 -> Loss: 0.4665950834751129\n",
      "85 -> Loss: 0.3847440481185913\n",
      "86 -> Loss: 0.2192910760641098\n",
      "87 -> Loss: 0.2783726751804352\n",
      "88 -> Loss: 0.400838166475296\n",
      "89 -> Loss: 0.579255223274231\n",
      "90 -> Loss: 0.23017093539237976\n",
      "91 -> Loss: 0.18415530025959015\n",
      "92 -> Loss: 0.3218159079551697\n",
      "93 -> Loss: 0.6913970708847046\n",
      "94 -> Loss: 0.4274798631668091\n",
      "95 -> Loss: 0.4038877487182617\n",
      "96 -> Loss: 0.46588557958602905\n",
      "97 -> Loss: 0.8047740459442139\n",
      "98 -> Loss: 0.633625864982605\n",
      "99 -> Loss: 0.4373573660850525\n",
      "100 -> Loss: 0.48408907651901245\n",
      "101 -> Loss: 0.43086859583854675\n",
      "102 -> Loss: 0.6502535939216614\n",
      "103 -> Loss: 1.0890426635742188\n",
      "104 -> Loss: 0.19032740592956543\n",
      "105 -> Loss: 0.34499284625053406\n",
      "106 -> Loss: 0.2578004002571106\n",
      "107 -> Loss: 0.5174411535263062\n",
      "108 -> Loss: 0.658067524433136\n",
      "109 -> Loss: 0.36437687277793884\n",
      "110 -> Loss: 0.8164752721786499\n",
      "111 -> Loss: 0.40499377250671387\n",
      "112 -> Loss: 0.4684019684791565\n",
      "113 -> Loss: 0.4061019718647003\n",
      "114 -> Loss: 0.3835587203502655\n",
      "115 -> Loss: 0.26678237318992615\n",
      "116 -> Loss: 1.0260200500488281\n",
      "117 -> Loss: 0.7696152925491333\n",
      "118 -> Loss: 0.49331486225128174\n",
      "119 -> Loss: 0.378465861082077\n",
      "120 -> Loss: 0.5594384670257568\n",
      "121 -> Loss: 0.6201089024543762\n",
      "122 -> Loss: 0.2851009666919708\n",
      "123 -> Loss: 0.24433977901935577\n",
      "124 -> Loss: 0.49604350328445435\n",
      "125 -> Loss: 0.4205467104911804\n",
      "126 -> Loss: 0.7814015746116638\n",
      "127 -> Loss: 0.44444361329078674\n",
      "128 -> Loss: 0.39529457688331604\n",
      "129 -> Loss: 0.3398419916629791\n",
      "130 -> Loss: 0.3686875104904175\n",
      "131 -> Loss: 0.8614169955253601\n",
      "132 -> Loss: 0.72547447681427\n",
      "133 -> Loss: 0.3198980689048767\n",
      "134 -> Loss: 0.47020095586776733\n",
      "135 -> Loss: 1.0117042064666748\n",
      "136 -> Loss: 0.47150492668151855\n",
      "137 -> Loss: 0.3527946472167969\n",
      "138 -> Loss: 0.09923629462718964\n",
      "139 -> Loss: 0.7308397889137268\n",
      "140 -> Loss: 0.2572591006755829\n",
      "141 -> Loss: 0.409254252910614\n",
      "142 -> Loss: 0.6058268547058105\n",
      "143 -> Loss: 0.7026156783103943\n",
      "144 -> Loss: 1.013178825378418\n",
      "145 -> Loss: 0.618585467338562\n",
      "146 -> Loss: 0.48025503754615784\n",
      "147 -> Loss: 0.31725940108299255\n",
      "148 -> Loss: 0.6767138242721558\n",
      "149 -> Loss: 0.6390747427940369\n",
      "150 -> Loss: 0.32048502564430237\n",
      "151 -> Loss: 0.6346649527549744\n",
      "152 -> Loss: 0.22801491618156433\n",
      "153 -> Loss: 0.43105968832969666\n",
      "154 -> Loss: 0.4482389986515045\n",
      "155 -> Loss: 0.5750997066497803\n",
      "156 -> Loss: 0.4979948401451111\n",
      "157 -> Loss: 0.5745258331298828\n",
      "158 -> Loss: 0.2226283699274063\n",
      "159 -> Loss: 1.105872631072998\n",
      "160 -> Loss: 0.567509114742279\n",
      "161 -> Loss: 0.3940986692905426\n",
      "162 -> Loss: 0.3229440748691559\n",
      "163 -> Loss: 0.6433433294296265\n",
      "164 -> Loss: 0.28888458013534546\n",
      "165 -> Loss: 0.6166406869888306\n",
      "166 -> Loss: 0.5045621395111084\n",
      "167 -> Loss: 0.34423649311065674\n",
      "168 -> Loss: 0.4500112235546112\n",
      "169 -> Loss: 0.7005327343940735\n",
      "170 -> Loss: 0.26985880732536316\n",
      "171 -> Loss: 0.2981858253479004\n",
      "172 -> Loss: 0.3722977638244629\n",
      "173 -> Loss: 0.6266137361526489\n",
      "174 -> Loss: 0.3236926198005676\n",
      "175 -> Loss: 0.8300292491912842\n",
      "176 -> Loss: 0.7333130836486816\n",
      "177 -> Loss: 0.842909574508667\n",
      "178 -> Loss: 0.8805279731750488\n",
      "179 -> Loss: 1.007501482963562\n",
      "180 -> Loss: 0.23778316378593445\n",
      "181 -> Loss: 0.5139724016189575\n",
      "182 -> Loss: 0.31815189123153687\n",
      "183 -> Loss: 0.7382231950759888\n",
      "184 -> Loss: 0.6537735462188721\n",
      "185 -> Loss: 0.21333450078964233\n",
      "186 -> Loss: 0.33748048543930054\n",
      "187 -> Loss: 0.34066659212112427\n",
      "188 -> Loss: 0.2101186215877533\n",
      "189 -> Loss: 0.1305295079946518\n",
      "190 -> Loss: 0.23144817352294922\n",
      "191 -> Loss: 0.1918090581893921\n",
      "192 -> Loss: 0.5917384624481201\n",
      "193 -> Loss: 0.7260874509811401\n",
      "194 -> Loss: 0.5982177257537842\n",
      "195 -> Loss: 0.40490028262138367\n",
      "196 -> Loss: 0.853350043296814\n",
      "197 -> Loss: 0.8639983534812927\n",
      "198 -> Loss: 0.20297834277153015\n",
      "199 -> Loss: 0.08994358032941818\n",
      "200 -> Loss: 0.6158568859100342\n",
      "201 -> Loss: 1.2552220821380615\n",
      "202 -> Loss: 0.24235890805721283\n",
      "203 -> Loss: 0.4861045181751251\n",
      "204 -> Loss: 0.5014339089393616\n",
      "205 -> Loss: 0.47589612007141113\n",
      "206 -> Loss: 0.5899432897567749\n",
      "207 -> Loss: 0.42131033539772034\n",
      "208 -> Loss: 0.8785918354988098\n",
      "209 -> Loss: 0.32801342010498047\n",
      "210 -> Loss: 0.44616180658340454\n",
      "211 -> Loss: 0.3699450194835663\n",
      "212 -> Loss: 0.7681435346603394\n",
      "213 -> Loss: 0.34860289096832275\n",
      "214 -> Loss: 0.3266889452934265\n",
      "215 -> Loss: 0.7127926349639893\n",
      "216 -> Loss: 0.26395851373672485\n",
      "217 -> Loss: 0.7098305821418762\n",
      "218 -> Loss: 0.5106788873672485\n",
      "219 -> Loss: 0.4559529721736908\n",
      "220 -> Loss: 1.0345271825790405\n",
      "221 -> Loss: 0.3506324887275696\n",
      "222 -> Loss: 0.9260346293449402\n",
      "223 -> Loss: 0.31204766035079956\n",
      "224 -> Loss: 0.4105999171733856\n",
      "225 -> Loss: 0.4350138008594513\n",
      "226 -> Loss: 0.42276254296302795\n",
      "227 -> Loss: 0.8636422157287598\n",
      "228 -> Loss: 0.40508168935775757\n",
      "229 -> Loss: 0.8640913367271423\n",
      "230 -> Loss: 0.29330533742904663\n",
      "231 -> Loss: 0.4780297577381134\n",
      "232 -> Loss: 0.501456618309021\n",
      "233 -> Loss: 0.395206481218338\n",
      "234 -> Loss: 0.782745361328125\n",
      "235 -> Loss: 0.5024464130401611\n",
      "236 -> Loss: 0.5127267241477966\n",
      "237 -> Loss: 0.4048084020614624\n",
      "238 -> Loss: 0.48063912987709045\n",
      "239 -> Loss: 0.230237677693367\n",
      "240 -> Loss: 0.36311066150665283\n",
      "241 -> Loss: 0.39285197854042053\n",
      "242 -> Loss: 0.6970760226249695\n",
      "243 -> Loss: 0.6141595840454102\n",
      "244 -> Loss: 1.0085221529006958\n",
      "245 -> Loss: 0.5721990466117859\n",
      "246 -> Loss: 0.5707958936691284\n",
      "247 -> Loss: 1.0099656581878662\n",
      "248 -> Loss: 0.45727312564849854\n",
      "249 -> Loss: 0.4957844913005829\n",
      "250 -> Loss: 0.4703288674354553\n",
      "251 -> Loss: 0.6729117631912231\n",
      "252 -> Loss: 0.7247945070266724\n",
      "253 -> Loss: 0.844204843044281\n",
      "254 -> Loss: 0.6676031351089478\n",
      "255 -> Loss: 0.4640785753726959\n",
      "256 -> Loss: 0.48542848229408264\n",
      "257 -> Loss: 0.758072555065155\n",
      "258 -> Loss: 0.6361615061759949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 -> Loss: 0.27108097076416016\n",
      "260 -> Loss: 0.527826189994812\n",
      "261 -> Loss: 0.5838673710823059\n",
      "262 -> Loss: 0.7018933296203613\n",
      "263 -> Loss: 0.14541533589363098\n",
      "264 -> Loss: 0.45691418647766113\n",
      "265 -> Loss: 0.4368586540222168\n",
      "266 -> Loss: 0.13244548439979553\n",
      "267 -> Loss: 0.2880104184150696\n",
      "268 -> Loss: 0.4282197952270508\n",
      "269 -> Loss: 0.21098196506500244\n",
      "270 -> Loss: 0.2622842490673065\n",
      "271 -> Loss: 0.7317684292793274\n",
      "272 -> Loss: 0.40075239539146423\n",
      "273 -> Loss: 0.8611503839492798\n",
      "274 -> Loss: 0.29605022072792053\n",
      "275 -> Loss: 0.21642595529556274\n",
      "276 -> Loss: 0.6913865804672241\n",
      "277 -> Loss: 0.4979076683521271\n",
      "278 -> Loss: 0.3675096333026886\n",
      "279 -> Loss: 0.9330558180809021\n",
      "280 -> Loss: 0.3321142792701721\n",
      "281 -> Loss: 0.44862326979637146\n",
      "282 -> Loss: 0.4151404798030853\n",
      "283 -> Loss: 0.36282452940940857\n",
      "284 -> Loss: 0.4901552200317383\n",
      "285 -> Loss: 0.06830372661352158\n",
      "286 -> Loss: 0.7116612195968628\n",
      "287 -> Loss: 0.8327693343162537\n",
      "288 -> Loss: 0.7594789266586304\n",
      "289 -> Loss: 0.5747017860412598\n",
      "290 -> Loss: 0.32665491104125977\n",
      "291 -> Loss: 0.7719380855560303\n",
      "292 -> Loss: 0.4951627254486084\n",
      "293 -> Loss: 0.4483620524406433\n",
      "294 -> Loss: 0.6000255346298218\n",
      "295 -> Loss: 0.39745524525642395\n",
      "296 -> Loss: 0.850587785243988\n",
      "297 -> Loss: 0.3427360951900482\n",
      "298 -> Loss: 0.22988319396972656\n",
      "299 -> Loss: 0.494646817445755\n",
      "300 -> Loss: 0.5913181304931641\n",
      "301 -> Loss: 0.6226724982261658\n",
      "302 -> Loss: 1.0260438919067383\n",
      "303 -> Loss: 0.7555316090583801\n",
      "304 -> Loss: 0.5625909566879272\n",
      "305 -> Loss: 0.9766960144042969\n",
      "306 -> Loss: 0.3624562621116638\n",
      "307 -> Loss: 0.5315830707550049\n",
      "308 -> Loss: 0.32125046849250793\n",
      "309 -> Loss: 0.39668601751327515\n",
      "310 -> Loss: 0.5496343374252319\n",
      "311 -> Loss: 0.42210763692855835\n",
      "312 -> Loss: 0.3730160892009735\n",
      "313 -> Loss: 0.6303834319114685\n",
      "314 -> Loss: 0.6895446181297302\n",
      "315 -> Loss: 0.3446522057056427\n",
      "316 -> Loss: 0.9281936883926392\n",
      "317 -> Loss: 0.10493652522563934\n",
      "318 -> Loss: 0.783888578414917\n",
      "319 -> Loss: 0.5370209217071533\n",
      "320 -> Loss: 0.24684183299541473\n",
      "321 -> Loss: 0.6513463258743286\n",
      "322 -> Loss: 0.5565842390060425\n",
      "323 -> Loss: 0.5642157793045044\n",
      "324 -> Loss: 0.8656129240989685\n",
      "325 -> Loss: 0.3834877014160156\n",
      "326 -> Loss: 0.6407296657562256\n",
      "327 -> Loss: 0.825232744216919\n",
      "328 -> Loss: 0.4240403175354004\n",
      "329 -> Loss: 0.2981058955192566\n",
      "330 -> Loss: 0.8114295601844788\n",
      "331 -> Loss: 0.22362864017486572\n",
      "332 -> Loss: 0.5670953989028931\n",
      "333 -> Loss: 0.2812422215938568\n",
      "334 -> Loss: 0.6709362268447876\n",
      "335 -> Loss: 0.5477700233459473\n",
      "336 -> Loss: 0.5060665607452393\n",
      "337 -> Loss: 0.3534243404865265\n",
      "338 -> Loss: 0.4461037516593933\n",
      "339 -> Loss: 0.42019495368003845\n",
      "340 -> Loss: 0.233628511428833\n",
      "341 -> Loss: 0.42117729783058167\n",
      "342 -> Loss: 0.4471198320388794\n",
      "343 -> Loss: 0.811424195766449\n",
      "344 -> Loss: 0.3335855007171631\n",
      "345 -> Loss: 0.20656722784042358\n",
      "346 -> Loss: 0.796370804309845\n",
      "347 -> Loss: 0.12001129984855652\n",
      "348 -> Loss: 0.5523136854171753\n",
      "349 -> Loss: 0.2022295743227005\n",
      "350 -> Loss: 0.6592189073562622\n",
      "351 -> Loss: 0.4875495731830597\n",
      "352 -> Loss: 0.28172188997268677\n",
      "353 -> Loss: 0.6823731660842896\n",
      "354 -> Loss: 0.3646654784679413\n",
      "355 -> Loss: 0.40648341178894043\n",
      "356 -> Loss: 0.43610042333602905\n",
      "357 -> Loss: 0.8846461176872253\n",
      "358 -> Loss: 0.25273773074150085\n",
      "359 -> Loss: 0.7867050170898438\n",
      "360 -> Loss: 0.7382318377494812\n",
      "361 -> Loss: 0.135109081864357\n",
      "362 -> Loss: 0.792224645614624\n",
      "363 -> Loss: 0.19239956140518188\n",
      "364 -> Loss: 0.3792118728160858\n",
      "365 -> Loss: 0.49183133244514465\n",
      "366 -> Loss: 0.15322962403297424\n",
      "367 -> Loss: 0.5946663022041321\n",
      "368 -> Loss: 0.09382274746894836\n",
      "369 -> Loss: 0.5125417709350586\n",
      "370 -> Loss: 0.7541263103485107\n",
      "371 -> Loss: 0.305733323097229\n",
      "372 -> Loss: 0.9781752824783325\n",
      "373 -> Loss: 0.6035264730453491\n",
      "374 -> Loss: 0.42909878492355347\n",
      "375 -> Loss: 0.33162593841552734\n",
      "376 -> Loss: 0.6547126770019531\n",
      "377 -> Loss: 0.47848841547966003\n",
      "378 -> Loss: 0.22570545971393585\n",
      "379 -> Loss: 0.3032875955104828\n",
      "380 -> Loss: 0.26774200797080994\n",
      "381 -> Loss: 0.4800700843334198\n",
      "382 -> Loss: 1.0760693550109863\n",
      "383 -> Loss: 1.2677245140075684\n",
      "384 -> Loss: 0.5123387575149536\n",
      "385 -> Loss: 0.8088845014572144\n",
      "386 -> Loss: 0.42054566740989685\n",
      "387 -> Loss: 0.35074520111083984\n",
      "388 -> Loss: 0.3931424617767334\n",
      "389 -> Loss: 0.44085174798965454\n",
      "390 -> Loss: 0.7040209174156189\n",
      "391 -> Loss: 0.4517005681991577\n",
      "392 -> Loss: 0.31069204211235046\n",
      "393 -> Loss: 0.5343918800354004\n",
      "394 -> Loss: 0.24348291754722595\n",
      "395 -> Loss: 0.42555975914001465\n",
      "396 -> Loss: 1.0655508041381836\n",
      "397 -> Loss: 0.3726544678211212\n",
      "398 -> Loss: 0.5131593942642212\n",
      "399 -> Loss: 0.40325018763542175\n",
      "400 -> Loss: 0.603395938873291\n",
      "401 -> Loss: 0.1479460746049881\n",
      "402 -> Loss: 0.5062153339385986\n",
      "403 -> Loss: 0.6762787103652954\n",
      "404 -> Loss: 0.792961597442627\n",
      "405 -> Loss: 0.42009037733078003\n",
      "406 -> Loss: 0.5657393932342529\n",
      "407 -> Loss: 0.9206163883209229\n",
      "408 -> Loss: 0.31839653849601746\n",
      "409 -> Loss: 1.0769362449645996\n",
      "410 -> Loss: 0.5133825540542603\n",
      "411 -> Loss: 0.3987601101398468\n",
      "412 -> Loss: 0.25849756598472595\n",
      "413 -> Loss: 0.4096258878707886\n",
      "414 -> Loss: 0.7005020976066589\n",
      "415 -> Loss: 0.9842206835746765\n",
      "416 -> Loss: 0.3546813130378723\n",
      "417 -> Loss: 0.3045974671840668\n",
      "418 -> Loss: 0.667052149772644\n",
      "419 -> Loss: 0.8688555955886841\n",
      "420 -> Loss: 0.7315855622291565\n",
      "421 -> Loss: 0.8344125151634216\n",
      "422 -> Loss: 0.5930086970329285\n",
      "423 -> Loss: 0.49761515855789185\n",
      "424 -> Loss: 0.7749520540237427\n",
      "425 -> Loss: 0.5219030380249023\n",
      "426 -> Loss: 0.6650877594947815\n",
      "427 -> Loss: 0.11959080398082733\n",
      "428 -> Loss: 0.23478761315345764\n",
      "429 -> Loss: 0.5988476276397705\n",
      "430 -> Loss: 0.5054283738136292\n",
      "431 -> Loss: 0.633685290813446\n",
      "432 -> Loss: 0.3442228436470032\n",
      "433 -> Loss: 0.4418264925479889\n",
      "434 -> Loss: 0.3845049738883972\n",
      "435 -> Loss: 0.5002784729003906\n",
      "436 -> Loss: 0.30685126781463623\n",
      "437 -> Loss: 0.8802295327186584\n",
      "438 -> Loss: 0.5298661589622498\n",
      "439 -> Loss: 0.2703186571598053\n",
      "440 -> Loss: 0.606948733329773\n",
      "441 -> Loss: 0.5288776159286499\n",
      "442 -> Loss: 0.21978828310966492\n",
      "443 -> Loss: 0.6135809421539307\n",
      "444 -> Loss: 0.3443421423435211\n",
      "445 -> Loss: 0.5210824012756348\n",
      "446 -> Loss: 0.33331912755966187\n",
      "447 -> Loss: 0.2709551155567169\n",
      "448 -> Loss: 0.16813939809799194\n",
      "449 -> Loss: 0.9128741025924683\n",
      "450 -> Loss: 0.4418310821056366\n",
      "451 -> Loss: 0.3470519781112671\n",
      "452 -> Loss: 0.2763955593109131\n",
      "453 -> Loss: 0.708394467830658\n",
      "454 -> Loss: 0.540992021560669\n",
      "455 -> Loss: 0.5537145733833313\n",
      "456 -> Loss: 0.3395850956439972\n",
      "457 -> Loss: 0.36382728815078735\n",
      "458 -> Loss: 0.3703743815422058\n",
      "459 -> Loss: 0.4936327040195465\n",
      "460 -> Loss: 0.27077680826187134\n",
      "461 -> Loss: 0.6106404066085815\n",
      "462 -> Loss: 0.17007067799568176\n",
      "463 -> Loss: 0.4736151099205017\n",
      "464 -> Loss: 0.779415488243103\n",
      "465 -> Loss: 0.3209529221057892\n",
      "466 -> Loss: 0.9038340449333191\n",
      "467 -> Loss: 0.5125548243522644\n",
      "468 -> Loss: 0.3551194667816162\n",
      "469 -> Loss: 0.3596939444541931\n",
      "470 -> Loss: 0.47034239768981934\n",
      "471 -> Loss: 0.6794735789299011\n",
      "472 -> Loss: 0.27730751037597656\n",
      "473 -> Loss: 0.5808674097061157\n",
      "474 -> Loss: 0.2708062529563904\n",
      "475 -> Loss: 0.3788553476333618\n",
      "476 -> Loss: 0.32671111822128296\n",
      "477 -> Loss: 0.7537513375282288\n",
      "478 -> Loss: 0.09016316384077072\n",
      "479 -> Loss: 0.31424635648727417\n",
      "480 -> Loss: 0.34029442071914673\n",
      "481 -> Loss: 0.31085309386253357\n",
      "482 -> Loss: 0.29737186431884766\n",
      "483 -> Loss: 1.087871789932251\n",
      "484 -> Loss: 0.22845378518104553\n",
      "485 -> Loss: 0.24321307241916656\n",
      "486 -> Loss: 0.28899794816970825\n",
      "487 -> Loss: 0.44976145029067993\n",
      "488 -> Loss: 0.16006632149219513\n",
      "489 -> Loss: 0.4442826211452484\n",
      "490 -> Loss: 0.18339204788208008\n",
      "491 -> Loss: 0.30895498394966125\n",
      "492 -> Loss: 0.8430424332618713\n",
      "493 -> Loss: 0.7128961682319641\n",
      "494 -> Loss: 0.44606897234916687\n",
      "495 -> Loss: 0.5966736078262329\n",
      "496 -> Loss: 0.4240635335445404\n",
      "497 -> Loss: 0.9762077927589417\n",
      "498 -> Loss: 0.7836547493934631\n",
      "499 -> Loss: 0.32744207978248596\n",
      "500 -> Loss: 0.7420529127120972\n",
      "501 -> Loss: 0.20581984519958496\n",
      "502 -> Loss: 0.5609287023544312\n",
      "503 -> Loss: 0.4517973065376282\n",
      "504 -> Loss: 1.284356951713562\n",
      "505 -> Loss: 0.3001087009906769\n",
      "506 -> Loss: 0.5738126635551453\n",
      "507 -> Loss: 0.42210716009140015\n",
      "508 -> Loss: 0.44952842593193054\n",
      "509 -> Loss: 0.5554172992706299\n",
      "510 -> Loss: 0.3459049165248871\n",
      "511 -> Loss: 0.36647939682006836\n",
      "512 -> Loss: 0.8979705572128296\n",
      "513 -> Loss: 0.2999529242515564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514 -> Loss: 0.3638819456100464\n",
      "515 -> Loss: 0.5962555408477783\n",
      "516 -> Loss: 0.38886767625808716\n",
      "517 -> Loss: 0.6665236949920654\n",
      "518 -> Loss: 0.2738398313522339\n",
      "519 -> Loss: 0.22141176462173462\n",
      "520 -> Loss: 0.22383053600788116\n",
      "521 -> Loss: 0.8388539552688599\n",
      "522 -> Loss: 0.26361143589019775\n",
      "523 -> Loss: 0.5790871381759644\n",
      "524 -> Loss: 0.367141991853714\n",
      "525 -> Loss: 0.3153378963470459\n",
      "526 -> Loss: 0.8531593084335327\n",
      "527 -> Loss: 0.48080137372016907\n",
      "528 -> Loss: 0.4085765480995178\n",
      "529 -> Loss: 0.7370085120201111\n",
      "530 -> Loss: 0.40140289068222046\n",
      "531 -> Loss: 0.45800086855888367\n",
      "532 -> Loss: 0.530412495136261\n",
      "533 -> Loss: 0.6282362937927246\n",
      "534 -> Loss: 0.1508878469467163\n",
      "535 -> Loss: 0.772908627986908\n",
      "536 -> Loss: 0.33029472827911377\n",
      "537 -> Loss: 0.6174072623252869\n",
      "538 -> Loss: 0.3727363049983978\n",
      "539 -> Loss: 0.31696566939353943\n",
      "540 -> Loss: 0.7487247586250305\n",
      "541 -> Loss: 0.5088855028152466\n",
      "542 -> Loss: 0.30606651306152344\n",
      "543 -> Loss: 0.4410032033920288\n",
      "544 -> Loss: 0.6288946866989136\n",
      "545 -> Loss: 0.7768513560295105\n",
      "546 -> Loss: 0.3354640007019043\n",
      "547 -> Loss: 1.02070152759552\n",
      "548 -> Loss: 0.7417237758636475\n",
      "549 -> Loss: 0.5719045996665955\n",
      "550 -> Loss: 1.1739001274108887\n",
      "551 -> Loss: 0.5019453167915344\n",
      "552 -> Loss: 0.8630686402320862\n",
      "553 -> Loss: 0.5856883525848389\n",
      "554 -> Loss: 1.1451035737991333\n",
      "555 -> Loss: 0.733508825302124\n",
      "556 -> Loss: 0.5302356481552124\n",
      "557 -> Loss: 0.33963242173194885\n",
      "558 -> Loss: 0.4559701681137085\n",
      "559 -> Loss: 0.8837518692016602\n",
      "560 -> Loss: 0.6694167256355286\n",
      "561 -> Loss: 0.2568836808204651\n",
      "562 -> Loss: 0.2677910625934601\n",
      "563 -> Loss: 0.21764658391475677\n",
      "564 -> Loss: 1.352710247039795\n",
      "565 -> Loss: 0.6437622308731079\n",
      "566 -> Loss: 0.47580280900001526\n",
      "567 -> Loss: 0.8886750340461731\n",
      "568 -> Loss: 0.3868444859981537\n",
      "569 -> Loss: 0.4820074737071991\n",
      "570 -> Loss: 0.520075798034668\n",
      "571 -> Loss: 0.23718520998954773\n",
      "572 -> Loss: 0.29847851395606995\n",
      "573 -> Loss: 0.41593724489212036\n",
      "574 -> Loss: 0.48338770866394043\n",
      "575 -> Loss: 0.5620201826095581\n",
      "576 -> Loss: 0.3696066439151764\n",
      "577 -> Loss: 0.21093980967998505\n",
      "578 -> Loss: 0.43725982308387756\n",
      "579 -> Loss: 0.545336902141571\n",
      "580 -> Loss: 0.5227900743484497\n",
      "581 -> Loss: 0.5402436852455139\n",
      "582 -> Loss: 0.560520350933075\n",
      "583 -> Loss: 0.48200586438179016\n",
      "584 -> Loss: 0.47131797671318054\n",
      "585 -> Loss: 0.5650838017463684\n",
      "586 -> Loss: 0.7796453237533569\n",
      "587 -> Loss: 0.2342149019241333\n",
      "588 -> Loss: 0.42696136236190796\n",
      "589 -> Loss: 0.6158758997917175\n",
      "590 -> Loss: 0.46020862460136414\n",
      "591 -> Loss: 0.4366081953048706\n",
      "592 -> Loss: 0.6024870276451111\n",
      "593 -> Loss: 0.5059505105018616\n",
      "594 -> Loss: 0.18433290719985962\n",
      "595 -> Loss: 0.6679944396018982\n",
      "596 -> Loss: 0.6249151229858398\n",
      "597 -> Loss: 0.521395206451416\n",
      "598 -> Loss: 0.42440488934516907\n",
      "599 -> Loss: 0.35357317328453064\n",
      "600 -> Loss: 0.5636903047561646\n",
      "601 -> Loss: 0.6114926338195801\n",
      "602 -> Loss: 0.8568405508995056\n",
      "603 -> Loss: 0.2866814434528351\n",
      "604 -> Loss: 0.6693542003631592\n",
      "605 -> Loss: 0.12945343554019928\n",
      "606 -> Loss: 0.8619343638420105\n",
      "607 -> Loss: 0.054563894867897034\n",
      "608 -> Loss: 0.8156663179397583\n",
      "609 -> Loss: 0.327945351600647\n",
      "610 -> Loss: 0.0959601029753685\n",
      "611 -> Loss: 0.6009557843208313\n",
      "612 -> Loss: 0.5021873116493225\n",
      "613 -> Loss: 0.9535167217254639\n",
      "614 -> Loss: 0.2722375690937042\n",
      "615 -> Loss: 0.6437363624572754\n",
      "616 -> Loss: 0.25129789113998413\n",
      "617 -> Loss: 0.21438542008399963\n",
      "618 -> Loss: 1.0510149002075195\n",
      "619 -> Loss: 0.23662510514259338\n",
      "620 -> Loss: 0.2749502956867218\n",
      "621 -> Loss: 0.4294064939022064\n",
      "622 -> Loss: 0.37547510862350464\n",
      "623 -> Loss: 0.9644553661346436\n",
      "624 -> Loss: 0.30532097816467285\n",
      "625 -> Loss: 0.32612407207489014\n",
      "626 -> Loss: 0.33997222781181335\n",
      "627 -> Loss: 0.7520706057548523\n",
      "628 -> Loss: 0.8372217416763306\n",
      "629 -> Loss: 0.36298757791519165\n",
      "630 -> Loss: 0.21160495281219482\n",
      "631 -> Loss: 0.7564796209335327\n",
      "632 -> Loss: 0.41665181517601013\n",
      "633 -> Loss: 0.3401966989040375\n",
      "634 -> Loss: 0.16905577480793\n",
      "635 -> Loss: 0.24302545189857483\n",
      "636 -> Loss: 0.47689133882522583\n",
      "637 -> Loss: 0.6221755146980286\n",
      "638 -> Loss: 0.283191055059433\n",
      "639 -> Loss: 0.5297936797142029\n",
      "640 -> Loss: 0.6356381177902222\n",
      "641 -> Loss: 0.23006650805473328\n",
      "642 -> Loss: 0.46390894055366516\n",
      "643 -> Loss: 0.5650768280029297\n",
      "644 -> Loss: 0.8487813472747803\n",
      "645 -> Loss: 0.5216549038887024\n",
      "646 -> Loss: 0.23351089656352997\n",
      "647 -> Loss: 0.25514253973960876\n",
      "648 -> Loss: 0.11047355830669403\n",
      "649 -> Loss: 0.658941924571991\n",
      "650 -> Loss: 0.5613294839859009\n",
      "651 -> Loss: 0.425376832485199\n",
      "652 -> Loss: 1.0305094718933105\n",
      "653 -> Loss: 0.35544198751449585\n",
      "654 -> Loss: 0.643383264541626\n",
      "655 -> Loss: 0.19860127568244934\n",
      "656 -> Loss: 0.4854598343372345\n",
      "657 -> Loss: 0.6412245035171509\n",
      "658 -> Loss: 0.22521637380123138\n",
      "659 -> Loss: 0.35975882411003113\n",
      "660 -> Loss: 0.35970062017440796\n",
      "661 -> Loss: 0.21366390585899353\n",
      "662 -> Loss: 0.9224909543991089\n",
      "663 -> Loss: 0.5835461020469666\n",
      "664 -> Loss: 0.5296260118484497\n",
      "665 -> Loss: 0.7356141209602356\n",
      "666 -> Loss: 0.7107119560241699\n",
      "667 -> Loss: 0.6901090145111084\n",
      "668 -> Loss: 0.36440300941467285\n",
      "669 -> Loss: 0.22451089322566986\n",
      "670 -> Loss: 0.8433369398117065\n",
      "671 -> Loss: 0.8173783421516418\n",
      "672 -> Loss: 0.9481149315834045\n",
      "673 -> Loss: 0.2648252248764038\n",
      "674 -> Loss: 0.7023138403892517\n",
      "675 -> Loss: 0.337211549282074\n",
      "676 -> Loss: 1.1708428859710693\n",
      "677 -> Loss: 0.648398220539093\n",
      "678 -> Loss: 0.09243396669626236\n",
      "679 -> Loss: 0.4112209975719452\n",
      "680 -> Loss: 0.4998338520526886\n",
      "681 -> Loss: 0.45811858773231506\n",
      "682 -> Loss: 0.7480248212814331\n",
      "683 -> Loss: 0.22658316791057587\n",
      "684 -> Loss: 0.6535411477088928\n",
      "685 -> Loss: 0.823769748210907\n",
      "686 -> Loss: 0.6173561811447144\n",
      "687 -> Loss: 0.4472578465938568\n",
      "688 -> Loss: 0.49130526185035706\n",
      "689 -> Loss: 1.1005115509033203\n",
      "690 -> Loss: 0.21857120096683502\n",
      "691 -> Loss: 0.1422533094882965\n",
      "692 -> Loss: 0.18546347320079803\n",
      "693 -> Loss: 0.7069635987281799\n",
      "694 -> Loss: 0.2830529808998108\n",
      "695 -> Loss: 0.676487922668457\n",
      "696 -> Loss: 0.3414202928543091\n",
      "697 -> Loss: 0.8393824100494385\n",
      "698 -> Loss: 0.9382008910179138\n",
      "699 -> Loss: 0.7897652983665466\n",
      "700 -> Loss: 0.6724526286125183\n",
      "701 -> Loss: 0.46183571219444275\n",
      "702 -> Loss: 0.2281651645898819\n",
      "703 -> Loss: 0.5740536451339722\n",
      "704 -> Loss: 0.8196933269500732\n",
      "705 -> Loss: 0.669661283493042\n",
      "706 -> Loss: 0.44357776641845703\n",
      "707 -> Loss: 0.3321184515953064\n",
      "708 -> Loss: 0.17569735646247864\n",
      "709 -> Loss: 0.7069051861763\n",
      "710 -> Loss: 0.1591704785823822\n",
      "711 -> Loss: 0.6476003527641296\n",
      "712 -> Loss: 0.7590410709381104\n",
      "713 -> Loss: 0.15334552526474\n",
      "714 -> Loss: 0.6603546142578125\n",
      "715 -> Loss: 0.23241861164569855\n",
      "716 -> Loss: 0.7741109728813171\n",
      "717 -> Loss: 0.6714164614677429\n",
      "718 -> Loss: 0.19801247119903564\n",
      "719 -> Loss: 0.21920037269592285\n",
      "720 -> Loss: 0.29935961961746216\n",
      "721 -> Loss: 0.446816086769104\n",
      "722 -> Loss: 0.3712027072906494\n",
      "723 -> Loss: 0.42864131927490234\n",
      "724 -> Loss: 0.3815672993659973\n",
      "725 -> Loss: 0.43538692593574524\n",
      "726 -> Loss: 0.5261609554290771\n",
      "727 -> Loss: 0.14928629994392395\n",
      "728 -> Loss: 0.13506430387496948\n",
      "729 -> Loss: 0.7688177824020386\n",
      "730 -> Loss: 0.4447322487831116\n",
      "731 -> Loss: 0.4997626841068268\n",
      "732 -> Loss: 0.5650066137313843\n",
      "733 -> Loss: 0.5336959362030029\n",
      "734 -> Loss: 1.18503737449646\n",
      "735 -> Loss: 0.29500246047973633\n",
      "736 -> Loss: 0.34134283661842346\n",
      "737 -> Loss: 0.5945127010345459\n",
      "738 -> Loss: 0.8248416185379028\n",
      "739 -> Loss: 0.5768027305603027\n",
      "740 -> Loss: 0.30935826897621155\n",
      "741 -> Loss: 0.34910327196121216\n",
      "742 -> Loss: 0.7961113452911377\n",
      "743 -> Loss: 0.4883866608142853\n",
      "744 -> Loss: 0.4921639859676361\n",
      "745 -> Loss: 0.7111706733703613\n",
      "746 -> Loss: 0.23933951556682587\n",
      "747 -> Loss: 0.2949100136756897\n",
      "748 -> Loss: 0.23926852643489838\n",
      "749 -> Loss: 0.34588825702667236\n",
      "750 -> Loss: 0.5824708938598633\n",
      "751 -> Loss: 0.5522606372833252\n",
      "752 -> Loss: 0.6101070642471313\n",
      "753 -> Loss: 0.42922666668891907\n",
      "754 -> Loss: 0.4926522672176361\n",
      "755 -> Loss: 0.18579678237438202\n",
      "756 -> Loss: 0.6832948327064514\n",
      "757 -> Loss: 1.1696338653564453\n",
      "758 -> Loss: 0.3799894154071808\n",
      "759 -> Loss: 0.3149247467517853\n",
      "760 -> Loss: 0.21242544054985046\n",
      "761 -> Loss: 0.5714666843414307\n",
      "762 -> Loss: 0.474713534116745\n",
      "763 -> Loss: 0.47248098254203796\n",
      "764 -> Loss: 0.2771371304988861\n",
      "765 -> Loss: 0.3960421085357666\n",
      "766 -> Loss: 0.2645720839500427\n",
      "767 -> Loss: 0.4868307113647461\n",
      "768 -> Loss: 0.8844877481460571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 -> Loss: 1.060248613357544\n",
      "770 -> Loss: 0.7374250888824463\n",
      "771 -> Loss: 0.870110273361206\n",
      "772 -> Loss: 0.24526375532150269\n",
      "773 -> Loss: 0.49328744411468506\n",
      "774 -> Loss: 0.18299981951713562\n",
      "775 -> Loss: 0.5860162973403931\n",
      "776 -> Loss: 0.6000025272369385\n",
      "777 -> Loss: 0.5822156071662903\n",
      "778 -> Loss: 0.8296589255332947\n",
      "779 -> Loss: 0.4015807509422302\n",
      "780 -> Loss: 0.4388345777988434\n",
      "781 -> Loss: 0.2461174726486206\n",
      "782 -> Loss: 0.47471311688423157\n",
      "783 -> Loss: 0.34213709831237793\n",
      "784 -> Loss: 0.2503000497817993\n",
      "785 -> Loss: 0.5483832359313965\n",
      "786 -> Loss: 0.4859844744205475\n",
      "787 -> Loss: 0.5199170112609863\n",
      "788 -> Loss: 0.22734658420085907\n",
      "789 -> Loss: 0.3786564767360687\n",
      "790 -> Loss: 0.45610886812210083\n",
      "791 -> Loss: 0.4401465654373169\n",
      "792 -> Loss: 0.6520127058029175\n",
      "793 -> Loss: 0.6121006608009338\n",
      "794 -> Loss: 0.7271037101745605\n",
      "795 -> Loss: 0.798469603061676\n",
      "796 -> Loss: 0.6800267100334167\n",
      "797 -> Loss: 0.6739587783813477\n",
      "798 -> Loss: 0.19953536987304688\n",
      "799 -> Loss: 0.2520343065261841\n",
      "800 -> Loss: 0.3606294095516205\n",
      "801 -> Loss: 0.742590069770813\n",
      "802 -> Loss: 0.29587987065315247\n",
      "803 -> Loss: 1.0533320903778076\n",
      "804 -> Loss: 0.2007698267698288\n",
      "805 -> Loss: 0.5416667461395264\n",
      "806 -> Loss: 0.49828287959098816\n",
      "807 -> Loss: 0.7598183155059814\n",
      "808 -> Loss: 0.5889653563499451\n",
      "809 -> Loss: 0.3206704556941986\n",
      "810 -> Loss: 0.6668691635131836\n",
      "811 -> Loss: 0.20944324135780334\n",
      "812 -> Loss: 0.35749974846839905\n",
      "813 -> Loss: 0.36579835414886475\n",
      "814 -> Loss: 0.5636128783226013\n",
      "815 -> Loss: 0.30491504073143005\n",
      "816 -> Loss: 0.43340471386909485\n",
      "817 -> Loss: 0.4732673466205597\n",
      "818 -> Loss: 0.4917208254337311\n",
      "819 -> Loss: 0.29241278767585754\n",
      "820 -> Loss: 0.4797569811344147\n",
      "821 -> Loss: 0.7170406579971313\n",
      "822 -> Loss: 0.5806429982185364\n",
      "823 -> Loss: 0.5452872514724731\n",
      "824 -> Loss: 0.6510159969329834\n",
      "825 -> Loss: 0.8117203116416931\n",
      "826 -> Loss: 0.6100350022315979\n",
      "827 -> Loss: 0.7665170431137085\n",
      "828 -> Loss: 0.27421900629997253\n",
      "829 -> Loss: 0.547715425491333\n",
      "830 -> Loss: 0.11610476672649384\n",
      "831 -> Loss: 0.45914915204048157\n",
      "832 -> Loss: 0.3152802884578705\n",
      "833 -> Loss: 0.34508177638053894\n",
      "834 -> Loss: 0.4966125786304474\n",
      "835 -> Loss: 0.5596653819084167\n",
      "836 -> Loss: 0.9780800938606262\n",
      "837 -> Loss: 0.5262070298194885\n",
      "838 -> Loss: 0.33268287777900696\n",
      "839 -> Loss: 0.6429002285003662\n",
      "840 -> Loss: 0.42986518144607544\n",
      "841 -> Loss: 0.2937326729297638\n",
      "842 -> Loss: 0.5231740474700928\n",
      "843 -> Loss: 0.49149614572525024\n",
      "844 -> Loss: 0.222563236951828\n",
      "845 -> Loss: 0.6227449774742126\n",
      "846 -> Loss: 0.3089163303375244\n",
      "847 -> Loss: 0.40469858050346375\n",
      "848 -> Loss: 0.762547492980957\n",
      "849 -> Loss: 0.5674791932106018\n",
      "850 -> Loss: 0.4067525267601013\n",
      "851 -> Loss: 0.3960179388523102\n",
      "852 -> Loss: 0.30570298433303833\n",
      "853 -> Loss: 0.7205132842063904\n",
      "854 -> Loss: 0.41933363676071167\n",
      "855 -> Loss: 0.7887853980064392\n",
      "856 -> Loss: 0.9521710872650146\n",
      "857 -> Loss: 0.04440882429480553\n",
      "858 -> Loss: 0.7942763566970825\n",
      "859 -> Loss: 0.4714238941669464\n",
      "860 -> Loss: 0.2779795229434967\n",
      "861 -> Loss: 0.44631311297416687\n",
      "862 -> Loss: 0.20734617114067078\n",
      "863 -> Loss: 0.9689337611198425\n",
      "864 -> Loss: 0.4844357371330261\n",
      "865 -> Loss: 0.3807259500026703\n",
      "866 -> Loss: 0.439734548330307\n",
      "867 -> Loss: 0.5765792727470398\n",
      "868 -> Loss: 0.49660778045654297\n",
      "869 -> Loss: 0.6702476143836975\n",
      "870 -> Loss: 0.5171040892601013\n",
      "871 -> Loss: 0.4938218295574188\n",
      "872 -> Loss: 0.23181316256523132\n",
      "873 -> Loss: 0.24580278992652893\n",
      "874 -> Loss: 0.6652852296829224\n",
      "875 -> Loss: 0.638210117816925\n",
      "876 -> Loss: 0.45128223299980164\n",
      "877 -> Loss: 0.7698202729225159\n",
      "878 -> Loss: 0.3547751307487488\n",
      "879 -> Loss: 0.13125842809677124\n",
      "880 -> Loss: 0.5485274791717529\n",
      "881 -> Loss: 0.2050192505121231\n",
      "882 -> Loss: 0.3865441679954529\n",
      "883 -> Loss: 0.8339189887046814\n",
      "884 -> Loss: 0.34196433424949646\n",
      "885 -> Loss: 0.4156073033809662\n",
      "886 -> Loss: 0.7133633494377136\n",
      "887 -> Loss: 0.3314383924007416\n",
      "888 -> Loss: 0.5249670743942261\n",
      "889 -> Loss: 0.5407811999320984\n",
      "890 -> Loss: 0.46912941336631775\n",
      "891 -> Loss: 0.5880904197692871\n",
      "892 -> Loss: 0.523669958114624\n",
      "893 -> Loss: 0.38331732153892517\n",
      "894 -> Loss: 0.2715618908405304\n",
      "895 -> Loss: 0.49583953619003296\n",
      "896 -> Loss: 1.2074503898620605\n",
      "897 -> Loss: 0.36473119258880615\n",
      "898 -> Loss: 0.21031692624092102\n",
      "899 -> Loss: 0.34107235074043274\n",
      "900 -> Loss: 0.6232115030288696\n",
      "901 -> Loss: 0.16002152860164642\n",
      "902 -> Loss: 0.3394030034542084\n",
      "903 -> Loss: 0.34708401560783386\n",
      "904 -> Loss: 0.17169564962387085\n",
      "905 -> Loss: 0.6054919958114624\n",
      "906 -> Loss: 0.5763269662857056\n",
      "907 -> Loss: 0.5277164578437805\n",
      "908 -> Loss: 0.38591617345809937\n",
      "909 -> Loss: 0.4130854606628418\n",
      "910 -> Loss: 0.23829525709152222\n",
      "911 -> Loss: 0.06482068449258804\n",
      "912 -> Loss: 0.15262563526630402\n",
      "913 -> Loss: 0.8227399587631226\n",
      "914 -> Loss: 0.7396606206893921\n",
      "915 -> Loss: 0.6287024617195129\n",
      "916 -> Loss: 0.6047910451889038\n",
      "917 -> Loss: 0.4458216726779938\n",
      "918 -> Loss: 1.0413283109664917\n",
      "919 -> Loss: 0.4656818211078644\n",
      "920 -> Loss: 0.5459287762641907\n",
      "921 -> Loss: 0.8843845725059509\n",
      "922 -> Loss: 0.7426360845565796\n",
      "923 -> Loss: 0.2836874723434448\n",
      "924 -> Loss: 0.7879385352134705\n",
      "925 -> Loss: 0.3903293311595917\n",
      "926 -> Loss: 0.4662388265132904\n",
      "927 -> Loss: 0.3532674312591553\n",
      "928 -> Loss: 0.49060067534446716\n",
      "929 -> Loss: 0.6202114224433899\n",
      "930 -> Loss: 0.5489990711212158\n",
      "931 -> Loss: 0.24025346338748932\n",
      "932 -> Loss: 0.7216126918792725\n",
      "933 -> Loss: 0.6310214996337891\n",
      "934 -> Loss: 0.28995034098625183\n",
      "935 -> Loss: 0.26020166277885437\n",
      "936 -> Loss: 0.3909081816673279\n",
      "937 -> Loss: 0.5227696299552917\n",
      "938 -> Loss: 0.4193077087402344\n",
      "939 -> Loss: 0.6175203323364258\n",
      "940 -> Loss: 0.6962789297103882\n",
      "941 -> Loss: 0.57053542137146\n",
      "942 -> Loss: 0.28638193011283875\n",
      "943 -> Loss: 0.26913145184516907\n",
      "944 -> Loss: 0.5703697204589844\n",
      "945 -> Loss: 0.9370971918106079\n",
      "946 -> Loss: 0.25801849365234375\n",
      "947 -> Loss: 0.3565205931663513\n",
      "948 -> Loss: 0.17641180753707886\n",
      "949 -> Loss: 0.829200029373169\n",
      "950 -> Loss: 0.2427237331867218\n",
      "951 -> Loss: 0.43710774183273315\n",
      "952 -> Loss: 0.3760150372982025\n",
      "953 -> Loss: 0.7835503220558167\n",
      "954 -> Loss: 0.5741713643074036\n",
      "955 -> Loss: 0.24883592128753662\n",
      "956 -> Loss: 0.6760683655738831\n",
      "957 -> Loss: 0.2812661826610565\n",
      "958 -> Loss: 0.5360136032104492\n",
      "959 -> Loss: 0.20409558713436127\n",
      "960 -> Loss: 0.5942479968070984\n",
      "961 -> Loss: 0.7228884100914001\n",
      "962 -> Loss: 0.5206254720687866\n",
      "963 -> Loss: 0.33741530776023865\n",
      "964 -> Loss: 0.3528062403202057\n",
      "965 -> Loss: 0.536856472492218\n",
      "966 -> Loss: 0.23231816291809082\n",
      "967 -> Loss: 0.07869666814804077\n",
      "968 -> Loss: 0.6373865604400635\n",
      "969 -> Loss: 0.46638357639312744\n",
      "970 -> Loss: 0.4951799809932709\n",
      "971 -> Loss: 0.19869539141654968\n",
      "972 -> Loss: 0.501367449760437\n",
      "973 -> Loss: 0.3207303285598755\n",
      "974 -> Loss: 0.5268728137016296\n",
      "975 -> Loss: 0.22443841397762299\n",
      "976 -> Loss: 0.4250776469707489\n",
      "977 -> Loss: 0.05787963792681694\n",
      "978 -> Loss: 0.3257554769515991\n",
      "979 -> Loss: 0.09545571357011795\n",
      "980 -> Loss: 0.7237119674682617\n",
      "981 -> Loss: 0.7689898014068604\n",
      "982 -> Loss: 0.34554076194763184\n",
      "983 -> Loss: 0.273464560508728\n",
      "984 -> Loss: 0.6299830675125122\n",
      "985 -> Loss: 0.30034855008125305\n",
      "986 -> Loss: 0.7003106474876404\n",
      "987 -> Loss: 0.43939799070358276\n",
      "988 -> Loss: 0.2813330590724945\n",
      "989 -> Loss: 0.6720258593559265\n",
      "990 -> Loss: 0.29571443796157837\n",
      "991 -> Loss: 0.6794347167015076\n",
      "992 -> Loss: 0.4123818576335907\n",
      "993 -> Loss: 0.8525267243385315\n",
      "994 -> Loss: 0.4408966302871704\n",
      "995 -> Loss: 0.6031596064567566\n",
      "996 -> Loss: 0.31126701831817627\n",
      "997 -> Loss: 0.4564668834209442\n",
      "998 -> Loss: 0.30714666843414307\n",
      "999 -> Loss: 1.1486493349075317\n",
      "1000 -> Loss: 0.25367069244384766\n",
      "\n",
      "Validation Accuracy: 65.0, Test Accuracy: 74.5 \n",
      "\n",
      "1001 -> Loss: 1.002090573310852\n",
      "1002 -> Loss: 0.6257436871528625\n",
      "1003 -> Loss: 0.39272475242614746\n",
      "1004 -> Loss: 0.6839376091957092\n",
      "1005 -> Loss: 0.3505590260028839\n",
      "1006 -> Loss: 0.40941864252090454\n",
      "1007 -> Loss: 0.43139562010765076\n",
      "1008 -> Loss: 0.6268888711929321\n",
      "1009 -> Loss: 0.23485404253005981\n",
      "1010 -> Loss: 0.4764598608016968\n",
      "1011 -> Loss: 0.6661348938941956\n",
      "1012 -> Loss: 0.3779447376728058\n",
      "1013 -> Loss: 0.4385703504085541\n",
      "1014 -> Loss: 0.5327048301696777\n",
      "1015 -> Loss: 0.6448798775672913\n",
      "1016 -> Loss: 0.48470643162727356\n",
      "1017 -> Loss: 0.39979180693626404\n",
      "1018 -> Loss: 0.35296887159347534\n",
      "1019 -> Loss: 0.45750758051872253\n",
      "1020 -> Loss: 1.1134936809539795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021 -> Loss: 0.41861724853515625\n",
      "1022 -> Loss: 0.2911081910133362\n",
      "1023 -> Loss: 0.4622322618961334\n",
      "1024 -> Loss: 0.49772074818611145\n",
      "1025 -> Loss: 0.14924265444278717\n",
      "1026 -> Loss: 0.20530125498771667\n",
      "1027 -> Loss: 0.60121750831604\n",
      "1028 -> Loss: 0.34848424792289734\n",
      "1029 -> Loss: 0.4601617455482483\n",
      "1030 -> Loss: 0.4411923289299011\n",
      "1031 -> Loss: 0.4913756847381592\n",
      "1032 -> Loss: 0.29567456245422363\n",
      "1033 -> Loss: 0.6030915379524231\n",
      "1034 -> Loss: 0.6569069623947144\n",
      "1035 -> Loss: 0.45350611209869385\n",
      "1036 -> Loss: 1.2566273212432861\n",
      "1037 -> Loss: 0.6887289881706238\n",
      "1038 -> Loss: 0.5198811888694763\n",
      "1039 -> Loss: 0.2637079060077667\n",
      "1040 -> Loss: 0.5428491234779358\n",
      "1041 -> Loss: 0.4652807116508484\n",
      "1042 -> Loss: 0.21622249484062195\n",
      "1043 -> Loss: 0.4863138794898987\n",
      "1044 -> Loss: 0.11350523680448532\n",
      "1045 -> Loss: 0.7810757160186768\n",
      "1046 -> Loss: 0.5388825535774231\n",
      "1047 -> Loss: 0.3297642767429352\n",
      "1048 -> Loss: 0.26083287596702576\n",
      "1049 -> Loss: 0.29000335931777954\n",
      "1050 -> Loss: 0.49779096245765686\n",
      "1051 -> Loss: 0.5506600737571716\n",
      "1052 -> Loss: 0.41509711742401123\n",
      "1053 -> Loss: 0.5725373029708862\n",
      "1054 -> Loss: 0.1551327407360077\n",
      "1055 -> Loss: 0.2138805091381073\n",
      "1056 -> Loss: 0.7597084641456604\n",
      "1057 -> Loss: 0.41733309626579285\n",
      "1058 -> Loss: 0.3655122220516205\n",
      "1059 -> Loss: 0.5454047918319702\n",
      "1060 -> Loss: 0.6344922780990601\n",
      "1061 -> Loss: 0.749747097492218\n",
      "1062 -> Loss: 0.7969949245452881\n",
      "1063 -> Loss: 0.46330827474594116\n",
      "1064 -> Loss: 0.6364269256591797\n",
      "1065 -> Loss: 0.26532983779907227\n",
      "1066 -> Loss: 0.5272248387336731\n",
      "1067 -> Loss: 0.5495330691337585\n",
      "1068 -> Loss: 0.4034169614315033\n",
      "1069 -> Loss: 0.6674779057502747\n",
      "1070 -> Loss: 0.1801268756389618\n",
      "1071 -> Loss: 0.6407345533370972\n",
      "1072 -> Loss: 0.6081246733665466\n",
      "1073 -> Loss: 0.7071192860603333\n",
      "1074 -> Loss: 0.5141526460647583\n",
      "1075 -> Loss: 0.6970765590667725\n",
      "1076 -> Loss: 0.46985045075416565\n",
      "1077 -> Loss: 0.28825628757476807\n",
      "1078 -> Loss: 0.7662217617034912\n",
      "1079 -> Loss: 0.31840237975120544\n",
      "1080 -> Loss: 0.25567567348480225\n",
      "1081 -> Loss: 0.4794279932975769\n",
      "1082 -> Loss: 0.18865427374839783\n",
      "1083 -> Loss: 0.25296512246131897\n",
      "1084 -> Loss: 0.5729801654815674\n",
      "1085 -> Loss: 0.8345615863800049\n",
      "1086 -> Loss: 0.20705464482307434\n",
      "1087 -> Loss: 0.3256259262561798\n",
      "1088 -> Loss: 0.8707972764968872\n",
      "1089 -> Loss: 1.0061802864074707\n",
      "1090 -> Loss: 0.6313913464546204\n",
      "1091 -> Loss: 0.11725324392318726\n",
      "1092 -> Loss: 0.14340363442897797\n",
      "1093 -> Loss: 0.33322829008102417\n",
      "1094 -> Loss: 0.3847919702529907\n",
      "1095 -> Loss: 0.6675456166267395\n",
      "1096 -> Loss: 1.05287766456604\n",
      "1097 -> Loss: 0.6916826367378235\n",
      "1098 -> Loss: 0.8416853547096252\n",
      "1099 -> Loss: 0.43810945749282837\n",
      "1100 -> Loss: 0.121939517557621\n",
      "1101 -> Loss: 0.8849607110023499\n",
      "1102 -> Loss: 0.29603445529937744\n",
      "1103 -> Loss: 0.9070928692817688\n",
      "1104 -> Loss: 0.11690682172775269\n",
      "1105 -> Loss: 0.6041512489318848\n",
      "1106 -> Loss: 0.09658198058605194\n",
      "1107 -> Loss: 0.3205178380012512\n",
      "1108 -> Loss: 1.019818902015686\n",
      "1109 -> Loss: 0.6184383630752563\n",
      "1110 -> Loss: 0.6454350352287292\n",
      "1111 -> Loss: 0.46460679173469543\n",
      "1112 -> Loss: 0.32367706298828125\n",
      "1113 -> Loss: 0.21322935819625854\n",
      "1114 -> Loss: 0.4980909824371338\n",
      "1115 -> Loss: 0.701501727104187\n",
      "1116 -> Loss: 0.20699024200439453\n",
      "1117 -> Loss: 0.09653810411691666\n",
      "1118 -> Loss: 0.4269844889640808\n",
      "1119 -> Loss: 0.7162172198295593\n",
      "1120 -> Loss: 0.5118547677993774\n",
      "1121 -> Loss: 0.4280951917171478\n",
      "1122 -> Loss: 0.4476645886898041\n",
      "1123 -> Loss: 0.44051262736320496\n",
      "1124 -> Loss: 1.088160753250122\n",
      "1125 -> Loss: 0.8924880623817444\n",
      "1126 -> Loss: 0.4049989879131317\n",
      "1127 -> Loss: 0.698826789855957\n",
      "1128 -> Loss: 0.7813711762428284\n",
      "1129 -> Loss: 0.34570521116256714\n",
      "1130 -> Loss: 1.0111315250396729\n",
      "1131 -> Loss: 0.4584996998310089\n",
      "1132 -> Loss: 0.5766133069992065\n",
      "1133 -> Loss: 0.46222516894340515\n",
      "1134 -> Loss: 0.3089889883995056\n",
      "1135 -> Loss: 0.22534768283367157\n",
      "1136 -> Loss: 0.8672192692756653\n",
      "1137 -> Loss: 0.305764377117157\n",
      "1138 -> Loss: 0.7815436720848083\n",
      "1139 -> Loss: 0.7086102366447449\n",
      "1140 -> Loss: 0.3966667950153351\n",
      "1141 -> Loss: 0.4265054166316986\n",
      "1142 -> Loss: 0.7035462260246277\n",
      "1143 -> Loss: 0.7759332656860352\n",
      "1144 -> Loss: 0.48486486077308655\n",
      "1145 -> Loss: 0.5851007699966431\n",
      "1146 -> Loss: 0.07363300770521164\n",
      "1147 -> Loss: 0.5121363401412964\n",
      "1148 -> Loss: 0.349229633808136\n",
      "1149 -> Loss: 0.5692573189735413\n",
      "1150 -> Loss: 0.7401437759399414\n",
      "1151 -> Loss: 0.5251255631446838\n",
      "1152 -> Loss: 0.258586049079895\n",
      "1153 -> Loss: 0.184156134724617\n",
      "1154 -> Loss: 0.5419954657554626\n",
      "1155 -> Loss: 0.3521620035171509\n",
      "1156 -> Loss: 0.12391451001167297\n",
      "1157 -> Loss: 0.4216575622558594\n",
      "1158 -> Loss: 0.4630250632762909\n",
      "1159 -> Loss: 0.49639013409614563\n",
      "1160 -> Loss: 0.6219088435173035\n",
      "1161 -> Loss: 0.2895170748233795\n",
      "1162 -> Loss: 0.7597678899765015\n",
      "1163 -> Loss: 0.32488712668418884\n",
      "1164 -> Loss: 0.8072040677070618\n",
      "1165 -> Loss: 0.7133514285087585\n",
      "1166 -> Loss: 0.47261419892311096\n",
      "1167 -> Loss: 0.18216092884540558\n",
      "1168 -> Loss: 0.22740872204303741\n",
      "1169 -> Loss: 0.5270739793777466\n",
      "1170 -> Loss: 0.6828495860099792\n",
      "1171 -> Loss: 0.3802260756492615\n",
      "1172 -> Loss: 0.5546844005584717\n",
      "1173 -> Loss: 0.6144418716430664\n",
      "1174 -> Loss: 0.286539763212204\n",
      "1175 -> Loss: 0.6145439743995667\n",
      "1176 -> Loss: 0.44239965081214905\n",
      "1177 -> Loss: 0.4304051399230957\n",
      "1178 -> Loss: 0.5679768919944763\n",
      "1179 -> Loss: 0.7599782347679138\n",
      "1180 -> Loss: 0.8073270320892334\n",
      "1181 -> Loss: 0.6749959588050842\n",
      "1182 -> Loss: 0.157966747879982\n",
      "1183 -> Loss: 0.7625137567520142\n",
      "1184 -> Loss: 0.38401487469673157\n",
      "1185 -> Loss: 1.2871875762939453\n",
      "1186 -> Loss: 0.590679407119751\n",
      "1187 -> Loss: 0.4571099281311035\n",
      "1188 -> Loss: 0.2713876962661743\n",
      "1189 -> Loss: 0.599886953830719\n",
      "1190 -> Loss: 0.26389452815055847\n",
      "1191 -> Loss: 0.4446480870246887\n",
      "1192 -> Loss: 0.6648995280265808\n",
      "1193 -> Loss: 0.48557671904563904\n",
      "1194 -> Loss: 0.7917704582214355\n",
      "1195 -> Loss: 0.3359779715538025\n",
      "1196 -> Loss: 0.27266553044319153\n",
      "1197 -> Loss: 0.7477933764457703\n",
      "1198 -> Loss: 0.431204229593277\n",
      "1199 -> Loss: 0.5412411689758301\n",
      "1200 -> Loss: 0.15586015582084656\n",
      "1201 -> Loss: 0.8161940574645996\n",
      "1202 -> Loss: 0.4995019733905792\n",
      "1203 -> Loss: 0.08870453387498856\n",
      "1204 -> Loss: 0.19157487154006958\n",
      "1205 -> Loss: 0.45757052302360535\n",
      "1206 -> Loss: 0.5673240423202515\n",
      "1207 -> Loss: 0.21798686683177948\n",
      "1208 -> Loss: 0.5434229969978333\n",
      "1209 -> Loss: 0.255159467458725\n",
      "1210 -> Loss: 0.5139629244804382\n",
      "1211 -> Loss: 0.4864857792854309\n",
      "1212 -> Loss: 0.6504436731338501\n",
      "1213 -> Loss: 0.44914308190345764\n",
      "1214 -> Loss: 0.845001757144928\n",
      "1215 -> Loss: 0.4532959461212158\n",
      "1216 -> Loss: 0.4524119198322296\n",
      "1217 -> Loss: 0.6119256615638733\n",
      "1218 -> Loss: 0.6469867825508118\n",
      "1219 -> Loss: 0.43277421593666077\n",
      "1220 -> Loss: 0.29748886823654175\n",
      "1221 -> Loss: 0.615006685256958\n",
      "1222 -> Loss: 0.43306228518486023\n",
      "1223 -> Loss: 0.508401095867157\n",
      "1224 -> Loss: 0.27238595485687256\n",
      "1225 -> Loss: 0.5804967880249023\n",
      "1226 -> Loss: 0.37493258714675903\n",
      "1227 -> Loss: 0.40430623292922974\n",
      "1228 -> Loss: 0.6340086460113525\n",
      "1229 -> Loss: 0.28749173879623413\n",
      "1230 -> Loss: 0.8276103138923645\n",
      "1231 -> Loss: 0.15843886137008667\n",
      "1232 -> Loss: 0.6474626660346985\n",
      "1233 -> Loss: 0.5138697028160095\n",
      "1234 -> Loss: 0.5201416015625\n",
      "1235 -> Loss: 0.29130423069000244\n",
      "1236 -> Loss: 0.19867061078548431\n",
      "1237 -> Loss: 0.242075115442276\n",
      "1238 -> Loss: 0.47457852959632874\n",
      "1239 -> Loss: 0.4281958043575287\n",
      "1240 -> Loss: 0.26058289408683777\n",
      "1241 -> Loss: 0.4461767077445984\n",
      "1242 -> Loss: 0.8747694492340088\n",
      "1243 -> Loss: 0.5383603572845459\n",
      "1244 -> Loss: 0.7600277662277222\n",
      "1245 -> Loss: 0.21887758374214172\n",
      "1246 -> Loss: 0.7254239320755005\n",
      "1247 -> Loss: 0.178963765501976\n",
      "1248 -> Loss: 0.5008116960525513\n",
      "1249 -> Loss: 0.42585697770118713\n",
      "1250 -> Loss: 0.2768382728099823\n",
      "1251 -> Loss: 0.49018797278404236\n",
      "1252 -> Loss: 0.1490667164325714\n",
      "1253 -> Loss: 0.4358721971511841\n",
      "1254 -> Loss: 0.31177785992622375\n",
      "1255 -> Loss: 0.7155296802520752\n",
      "1256 -> Loss: 0.6637914180755615\n",
      "1257 -> Loss: 0.38643166422843933\n",
      "1258 -> Loss: 0.48575517535209656\n",
      "1259 -> Loss: 0.21602745354175568\n",
      "1260 -> Loss: 0.7655927538871765\n",
      "1261 -> Loss: 0.2642124593257904\n",
      "1262 -> Loss: 0.13056211173534393\n",
      "1263 -> Loss: 0.5843821167945862\n",
      "1264 -> Loss: 0.49272987246513367\n",
      "1265 -> Loss: 0.4878712296485901\n",
      "1266 -> Loss: 0.0780562236905098\n",
      "1267 -> Loss: 0.22328618168830872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268 -> Loss: 0.4895821213722229\n",
      "1269 -> Loss: 0.3977683484554291\n",
      "1270 -> Loss: 0.5042760372161865\n",
      "1271 -> Loss: 1.4033793210983276\n",
      "1272 -> Loss: 0.3048066794872284\n",
      "1273 -> Loss: 0.5521018505096436\n",
      "1274 -> Loss: 0.5059213042259216\n",
      "1275 -> Loss: 0.4293927550315857\n",
      "1276 -> Loss: 0.28390559554100037\n",
      "1277 -> Loss: 0.545642077922821\n",
      "1278 -> Loss: 0.4833724796772003\n",
      "1279 -> Loss: 0.38583970069885254\n",
      "1280 -> Loss: 0.4086553752422333\n",
      "1281 -> Loss: 0.16834409534931183\n",
      "1282 -> Loss: 0.34124815464019775\n",
      "1283 -> Loss: 0.41192299127578735\n",
      "1284 -> Loss: 0.7259250283241272\n",
      "1285 -> Loss: 0.2692745327949524\n",
      "1286 -> Loss: 1.000659465789795\n",
      "1287 -> Loss: 0.4118349850177765\n",
      "1288 -> Loss: 0.38503795862197876\n",
      "1289 -> Loss: 0.6695672273635864\n",
      "1290 -> Loss: 0.2621490955352783\n",
      "1291 -> Loss: 0.8266687393188477\n",
      "1292 -> Loss: 0.8023719191551208\n",
      "1293 -> Loss: 0.26815265417099\n",
      "1294 -> Loss: 0.5144680738449097\n",
      "1295 -> Loss: 0.7854167222976685\n",
      "1296 -> Loss: 0.4181743562221527\n",
      "1297 -> Loss: 0.5840034484863281\n",
      "1298 -> Loss: 0.1982537806034088\n",
      "1299 -> Loss: 0.539623498916626\n",
      "1300 -> Loss: 0.2668605148792267\n",
      "1301 -> Loss: 0.5224277377128601\n",
      "1302 -> Loss: 0.6138500571250916\n",
      "1303 -> Loss: 0.31572771072387695\n",
      "1304 -> Loss: 0.5772966146469116\n",
      "1305 -> Loss: 0.5928162336349487\n",
      "1306 -> Loss: 0.49362149834632874\n",
      "1307 -> Loss: 0.8330971598625183\n",
      "1308 -> Loss: 0.3060983419418335\n",
      "1309 -> Loss: 0.3282022774219513\n",
      "1310 -> Loss: 0.21726258099079132\n",
      "1311 -> Loss: 0.6697855591773987\n",
      "1312 -> Loss: 0.12804055213928223\n",
      "1313 -> Loss: 0.27854323387145996\n",
      "1314 -> Loss: 0.4913029670715332\n",
      "1315 -> Loss: 0.4939854145050049\n",
      "1316 -> Loss: 0.4437987208366394\n",
      "1317 -> Loss: 0.23347024619579315\n",
      "1318 -> Loss: 0.3957391381263733\n",
      "1319 -> Loss: 0.1914450228214264\n",
      "1320 -> Loss: 0.6385431289672852\n",
      "1321 -> Loss: 0.16781485080718994\n",
      "1322 -> Loss: 0.45799246430397034\n",
      "1323 -> Loss: 0.5344324111938477\n",
      "1324 -> Loss: 0.14964967966079712\n",
      "1325 -> Loss: 0.2590363919734955\n",
      "1326 -> Loss: 0.45562422275543213\n",
      "1327 -> Loss: 0.637954831123352\n",
      "1328 -> Loss: 0.5479151010513306\n",
      "1329 -> Loss: 0.5344062447547913\n",
      "1330 -> Loss: 0.467791348695755\n",
      "1331 -> Loss: 0.15184055268764496\n",
      "1332 -> Loss: 0.24774999916553497\n",
      "1333 -> Loss: 0.6980373859405518\n",
      "1334 -> Loss: 0.45995819568634033\n",
      "1335 -> Loss: 0.6653310060501099\n",
      "1336 -> Loss: 0.7294414043426514\n",
      "1337 -> Loss: 0.8391722440719604\n",
      "1338 -> Loss: 0.282291978597641\n",
      "1339 -> Loss: 1.0938830375671387\n",
      "1340 -> Loss: 0.46988487243652344\n",
      "1341 -> Loss: 0.7544079422950745\n",
      "1342 -> Loss: 0.5546091198921204\n",
      "1343 -> Loss: 0.8042356967926025\n",
      "1344 -> Loss: 0.2749023735523224\n",
      "1345 -> Loss: 0.41131433844566345\n",
      "1346 -> Loss: 0.7507827877998352\n",
      "1347 -> Loss: 1.024433970451355\n",
      "1348 -> Loss: 0.7378329634666443\n",
      "1349 -> Loss: 0.8586991429328918\n",
      "1350 -> Loss: 0.31510129570961\n",
      "1351 -> Loss: 0.49258553981781006\n",
      "1352 -> Loss: 0.6027718186378479\n",
      "1353 -> Loss: 0.48508015275001526\n",
      "1354 -> Loss: 0.27143800258636475\n",
      "1355 -> Loss: 0.3505154252052307\n",
      "1356 -> Loss: 0.7227888703346252\n",
      "1357 -> Loss: 0.32640838623046875\n",
      "1358 -> Loss: 0.3605692684650421\n",
      "1359 -> Loss: 1.1272594928741455\n",
      "1360 -> Loss: 0.3727194666862488\n",
      "1361 -> Loss: 0.11577040702104568\n",
      "1362 -> Loss: 0.24692568182945251\n",
      "1363 -> Loss: 0.18096528947353363\n",
      "1364 -> Loss: 0.5722858309745789\n",
      "1365 -> Loss: 0.5074805021286011\n",
      "1366 -> Loss: 0.9214472770690918\n",
      "1367 -> Loss: 0.26624560356140137\n",
      "1368 -> Loss: 1.022970199584961\n",
      "1369 -> Loss: 0.6721569299697876\n",
      "1370 -> Loss: 0.5145341753959656\n",
      "1371 -> Loss: 0.5019859075546265\n",
      "1372 -> Loss: 0.4126123785972595\n",
      "1373 -> Loss: 0.5068968534469604\n",
      "1374 -> Loss: 0.3642512559890747\n",
      "1375 -> Loss: 0.6661568880081177\n",
      "1376 -> Loss: 0.2834104001522064\n",
      "1377 -> Loss: 0.4669419527053833\n",
      "1378 -> Loss: 0.5819065570831299\n",
      "1379 -> Loss: 1.1996190547943115\n",
      "1380 -> Loss: 0.4262661337852478\n",
      "1381 -> Loss: 0.5440990924835205\n",
      "1382 -> Loss: 0.29886627197265625\n",
      "1383 -> Loss: 0.2919809818267822\n",
      "1384 -> Loss: 0.4531176686286926\n",
      "1385 -> Loss: 0.639790415763855\n",
      "1386 -> Loss: 0.515474259853363\n",
      "1387 -> Loss: 0.4152468740940094\n",
      "1388 -> Loss: 0.39475637674331665\n",
      "1389 -> Loss: 0.7838091850280762\n",
      "1390 -> Loss: 0.7840791344642639\n",
      "1391 -> Loss: 0.4130392074584961\n",
      "1392 -> Loss: 0.2022533118724823\n",
      "1393 -> Loss: 0.34632742404937744\n",
      "1394 -> Loss: 0.24991393089294434\n",
      "1395 -> Loss: 0.5827695727348328\n",
      "1396 -> Loss: 0.3935275673866272\n",
      "1397 -> Loss: 0.5826244950294495\n",
      "1398 -> Loss: 0.47157561779022217\n",
      "1399 -> Loss: 0.15672802925109863\n",
      "1400 -> Loss: 0.36177924275398254\n",
      "1401 -> Loss: 0.6730841994285583\n",
      "1402 -> Loss: 0.4412791132926941\n",
      "1403 -> Loss: 0.42513060569763184\n",
      "1404 -> Loss: 0.8582298159599304\n",
      "1405 -> Loss: 0.5828101634979248\n",
      "1406 -> Loss: 0.8123192191123962\n",
      "1407 -> Loss: 0.2762542963027954\n",
      "1408 -> Loss: 0.48751217126846313\n",
      "1409 -> Loss: 0.5698000192642212\n",
      "1410 -> Loss: 0.20130780339241028\n",
      "1411 -> Loss: 0.3692503571510315\n",
      "1412 -> Loss: 0.3220357298851013\n",
      "1413 -> Loss: 0.7824867963790894\n",
      "1414 -> Loss: 0.5444493293762207\n",
      "1415 -> Loss: 0.31674131751060486\n",
      "1416 -> Loss: 0.1230693832039833\n",
      "1417 -> Loss: 0.5793823003768921\n",
      "1418 -> Loss: 1.006883144378662\n",
      "1419 -> Loss: 0.5055568814277649\n",
      "1420 -> Loss: 0.5558564066886902\n",
      "1421 -> Loss: 0.33264145255088806\n",
      "1422 -> Loss: 0.4201917052268982\n",
      "1423 -> Loss: 0.40436774492263794\n",
      "1424 -> Loss: 0.8459787368774414\n",
      "1425 -> Loss: 0.711354672908783\n",
      "1426 -> Loss: 0.19979310035705566\n",
      "1427 -> Loss: 0.3668558597564697\n",
      "1428 -> Loss: 0.7896449565887451\n",
      "1429 -> Loss: 0.5062115788459778\n",
      "1430 -> Loss: 0.39033403992652893\n",
      "1431 -> Loss: 0.26655641198158264\n",
      "1432 -> Loss: 0.6639426350593567\n",
      "1433 -> Loss: 0.9784060716629028\n",
      "1434 -> Loss: 0.6567327380180359\n",
      "1435 -> Loss: 0.7375669479370117\n",
      "1436 -> Loss: 0.35415396094322205\n",
      "1437 -> Loss: 0.5890986919403076\n",
      "1438 -> Loss: 0.9024566411972046\n",
      "1439 -> Loss: 0.43412110209465027\n",
      "1440 -> Loss: 0.2236248403787613\n",
      "1441 -> Loss: 0.5667247772216797\n",
      "1442 -> Loss: 0.3458782434463501\n",
      "1443 -> Loss: 0.2404412478208542\n",
      "1444 -> Loss: 0.8769584894180298\n",
      "1445 -> Loss: 0.545609176158905\n",
      "1446 -> Loss: 0.32252347469329834\n",
      "1447 -> Loss: 0.4355085492134094\n",
      "1448 -> Loss: 0.5724553465843201\n",
      "1449 -> Loss: 0.8777598738670349\n",
      "1450 -> Loss: 0.22638832032680511\n",
      "1451 -> Loss: 0.12274634838104248\n",
      "1452 -> Loss: 0.46118658781051636\n",
      "1453 -> Loss: 0.8027340173721313\n",
      "1454 -> Loss: 0.45653510093688965\n",
      "1455 -> Loss: 0.7696512937545776\n",
      "1456 -> Loss: 0.7081677913665771\n",
      "1457 -> Loss: 0.5651816129684448\n",
      "1458 -> Loss: 0.9535836577415466\n",
      "1459 -> Loss: 0.3280993700027466\n",
      "1460 -> Loss: 0.4127577245235443\n",
      "1461 -> Loss: 0.6143072843551636\n",
      "1462 -> Loss: 0.41659873723983765\n",
      "1463 -> Loss: 0.29428383708000183\n",
      "1464 -> Loss: 0.2798902094364166\n",
      "1465 -> Loss: 0.24362477660179138\n",
      "1466 -> Loss: 0.3615530729293823\n",
      "1467 -> Loss: 1.1445010900497437\n",
      "1468 -> Loss: 0.33255502581596375\n",
      "1469 -> Loss: 0.6797795295715332\n",
      "1470 -> Loss: 0.18155696988105774\n",
      "1471 -> Loss: 0.7357810735702515\n",
      "1472 -> Loss: 0.31564104557037354\n",
      "1473 -> Loss: 0.5735563635826111\n",
      "1474 -> Loss: 0.21705524623394012\n",
      "1475 -> Loss: 0.26531630754470825\n",
      "1476 -> Loss: 0.6621063351631165\n",
      "1477 -> Loss: 0.2202720046043396\n",
      "1478 -> Loss: 0.7154825925827026\n",
      "1479 -> Loss: 0.5167296528816223\n",
      "1480 -> Loss: 0.579961895942688\n",
      "1481 -> Loss: 0.4248839318752289\n",
      "1482 -> Loss: 0.19907435774803162\n",
      "1483 -> Loss: 0.4262213408946991\n",
      "1484 -> Loss: 0.7690959572792053\n",
      "1485 -> Loss: 0.41361185908317566\n",
      "1486 -> Loss: 0.3987622857093811\n",
      "1487 -> Loss: 0.23774966597557068\n",
      "1488 -> Loss: 0.290783166885376\n",
      "1489 -> Loss: 0.18561942875385284\n",
      "1490 -> Loss: 0.8741136789321899\n",
      "1491 -> Loss: 0.5149396657943726\n",
      "1492 -> Loss: 0.4928438365459442\n",
      "1493 -> Loss: 0.4661464989185333\n",
      "1494 -> Loss: 0.49850764870643616\n",
      "1495 -> Loss: 0.20461133122444153\n",
      "1496 -> Loss: 0.5385916233062744\n",
      "1497 -> Loss: 0.801406741142273\n",
      "1498 -> Loss: 0.3892110586166382\n",
      "1499 -> Loss: 0.37392985820770264\n",
      "1500 -> Loss: 0.6651284694671631\n",
      "1501 -> Loss: 0.34535375237464905\n",
      "1502 -> Loss: 1.030994176864624\n",
      "1503 -> Loss: 0.9379922151565552\n",
      "1504 -> Loss: 1.6699928045272827\n",
      "1505 -> Loss: 0.7598963975906372\n",
      "1506 -> Loss: 0.2575249671936035\n",
      "1507 -> Loss: 0.3882408142089844\n",
      "1508 -> Loss: 0.0929778441786766\n",
      "1509 -> Loss: 0.4198296070098877\n",
      "1510 -> Loss: 0.6854869723320007\n",
      "1511 -> Loss: 0.5207697749137878\n",
      "1512 -> Loss: 0.5213764309883118\n",
      "1513 -> Loss: 0.3317871391773224\n",
      "1514 -> Loss: 0.39599624276161194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1515 -> Loss: 0.4128221869468689\n",
      "1516 -> Loss: 0.3100527226924896\n",
      "1517 -> Loss: 0.3835766911506653\n",
      "1518 -> Loss: 0.3094867467880249\n",
      "1519 -> Loss: 0.7600144147872925\n",
      "1520 -> Loss: 0.6223241090774536\n",
      "1521 -> Loss: 0.28757399320602417\n",
      "1522 -> Loss: 0.27379336953163147\n",
      "1523 -> Loss: 0.71135014295578\n",
      "1524 -> Loss: 0.2654394805431366\n",
      "1525 -> Loss: 0.1395794302225113\n",
      "1526 -> Loss: 0.7617769837379456\n",
      "1527 -> Loss: 0.46322715282440186\n",
      "1528 -> Loss: 0.5118148326873779\n",
      "1529 -> Loss: 0.26710593700408936\n",
      "1530 -> Loss: 0.45770829916000366\n",
      "1531 -> Loss: 0.46733373403549194\n",
      "1532 -> Loss: 0.16879218816757202\n",
      "1533 -> Loss: 0.09633130580186844\n",
      "1534 -> Loss: 0.5497941970825195\n",
      "1535 -> Loss: 0.4812707006931305\n",
      "1536 -> Loss: 0.7690078616142273\n",
      "1537 -> Loss: 0.18623501062393188\n",
      "1538 -> Loss: 0.219236820936203\n",
      "1539 -> Loss: 0.22053927183151245\n",
      "1540 -> Loss: 0.12661543488502502\n",
      "1541 -> Loss: 0.4444517195224762\n",
      "1542 -> Loss: 0.5830420255661011\n",
      "1543 -> Loss: 0.42833131551742554\n",
      "1544 -> Loss: 0.14887996017932892\n",
      "1545 -> Loss: 0.8039952516555786\n",
      "1546 -> Loss: 0.22683988511562347\n",
      "1547 -> Loss: 0.6160235404968262\n",
      "1548 -> Loss: 0.49681857228279114\n",
      "1549 -> Loss: 0.5891028642654419\n",
      "1550 -> Loss: 0.2152058482170105\n",
      "1551 -> Loss: 0.3418619930744171\n",
      "1552 -> Loss: 0.19795715808868408\n",
      "1553 -> Loss: 0.619093656539917\n",
      "1554 -> Loss: 0.5246710181236267\n",
      "1555 -> Loss: 0.6805117130279541\n",
      "1556 -> Loss: 0.11716651171445847\n",
      "1557 -> Loss: 0.359219491481781\n",
      "1558 -> Loss: 0.15485794842243195\n",
      "1559 -> Loss: 0.39004987478256226\n",
      "1560 -> Loss: 0.16901768743991852\n",
      "1561 -> Loss: 0.4835944175720215\n",
      "1562 -> Loss: 0.3266178071498871\n",
      "1563 -> Loss: 0.4193710386753082\n",
      "1564 -> Loss: 0.4795910716056824\n",
      "1565 -> Loss: 0.39893490076065063\n",
      "1566 -> Loss: 0.4380689561367035\n",
      "1567 -> Loss: 0.48157790303230286\n",
      "1568 -> Loss: 1.0711778402328491\n",
      "1569 -> Loss: 0.3811945915222168\n",
      "1570 -> Loss: 1.657321810722351\n",
      "1571 -> Loss: 0.521538496017456\n",
      "1572 -> Loss: 0.4935368597507477\n",
      "1573 -> Loss: 0.21762169897556305\n",
      "1574 -> Loss: 0.28327763080596924\n",
      "1575 -> Loss: 0.1485186368227005\n",
      "1576 -> Loss: 0.40160253643989563\n",
      "1577 -> Loss: 0.42249158024787903\n",
      "1578 -> Loss: 0.26802942156791687\n",
      "1579 -> Loss: 0.6946694254875183\n",
      "1580 -> Loss: 0.3654794991016388\n",
      "1581 -> Loss: 0.8864734172821045\n",
      "1582 -> Loss: 0.595418393611908\n",
      "1583 -> Loss: 0.14758560061454773\n",
      "1584 -> Loss: 0.25926145911216736\n",
      "1585 -> Loss: 0.27904319763183594\n",
      "1586 -> Loss: 0.7535887956619263\n",
      "1587 -> Loss: 0.18895843625068665\n",
      "1588 -> Loss: 0.5683324933052063\n",
      "1589 -> Loss: 0.13715410232543945\n",
      "1590 -> Loss: 0.35582807660102844\n",
      "1591 -> Loss: 0.5427257418632507\n",
      "1592 -> Loss: 0.31583428382873535\n",
      "1593 -> Loss: 0.7676166892051697\n",
      "1594 -> Loss: 0.5911265015602112\n",
      "1595 -> Loss: 0.2179350107908249\n",
      "1596 -> Loss: 0.5907392501831055\n",
      "1597 -> Loss: 0.36709654331207275\n",
      "1598 -> Loss: 0.19684213399887085\n",
      "1599 -> Loss: 0.47631266713142395\n",
      "1600 -> Loss: 0.26434165239334106\n",
      "1601 -> Loss: 0.40812867879867554\n",
      "1602 -> Loss: 0.7903765439987183\n",
      "1603 -> Loss: 0.4502840042114258\n",
      "1604 -> Loss: 0.2042524665594101\n",
      "1605 -> Loss: 0.47403860092163086\n",
      "1606 -> Loss: 0.5567872524261475\n",
      "1607 -> Loss: 0.32766976952552795\n",
      "1608 -> Loss: 0.6280503273010254\n",
      "1609 -> Loss: 0.4738110303878784\n",
      "1610 -> Loss: 0.6513381004333496\n",
      "1611 -> Loss: 0.1853850781917572\n",
      "1612 -> Loss: 0.3587735891342163\n",
      "1613 -> Loss: 0.6810239553451538\n",
      "1614 -> Loss: 0.2555369734764099\n",
      "1615 -> Loss: 0.3106950521469116\n",
      "1616 -> Loss: 0.49344226717948914\n",
      "1617 -> Loss: 0.8944863677024841\n",
      "1618 -> Loss: 0.2587868869304657\n",
      "1619 -> Loss: 0.7571708559989929\n",
      "1620 -> Loss: 0.37378811836242676\n",
      "1621 -> Loss: 0.5516746640205383\n",
      "1622 -> Loss: 0.35468795895576477\n",
      "1623 -> Loss: 0.7365014553070068\n",
      "1624 -> Loss: 0.3595295548439026\n",
      "1625 -> Loss: 0.24629153311252594\n",
      "1626 -> Loss: 0.5974000692367554\n",
      "1627 -> Loss: 0.31238749623298645\n",
      "1628 -> Loss: 0.6185390949249268\n",
      "1629 -> Loss: 0.14522747695446014\n",
      "1630 -> Loss: 0.3580531179904938\n",
      "1631 -> Loss: 0.5310340523719788\n",
      "1632 -> Loss: 0.6016222834587097\n",
      "1633 -> Loss: 0.5693210363388062\n",
      "1634 -> Loss: 0.1859503835439682\n",
      "1635 -> Loss: 0.301521360874176\n",
      "1636 -> Loss: 0.6249328255653381\n",
      "1637 -> Loss: 0.6460782289505005\n",
      "1638 -> Loss: 0.7987488508224487\n",
      "1639 -> Loss: 0.6910465955734253\n",
      "1640 -> Loss: 0.49042603373527527\n",
      "1641 -> Loss: 1.145274043083191\n",
      "1642 -> Loss: 0.5530660152435303\n",
      "1643 -> Loss: 0.3865816593170166\n",
      "1644 -> Loss: 0.258151650428772\n",
      "1645 -> Loss: 0.5957576036453247\n",
      "1646 -> Loss: 0.5255738496780396\n",
      "1647 -> Loss: 0.45882925391197205\n",
      "1648 -> Loss: 0.6013398766517639\n",
      "1649 -> Loss: 0.25226953625679016\n",
      "1650 -> Loss: 0.6430051922798157\n",
      "1651 -> Loss: 0.36222052574157715\n",
      "1652 -> Loss: 0.37355878949165344\n",
      "1653 -> Loss: 0.25456875562667847\n",
      "1654 -> Loss: 0.7091872096061707\n",
      "1655 -> Loss: 0.4764343500137329\n",
      "1656 -> Loss: 0.2650358974933624\n",
      "1657 -> Loss: 0.4152297377586365\n",
      "1658 -> Loss: 0.5149610042572021\n",
      "1659 -> Loss: 0.33212682604789734\n",
      "1660 -> Loss: 0.553285539150238\n",
      "1661 -> Loss: 0.25969016551971436\n",
      "1662 -> Loss: 0.23969078063964844\n",
      "1663 -> Loss: 0.418361634016037\n",
      "1664 -> Loss: 0.5980609059333801\n",
      "1665 -> Loss: 0.531757116317749\n",
      "1666 -> Loss: 0.7452282309532166\n",
      "1667 -> Loss: 0.21972788870334625\n",
      "1668 -> Loss: 0.3264990746974945\n",
      "1669 -> Loss: 0.25966310501098633\n",
      "1670 -> Loss: 0.6790530681610107\n",
      "1671 -> Loss: 0.41172951459884644\n",
      "1672 -> Loss: 0.3235517144203186\n",
      "1673 -> Loss: 0.3847394287586212\n",
      "1674 -> Loss: 0.8897234797477722\n",
      "1675 -> Loss: 0.884782612323761\n",
      "1676 -> Loss: 0.3771876394748688\n",
      "1677 -> Loss: 0.15786796808242798\n",
      "1678 -> Loss: 0.5271424055099487\n",
      "1679 -> Loss: 0.4648194909095764\n",
      "1680 -> Loss: 0.31014519929885864\n",
      "1681 -> Loss: 0.9029632806777954\n",
      "1682 -> Loss: 0.6829246282577515\n",
      "1683 -> Loss: 0.44258931279182434\n",
      "1684 -> Loss: 0.19140580296516418\n",
      "1685 -> Loss: 0.610161542892456\n",
      "1686 -> Loss: 0.5724635720252991\n",
      "1687 -> Loss: 0.5272626280784607\n",
      "1688 -> Loss: 1.0750558376312256\n",
      "1689 -> Loss: 0.5768907070159912\n",
      "1690 -> Loss: 0.43182462453842163\n",
      "1691 -> Loss: 1.0793930292129517\n",
      "1692 -> Loss: 0.6106184720993042\n",
      "1693 -> Loss: 0.18102876842021942\n",
      "1694 -> Loss: 0.7548267841339111\n",
      "1695 -> Loss: 0.2511975169181824\n",
      "1696 -> Loss: 0.11053316295146942\n",
      "1697 -> Loss: 0.4136961102485657\n",
      "1698 -> Loss: 0.621638298034668\n",
      "1699 -> Loss: 0.38439807295799255\n",
      "1700 -> Loss: 0.477489709854126\n",
      "1701 -> Loss: 0.6759869456291199\n",
      "1702 -> Loss: 0.6322307586669922\n",
      "1703 -> Loss: 0.35526013374328613\n",
      "1704 -> Loss: 0.40047553181648254\n",
      "1705 -> Loss: 0.11027711629867554\n",
      "1706 -> Loss: 0.6588664650917053\n",
      "1707 -> Loss: 0.49984633922576904\n",
      "1708 -> Loss: 0.35634446144104004\n",
      "1709 -> Loss: 0.7189869284629822\n",
      "1710 -> Loss: 0.7264793515205383\n",
      "1711 -> Loss: 0.22053401172161102\n",
      "1712 -> Loss: 0.2704858183860779\n",
      "1713 -> Loss: 0.6642352342605591\n",
      "1714 -> Loss: 0.19012215733528137\n",
      "1715 -> Loss: 0.2073356658220291\n",
      "1716 -> Loss: 0.6689006090164185\n",
      "1717 -> Loss: 0.48292821645736694\n",
      "1718 -> Loss: 0.8796908259391785\n",
      "1719 -> Loss: 0.3576059639453888\n",
      "1720 -> Loss: 0.6696297526359558\n",
      "1721 -> Loss: 0.38080835342407227\n",
      "1722 -> Loss: 0.5441724061965942\n",
      "1723 -> Loss: 0.48314881324768066\n",
      "1724 -> Loss: 0.8286150097846985\n",
      "1725 -> Loss: 0.6236215829849243\n",
      "1726 -> Loss: 0.8686230182647705\n",
      "1727 -> Loss: 0.2881605327129364\n",
      "1728 -> Loss: 0.3416082561016083\n",
      "1729 -> Loss: 0.15348877012729645\n",
      "1730 -> Loss: 0.4344708025455475\n",
      "1731 -> Loss: 0.5978906750679016\n",
      "1732 -> Loss: 0.13702572882175446\n",
      "1733 -> Loss: 0.4860115051269531\n",
      "1734 -> Loss: 0.2951931953430176\n",
      "1735 -> Loss: 0.34439703822135925\n",
      "1736 -> Loss: 0.48225870728492737\n",
      "1737 -> Loss: 0.3047116994857788\n",
      "1738 -> Loss: 0.3517493009567261\n",
      "1739 -> Loss: 0.6847264766693115\n",
      "1740 -> Loss: 0.5243229269981384\n",
      "1741 -> Loss: 0.286556214094162\n",
      "1742 -> Loss: 0.18096952140331268\n",
      "1743 -> Loss: 0.42445841431617737\n",
      "1744 -> Loss: 0.48129546642303467\n",
      "1745 -> Loss: 0.8919526934623718\n",
      "1746 -> Loss: 0.597962498664856\n",
      "1747 -> Loss: 0.2940196096897125\n",
      "1748 -> Loss: 0.6015342473983765\n",
      "1749 -> Loss: 0.6049288511276245\n",
      "1750 -> Loss: 0.508267343044281\n",
      "1751 -> Loss: 0.3095102608203888\n",
      "1752 -> Loss: 0.3082103729248047\n",
      "1753 -> Loss: 0.5098521113395691\n",
      "1754 -> Loss: 0.20562762022018433\n",
      "1755 -> Loss: 0.45057976245880127\n",
      "1756 -> Loss: 0.43279555439949036\n",
      "1757 -> Loss: 0.44754502177238464\n",
      "1758 -> Loss: 0.12907534837722778\n",
      "1759 -> Loss: 0.30635443329811096\n",
      "1760 -> Loss: 0.1697208285331726\n",
      "1761 -> Loss: 0.8624979853630066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1762 -> Loss: 0.7224410176277161\n",
      "1763 -> Loss: 0.4359722137451172\n",
      "1764 -> Loss: 0.5263280868530273\n",
      "1765 -> Loss: 0.1656692773103714\n",
      "1766 -> Loss: 0.5483464002609253\n",
      "1767 -> Loss: 0.4483884871006012\n",
      "1768 -> Loss: 0.15624430775642395\n",
      "1769 -> Loss: 0.32391566038131714\n",
      "1770 -> Loss: 0.2612667679786682\n",
      "1771 -> Loss: 0.3677468001842499\n",
      "1772 -> Loss: 0.5689023733139038\n",
      "1773 -> Loss: 0.1978551596403122\n",
      "1774 -> Loss: 0.40585091710090637\n",
      "1775 -> Loss: 0.6440900564193726\n",
      "1776 -> Loss: 0.6246020793914795\n",
      "1777 -> Loss: 0.4571179449558258\n",
      "1778 -> Loss: 0.6552560329437256\n",
      "1779 -> Loss: 1.0301792621612549\n",
      "1780 -> Loss: 0.28834250569343567\n",
      "1781 -> Loss: 0.8422187566757202\n",
      "1782 -> Loss: 0.4712551534175873\n",
      "1783 -> Loss: 0.4825180768966675\n",
      "1784 -> Loss: 0.805219292640686\n",
      "1785 -> Loss: 0.35316893458366394\n",
      "1786 -> Loss: 0.4764402210712433\n",
      "1787 -> Loss: 0.4076770544052124\n",
      "1788 -> Loss: 0.6315345764160156\n",
      "1789 -> Loss: 0.4098452031612396\n",
      "1790 -> Loss: 0.823925793170929\n",
      "1791 -> Loss: 0.3200361728668213\n",
      "1792 -> Loss: 0.3407011032104492\n",
      "1793 -> Loss: 0.4709602892398834\n",
      "1794 -> Loss: 0.7125481367111206\n",
      "1795 -> Loss: 0.36238643527030945\n",
      "1796 -> Loss: 1.320709466934204\n",
      "1797 -> Loss: 0.4754648506641388\n",
      "1798 -> Loss: 0.1901213675737381\n",
      "1799 -> Loss: 0.31123530864715576\n",
      "1800 -> Loss: 0.15964315831661224\n",
      "1801 -> Loss: 0.19766512513160706\n",
      "1802 -> Loss: 1.3878700733184814\n",
      "1803 -> Loss: 0.5864623785018921\n",
      "1804 -> Loss: 0.2993391454219818\n",
      "1805 -> Loss: 0.43887320160865784\n",
      "1806 -> Loss: 0.6611435413360596\n",
      "1807 -> Loss: 0.8234055638313293\n",
      "1808 -> Loss: 0.5019800662994385\n",
      "1809 -> Loss: 0.5432518124580383\n",
      "1810 -> Loss: 0.7383499145507812\n",
      "1811 -> Loss: 0.7519355416297913\n",
      "1812 -> Loss: 0.5907152891159058\n",
      "1813 -> Loss: 0.3357771337032318\n",
      "1814 -> Loss: 0.4416712522506714\n",
      "1815 -> Loss: 0.5872853398323059\n",
      "1816 -> Loss: 0.11139896512031555\n",
      "1817 -> Loss: 0.4069604277610779\n",
      "1818 -> Loss: 0.5783039331436157\n",
      "1819 -> Loss: 0.19748155772686005\n",
      "1820 -> Loss: 0.455724835395813\n",
      "1821 -> Loss: 0.39618945121765137\n",
      "1822 -> Loss: 0.8197588324546814\n",
      "1823 -> Loss: 0.646655797958374\n",
      "1824 -> Loss: 0.9187889695167542\n",
      "1825 -> Loss: 0.830285906791687\n",
      "1826 -> Loss: 0.472531795501709\n",
      "1827 -> Loss: 0.5798754096031189\n",
      "1828 -> Loss: 0.6357558369636536\n",
      "1829 -> Loss: 0.559227705001831\n",
      "1830 -> Loss: 0.31905707716941833\n",
      "1831 -> Loss: 0.46045610308647156\n",
      "1832 -> Loss: 0.47138550877571106\n",
      "1833 -> Loss: 0.27356404066085815\n",
      "1834 -> Loss: 0.8721243739128113\n",
      "1835 -> Loss: 0.5513867139816284\n",
      "1836 -> Loss: 0.21899238228797913\n",
      "1837 -> Loss: 0.43237951397895813\n",
      "1838 -> Loss: 0.49996519088745117\n",
      "1839 -> Loss: 0.5206655263900757\n",
      "1840 -> Loss: 0.20449315011501312\n",
      "1841 -> Loss: 0.6376299262046814\n",
      "1842 -> Loss: 0.8295166492462158\n",
      "1843 -> Loss: 0.49523088335990906\n",
      "1844 -> Loss: 0.5940806865692139\n",
      "1845 -> Loss: 0.04091581702232361\n",
      "1846 -> Loss: 0.3717421293258667\n",
      "1847 -> Loss: 0.5576668381690979\n",
      "1848 -> Loss: 0.4018652141094208\n",
      "1849 -> Loss: 0.7052686810493469\n",
      "1850 -> Loss: 0.37494388222694397\n",
      "1851 -> Loss: 0.8245181441307068\n",
      "1852 -> Loss: 0.3813909590244293\n",
      "1853 -> Loss: 0.3538748621940613\n",
      "1854 -> Loss: 0.35710012912750244\n",
      "1855 -> Loss: 0.397682785987854\n",
      "1856 -> Loss: 0.4473769962787628\n",
      "1857 -> Loss: 0.32840681076049805\n",
      "1858 -> Loss: 0.659153938293457\n",
      "1859 -> Loss: 0.3563202917575836\n",
      "1860 -> Loss: 0.4883493185043335\n",
      "1861 -> Loss: 0.8892729878425598\n",
      "1862 -> Loss: 0.601207971572876\n",
      "1863 -> Loss: 0.7662860751152039\n",
      "1864 -> Loss: 0.46129995584487915\n",
      "1865 -> Loss: 0.6981467008590698\n",
      "1866 -> Loss: 0.41081833839416504\n",
      "1867 -> Loss: 0.4420537054538727\n",
      "1868 -> Loss: 0.8257012963294983\n",
      "1869 -> Loss: 0.594713568687439\n",
      "1870 -> Loss: 0.43089067935943604\n",
      "1871 -> Loss: 0.11372788995504379\n",
      "1872 -> Loss: 0.3371560573577881\n",
      "1873 -> Loss: 0.12592723965644836\n",
      "1874 -> Loss: 0.1975439190864563\n",
      "1875 -> Loss: 0.8025507926940918\n",
      "1876 -> Loss: 0.3958406150341034\n",
      "1877 -> Loss: 0.3377927839756012\n",
      "1878 -> Loss: 0.6371705532073975\n",
      "1879 -> Loss: 0.19947202503681183\n",
      "1880 -> Loss: 0.5955030918121338\n",
      "1881 -> Loss: 0.29905179142951965\n",
      "1882 -> Loss: 0.1919812709093094\n",
      "1883 -> Loss: 0.1498730331659317\n",
      "1884 -> Loss: 0.7057206034660339\n",
      "1885 -> Loss: 0.20894384384155273\n",
      "1886 -> Loss: 0.3775719404220581\n",
      "1887 -> Loss: 0.38941124081611633\n",
      "1888 -> Loss: 0.39659082889556885\n",
      "1889 -> Loss: 0.5376198291778564\n",
      "1890 -> Loss: 0.591889500617981\n",
      "1891 -> Loss: 0.46075835824012756\n",
      "1892 -> Loss: 0.5023220777511597\n",
      "1893 -> Loss: 0.64388507604599\n",
      "1894 -> Loss: 0.5401632785797119\n",
      "1895 -> Loss: 0.6502740383148193\n",
      "1896 -> Loss: 0.3573310375213623\n",
      "1897 -> Loss: 0.6727122068405151\n",
      "1898 -> Loss: 0.32587945461273193\n",
      "1899 -> Loss: 0.4483065605163574\n",
      "1900 -> Loss: 0.46542271971702576\n",
      "1901 -> Loss: 0.45499151945114136\n",
      "1902 -> Loss: 0.2879585027694702\n",
      "1903 -> Loss: 0.38942253589630127\n",
      "1904 -> Loss: 0.666508674621582\n",
      "1905 -> Loss: 0.3953936994075775\n",
      "1906 -> Loss: 0.6265885829925537\n",
      "1907 -> Loss: 0.3787708878517151\n",
      "1908 -> Loss: 0.7869144678115845\n",
      "1909 -> Loss: 0.553676426410675\n",
      "1910 -> Loss: 0.44815099239349365\n",
      "1911 -> Loss: 0.7564710974693298\n",
      "1912 -> Loss: 0.5134258270263672\n",
      "1913 -> Loss: 0.15043407678604126\n",
      "1914 -> Loss: 0.24484004080295563\n",
      "1915 -> Loss: 0.8039343953132629\n",
      "1916 -> Loss: 0.5742720365524292\n",
      "1917 -> Loss: 0.6121197938919067\n",
      "1918 -> Loss: 0.34549808502197266\n",
      "1919 -> Loss: 0.2855393588542938\n",
      "1920 -> Loss: 0.5753834843635559\n",
      "1921 -> Loss: 0.2528996765613556\n",
      "1922 -> Loss: 0.4876294732093811\n",
      "1923 -> Loss: 0.5282817482948303\n",
      "1924 -> Loss: 0.5120869278907776\n",
      "1925 -> Loss: 0.5043800473213196\n",
      "1926 -> Loss: 0.32488951086997986\n",
      "1927 -> Loss: 0.5732208490371704\n",
      "1928 -> Loss: 0.551771342754364\n",
      "1929 -> Loss: 0.8711015582084656\n",
      "1930 -> Loss: 0.25820812582969666\n",
      "1931 -> Loss: 0.532970130443573\n",
      "1932 -> Loss: 0.40254953503608704\n",
      "1933 -> Loss: 0.5459915995597839\n",
      "1934 -> Loss: 0.5306496620178223\n",
      "1935 -> Loss: 0.4333287477493286\n",
      "1936 -> Loss: 0.632151186466217\n",
      "1937 -> Loss: 0.24922499060630798\n",
      "1938 -> Loss: 0.3813491761684418\n",
      "1939 -> Loss: 0.4902392029762268\n",
      "1940 -> Loss: 0.3428216278553009\n",
      "1941 -> Loss: 0.29357409477233887\n",
      "1942 -> Loss: 0.33332502841949463\n",
      "1943 -> Loss: 0.29323315620422363\n",
      "1944 -> Loss: 0.559224009513855\n",
      "1945 -> Loss: 0.17128193378448486\n",
      "1946 -> Loss: 0.3768789768218994\n",
      "1947 -> Loss: 0.4350428879261017\n",
      "1948 -> Loss: 0.31067657470703125\n",
      "1949 -> Loss: 0.558569610118866\n",
      "1950 -> Loss: 0.6859921813011169\n",
      "1951 -> Loss: 0.5307973027229309\n",
      "1952 -> Loss: 0.7040229439735413\n",
      "1953 -> Loss: 0.32344135642051697\n",
      "1954 -> Loss: 0.7724671363830566\n",
      "1955 -> Loss: 0.08782045543193817\n",
      "1956 -> Loss: 0.4235828220844269\n",
      "1957 -> Loss: 0.7695066928863525\n",
      "1958 -> Loss: 0.40238216519355774\n",
      "1959 -> Loss: 0.31774312257766724\n",
      "1960 -> Loss: 0.6874195337295532\n",
      "1961 -> Loss: 0.35907262563705444\n",
      "1962 -> Loss: 1.018202304840088\n",
      "1963 -> Loss: 0.1787387877702713\n",
      "1964 -> Loss: 0.24353532493114471\n",
      "1965 -> Loss: 0.3965536057949066\n",
      "1966 -> Loss: 0.4286770522594452\n",
      "1967 -> Loss: 0.38908833265304565\n",
      "1968 -> Loss: 0.3497667908668518\n",
      "1969 -> Loss: 0.12953463196754456\n",
      "1970 -> Loss: 0.4339822232723236\n",
      "1971 -> Loss: 0.5525286793708801\n",
      "1972 -> Loss: 0.37688887119293213\n",
      "1973 -> Loss: 0.2069619596004486\n",
      "1974 -> Loss: 0.3479061424732208\n",
      "1975 -> Loss: 0.2969028353691101\n",
      "1976 -> Loss: 0.7053586840629578\n",
      "1977 -> Loss: 0.386532723903656\n",
      "1978 -> Loss: 0.4767395257949829\n",
      "1979 -> Loss: 0.15049627423286438\n",
      "1980 -> Loss: 0.4781650900840759\n",
      "1981 -> Loss: 0.5461351275444031\n",
      "1982 -> Loss: 0.43064084649086\n",
      "1983 -> Loss: 0.3077155649662018\n",
      "1984 -> Loss: 0.3486282229423523\n",
      "1985 -> Loss: 0.18030335009098053\n",
      "1986 -> Loss: 0.4001730680465698\n",
      "1987 -> Loss: 0.7462710738182068\n",
      "1988 -> Loss: 0.5460504293441772\n",
      "1989 -> Loss: 0.6219812035560608\n",
      "1990 -> Loss: 0.5795007348060608\n",
      "1991 -> Loss: 0.11029514670372009\n",
      "1992 -> Loss: 0.8757171630859375\n",
      "1993 -> Loss: 0.3139997720718384\n",
      "1994 -> Loss: 0.9106112122535706\n",
      "1995 -> Loss: 1.048179030418396\n",
      "1996 -> Loss: 0.5037632584571838\n",
      "1997 -> Loss: 0.27195727825164795\n",
      "1998 -> Loss: 0.5096850991249084\n",
      "1999 -> Loss: 0.6672555208206177\n",
      "2000 -> Loss: 0.33286455273628235\n",
      "\n",
      "Validation Accuracy: 68.5, Test Accuracy: 73.5 \n",
      "\n",
      "2001 -> Loss: 0.4797031581401825\n",
      "2002 -> Loss: 0.49079519510269165\n",
      "2003 -> Loss: 0.3632500469684601\n",
      "2004 -> Loss: 0.41175180673599243\n",
      "2005 -> Loss: 0.6817834973335266\n",
      "2006 -> Loss: 0.8243072032928467\n",
      "2007 -> Loss: 0.47269853949546814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008 -> Loss: 0.4427875578403473\n",
      "2009 -> Loss: 0.3073482811450958\n",
      "2010 -> Loss: 0.18806962668895721\n",
      "2011 -> Loss: 0.6840811371803284\n",
      "2012 -> Loss: 0.4952585995197296\n",
      "2013 -> Loss: 0.8758946657180786\n",
      "2014 -> Loss: 0.17238108813762665\n",
      "2015 -> Loss: 0.8759961724281311\n",
      "2016 -> Loss: 0.6940659284591675\n",
      "2017 -> Loss: 0.44242367148399353\n",
      "2018 -> Loss: 0.34295615553855896\n",
      "2019 -> Loss: 0.4370356798171997\n",
      "2020 -> Loss: 0.10729019343852997\n",
      "2021 -> Loss: 0.9113518595695496\n",
      "2022 -> Loss: 0.4941244125366211\n",
      "2023 -> Loss: 0.34972083568573\n",
      "2024 -> Loss: 0.1880316287279129\n",
      "2025 -> Loss: 0.40662112832069397\n",
      "2026 -> Loss: 0.40659061074256897\n",
      "2027 -> Loss: 0.815680742263794\n",
      "2028 -> Loss: 0.6695623993873596\n",
      "2029 -> Loss: 0.558904767036438\n",
      "2030 -> Loss: 0.4200460910797119\n",
      "2031 -> Loss: 0.38119643926620483\n",
      "2032 -> Loss: 0.3801000416278839\n",
      "2033 -> Loss: 0.60248863697052\n",
      "2034 -> Loss: 0.3282269835472107\n",
      "2035 -> Loss: 0.5027815103530884\n",
      "2036 -> Loss: 0.31355011463165283\n",
      "2037 -> Loss: 0.20201252400875092\n",
      "2038 -> Loss: 0.34549862146377563\n",
      "2039 -> Loss: 0.25609180331230164\n",
      "2040 -> Loss: 0.475843608379364\n",
      "2041 -> Loss: 0.5496639013290405\n",
      "2042 -> Loss: 0.8275811076164246\n",
      "2043 -> Loss: 0.39236652851104736\n",
      "2044 -> Loss: 0.3123297691345215\n",
      "2045 -> Loss: 0.8540053367614746\n",
      "2046 -> Loss: 0.6032307744026184\n",
      "2047 -> Loss: 0.5816364288330078\n",
      "2048 -> Loss: 0.5192908048629761\n",
      "2049 -> Loss: 0.30707108974456787\n",
      "2050 -> Loss: 0.18474791944026947\n",
      "2051 -> Loss: 0.3992976248264313\n",
      "2052 -> Loss: 0.302228182554245\n",
      "2053 -> Loss: 0.45156383514404297\n",
      "2054 -> Loss: 0.4608193635940552\n",
      "2055 -> Loss: 0.33335503935813904\n",
      "2056 -> Loss: 0.4280599057674408\n",
      "2057 -> Loss: 0.7099266052246094\n",
      "2058 -> Loss: 0.16734746098518372\n",
      "2059 -> Loss: 0.7424960732460022\n",
      "2060 -> Loss: 0.9415022134780884\n",
      "2061 -> Loss: 0.12914344668388367\n",
      "2062 -> Loss: 0.8595382571220398\n",
      "2063 -> Loss: 0.4960935413837433\n",
      "2064 -> Loss: 0.6021808385848999\n",
      "2065 -> Loss: 0.5533000230789185\n",
      "2066 -> Loss: 0.8075087666511536\n",
      "2067 -> Loss: 0.6022490859031677\n",
      "2068 -> Loss: 0.3067338168621063\n",
      "2069 -> Loss: 0.617918848991394\n",
      "2070 -> Loss: 0.6175590753555298\n",
      "2071 -> Loss: 0.6850497126579285\n",
      "2072 -> Loss: 0.6940591335296631\n",
      "2073 -> Loss: 0.567404568195343\n",
      "2074 -> Loss: 0.25382402539253235\n",
      "2075 -> Loss: 0.5865566730499268\n",
      "2076 -> Loss: 0.6611818671226501\n",
      "2077 -> Loss: 0.5486897826194763\n",
      "2078 -> Loss: 0.18283501267433167\n",
      "2079 -> Loss: 0.443177193403244\n",
      "2080 -> Loss: 0.20308849215507507\n",
      "2081 -> Loss: 0.21991483867168427\n",
      "2082 -> Loss: 0.15271341800689697\n",
      "2083 -> Loss: 0.407077431678772\n",
      "2084 -> Loss: 0.2223864644765854\n",
      "2085 -> Loss: 0.34677639603614807\n",
      "2086 -> Loss: 1.049920678138733\n",
      "2087 -> Loss: 0.3315703570842743\n",
      "2088 -> Loss: 0.44632765650749207\n",
      "2089 -> Loss: 0.5379941463470459\n",
      "2090 -> Loss: 0.12044604122638702\n",
      "2091 -> Loss: 0.47102269530296326\n",
      "2092 -> Loss: 0.4955843389034271\n",
      "2093 -> Loss: 0.9839373826980591\n",
      "2094 -> Loss: 0.46679994463920593\n",
      "2095 -> Loss: 1.6343532800674438\n",
      "2096 -> Loss: 1.0196948051452637\n",
      "2097 -> Loss: 0.4361276626586914\n",
      "2098 -> Loss: 0.600371241569519\n",
      "2099 -> Loss: 0.7948535680770874\n",
      "2100 -> Loss: 0.5532162189483643\n",
      "2101 -> Loss: 0.7585812211036682\n",
      "2102 -> Loss: 0.5346553921699524\n",
      "2103 -> Loss: 0.48265063762664795\n",
      "2104 -> Loss: 0.5503383874893188\n",
      "2105 -> Loss: 0.7243217825889587\n",
      "2106 -> Loss: 0.35096579790115356\n",
      "2107 -> Loss: 0.23919795453548431\n",
      "2108 -> Loss: 0.5474227666854858\n",
      "2109 -> Loss: 0.5429509878158569\n",
      "2110 -> Loss: 0.3090001344680786\n",
      "2111 -> Loss: 0.7124917507171631\n",
      "2112 -> Loss: 0.6089168190956116\n",
      "2113 -> Loss: 1.109740138053894\n",
      "2114 -> Loss: 0.6957221031188965\n",
      "2115 -> Loss: 0.3025321960449219\n",
      "2116 -> Loss: 0.5602198243141174\n",
      "2117 -> Loss: 0.5647236704826355\n",
      "2118 -> Loss: 0.3730720281600952\n",
      "2119 -> Loss: 0.6758247017860413\n",
      "2120 -> Loss: 0.30354493856430054\n",
      "2121 -> Loss: 0.8253528475761414\n",
      "2122 -> Loss: 0.42035412788391113\n",
      "2123 -> Loss: 0.24648533761501312\n",
      "2124 -> Loss: 0.4252625107765198\n",
      "2125 -> Loss: 0.6585791110992432\n",
      "2126 -> Loss: 0.4454764723777771\n",
      "2127 -> Loss: 0.4311710298061371\n",
      "2128 -> Loss: 0.4830072522163391\n",
      "2129 -> Loss: 0.2894119918346405\n",
      "2130 -> Loss: 0.41051042079925537\n",
      "2131 -> Loss: 0.5218514800071716\n",
      "2132 -> Loss: 0.3209349811077118\n",
      "2133 -> Loss: 0.411117821931839\n",
      "2134 -> Loss: 0.5624346733093262\n",
      "2135 -> Loss: 0.46773430705070496\n",
      "2136 -> Loss: 0.49624231457710266\n",
      "2137 -> Loss: 0.5379585027694702\n",
      "2138 -> Loss: 0.5710755586624146\n",
      "2139 -> Loss: 0.45912447571754456\n",
      "2140 -> Loss: 0.3739972710609436\n",
      "2141 -> Loss: 0.29814213514328003\n",
      "2142 -> Loss: 0.32466378808021545\n",
      "2143 -> Loss: 0.19423891603946686\n",
      "2144 -> Loss: 0.3974948227405548\n",
      "2145 -> Loss: 0.6811180114746094\n",
      "2146 -> Loss: 0.6408618092536926\n",
      "2147 -> Loss: 0.16926555335521698\n",
      "2148 -> Loss: 0.7682214379310608\n",
      "2149 -> Loss: 0.5437847971916199\n",
      "2150 -> Loss: 0.5098305344581604\n",
      "2151 -> Loss: 0.8874080181121826\n",
      "2152 -> Loss: 0.20443758368492126\n",
      "2153 -> Loss: 0.7096917629241943\n",
      "2154 -> Loss: 0.4457590878009796\n",
      "2155 -> Loss: 0.7796667218208313\n",
      "2156 -> Loss: 0.5205663442611694\n",
      "2157 -> Loss: 0.550819993019104\n",
      "2158 -> Loss: 0.6014106273651123\n",
      "2159 -> Loss: 0.7099031805992126\n",
      "2160 -> Loss: 0.33897829055786133\n",
      "2161 -> Loss: 0.26341891288757324\n",
      "2162 -> Loss: 0.4859883785247803\n",
      "2163 -> Loss: 0.3778645396232605\n",
      "2164 -> Loss: 0.5557227730751038\n",
      "2165 -> Loss: 0.4054393470287323\n",
      "2166 -> Loss: 0.6781003475189209\n",
      "2167 -> Loss: 0.46183720231056213\n",
      "2168 -> Loss: 0.46014881134033203\n",
      "2169 -> Loss: 0.5051805973052979\n",
      "2170 -> Loss: 0.7039830684661865\n",
      "2171 -> Loss: 0.30400243401527405\n",
      "2172 -> Loss: 0.5446587800979614\n",
      "2173 -> Loss: 0.7875741124153137\n",
      "2174 -> Loss: 0.4653186500072479\n",
      "2175 -> Loss: 0.3833684027194977\n",
      "2176 -> Loss: 0.2076033055782318\n",
      "2177 -> Loss: 0.4352882206439972\n",
      "2178 -> Loss: 0.5156134366989136\n",
      "2179 -> Loss: 0.297964870929718\n",
      "2180 -> Loss: 0.7378398180007935\n",
      "2181 -> Loss: 0.8511548042297363\n",
      "2182 -> Loss: 0.4626823961734772\n",
      "2183 -> Loss: 0.9138845205307007\n",
      "2184 -> Loss: 0.45743328332901\n",
      "2185 -> Loss: 1.2899084091186523\n",
      "2186 -> Loss: 0.6091749668121338\n",
      "2187 -> Loss: 0.31399595737457275\n",
      "2188 -> Loss: 0.8548132181167603\n",
      "2189 -> Loss: 0.39834243059158325\n",
      "2190 -> Loss: 0.2833995521068573\n",
      "2191 -> Loss: 0.2665688395500183\n",
      "2192 -> Loss: 1.0844006538391113\n",
      "2193 -> Loss: 0.6339678168296814\n",
      "2194 -> Loss: 0.5674501657485962\n",
      "2195 -> Loss: 0.6277145743370056\n",
      "2196 -> Loss: 0.41121914982795715\n",
      "2197 -> Loss: 0.14778262376785278\n",
      "2198 -> Loss: 0.45001742243766785\n",
      "2199 -> Loss: 0.2438465803861618\n",
      "2200 -> Loss: 0.813969612121582\n",
      "2201 -> Loss: 1.0865306854248047\n",
      "2202 -> Loss: 0.4601304233074188\n",
      "2203 -> Loss: 0.27829837799072266\n",
      "2204 -> Loss: 0.1792386919260025\n",
      "2205 -> Loss: 0.6901370286941528\n",
      "2206 -> Loss: 0.3561428487300873\n",
      "2207 -> Loss: 0.11280229687690735\n",
      "2208 -> Loss: 0.558540940284729\n",
      "2209 -> Loss: 0.542004406452179\n",
      "2210 -> Loss: 0.38429659605026245\n",
      "2211 -> Loss: 0.8515825271606445\n",
      "2212 -> Loss: 0.41633883118629456\n",
      "2213 -> Loss: 0.1585617959499359\n",
      "2214 -> Loss: 0.4242516756057739\n",
      "2215 -> Loss: 0.9405121207237244\n",
      "2216 -> Loss: 0.620287299156189\n",
      "2217 -> Loss: 0.5050793290138245\n",
      "2218 -> Loss: 0.2623547315597534\n",
      "2219 -> Loss: 0.7211505174636841\n",
      "2220 -> Loss: 0.49711814522743225\n",
      "2221 -> Loss: 0.39313358068466187\n",
      "2222 -> Loss: 0.7530644536018372\n",
      "2223 -> Loss: 0.5414243340492249\n",
      "2224 -> Loss: 0.3125712275505066\n",
      "2225 -> Loss: 0.4319731891155243\n",
      "2226 -> Loss: 0.6298632025718689\n",
      "2227 -> Loss: 0.5196289420127869\n",
      "2228 -> Loss: 0.71294766664505\n",
      "2229 -> Loss: 0.20253995060920715\n",
      "2230 -> Loss: 0.3056468963623047\n",
      "2231 -> Loss: 0.41385552287101746\n",
      "2232 -> Loss: 0.714755654335022\n",
      "2233 -> Loss: 0.28231966495513916\n",
      "2234 -> Loss: 0.4204687476158142\n",
      "2235 -> Loss: 0.4064931869506836\n",
      "2236 -> Loss: 0.3746177554130554\n",
      "2237 -> Loss: 0.2749038338661194\n",
      "2238 -> Loss: 0.25229957699775696\n",
      "2239 -> Loss: 0.3540981411933899\n",
      "2240 -> Loss: 0.5366990566253662\n",
      "2241 -> Loss: 0.2520156502723694\n",
      "2242 -> Loss: 1.1095304489135742\n",
      "2243 -> Loss: 0.8429235816001892\n",
      "2244 -> Loss: 0.49046453833580017\n",
      "2245 -> Loss: 0.589240550994873\n",
      "2246 -> Loss: 0.1997968554496765\n",
      "2247 -> Loss: 0.12350363284349442\n",
      "2248 -> Loss: 0.7087819576263428\n",
      "2249 -> Loss: 1.0617787837982178\n",
      "2250 -> Loss: 0.17378315329551697\n",
      "2251 -> Loss: 0.6094631552696228\n",
      "2252 -> Loss: 0.4332481324672699\n",
      "2253 -> Loss: 0.7027227282524109\n",
      "2254 -> Loss: 0.3394588828086853\n",
      "2255 -> Loss: 0.6305112838745117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256 -> Loss: 0.17162398993968964\n",
      "2257 -> Loss: 0.4997127950191498\n",
      "2258 -> Loss: 0.2614096403121948\n",
      "2259 -> Loss: 0.6517490744590759\n",
      "2260 -> Loss: 0.351227343082428\n",
      "2261 -> Loss: 0.23863670229911804\n",
      "2262 -> Loss: 0.7055375576019287\n",
      "2263 -> Loss: 0.5678477883338928\n",
      "2264 -> Loss: 0.2729538679122925\n",
      "2265 -> Loss: 0.16993127763271332\n",
      "2266 -> Loss: 0.8860474824905396\n",
      "2267 -> Loss: 0.7084066271781921\n",
      "2268 -> Loss: 0.3576844036579132\n",
      "2269 -> Loss: 0.33120450377464294\n",
      "2270 -> Loss: 0.6124591827392578\n",
      "2271 -> Loss: 0.7007219195365906\n",
      "2272 -> Loss: 0.7044221758842468\n",
      "2273 -> Loss: 0.4011329114437103\n",
      "2274 -> Loss: 0.5105149745941162\n",
      "2275 -> Loss: 0.5226568579673767\n",
      "2276 -> Loss: 0.30591827630996704\n",
      "2277 -> Loss: 0.8432247042655945\n",
      "2278 -> Loss: 0.6145723462104797\n",
      "2279 -> Loss: 0.7241942882537842\n",
      "2280 -> Loss: 0.543178915977478\n",
      "2281 -> Loss: 0.39905861020088196\n",
      "2282 -> Loss: 0.37991437315940857\n",
      "2283 -> Loss: 0.17450794577598572\n",
      "2284 -> Loss: 0.8730781674385071\n",
      "2285 -> Loss: 0.3537532091140747\n",
      "2286 -> Loss: 0.40950170159339905\n",
      "2287 -> Loss: 0.2256953865289688\n",
      "2288 -> Loss: 0.2781897187232971\n",
      "2289 -> Loss: 0.6943081617355347\n",
      "2290 -> Loss: 0.8719235062599182\n",
      "2291 -> Loss: 0.45039618015289307\n",
      "2292 -> Loss: 0.26728555560112\n",
      "2293 -> Loss: 0.3056652545928955\n",
      "2294 -> Loss: 0.4178530275821686\n",
      "2295 -> Loss: 0.4895208477973938\n",
      "2296 -> Loss: 0.3451586663722992\n",
      "2297 -> Loss: 0.3691500723361969\n",
      "2298 -> Loss: 0.39252209663391113\n",
      "2299 -> Loss: 0.7296653389930725\n",
      "2300 -> Loss: 0.5786231756210327\n",
      "2301 -> Loss: 0.709784746170044\n",
      "2302 -> Loss: 0.7213875651359558\n",
      "2303 -> Loss: 0.4670103192329407\n",
      "2304 -> Loss: 0.7765310406684875\n",
      "2305 -> Loss: 0.4464946985244751\n",
      "2306 -> Loss: 0.6049321889877319\n",
      "2307 -> Loss: 0.42486587166786194\n",
      "2308 -> Loss: 0.1840028315782547\n",
      "2309 -> Loss: 0.4035203754901886\n",
      "2310 -> Loss: 0.7820258140563965\n",
      "2311 -> Loss: 0.513131856918335\n",
      "2312 -> Loss: 0.30699703097343445\n",
      "2313 -> Loss: 0.4531955122947693\n",
      "2314 -> Loss: 0.31777432560920715\n",
      "2315 -> Loss: 0.6468909382820129\n",
      "2316 -> Loss: 0.7489338517189026\n",
      "2317 -> Loss: 0.6775157451629639\n",
      "2318 -> Loss: 0.024456845596432686\n",
      "2319 -> Loss: 0.38706210255622864\n",
      "2320 -> Loss: 0.40406376123428345\n",
      "2321 -> Loss: 0.38455814123153687\n",
      "2322 -> Loss: 0.36707738041877747\n",
      "2323 -> Loss: 0.5597561597824097\n",
      "2324 -> Loss: 0.2714278995990753\n",
      "2325 -> Loss: 0.4945264160633087\n",
      "2326 -> Loss: 0.4581589102745056\n",
      "2327 -> Loss: 0.7547416090965271\n",
      "2328 -> Loss: 0.19706471264362335\n",
      "2329 -> Loss: 0.3214297592639923\n",
      "2330 -> Loss: 0.6680344939231873\n",
      "2331 -> Loss: 0.24444058537483215\n",
      "2332 -> Loss: 0.8505281209945679\n",
      "2333 -> Loss: 0.4505282938480377\n",
      "2334 -> Loss: 0.5564819574356079\n",
      "2335 -> Loss: 0.32340240478515625\n",
      "2336 -> Loss: 0.7033246755599976\n",
      "2337 -> Loss: 0.6641008853912354\n",
      "2338 -> Loss: 0.8990322351455688\n",
      "2339 -> Loss: 0.548322856426239\n",
      "2340 -> Loss: 0.5190902352333069\n",
      "2341 -> Loss: 0.7305182218551636\n",
      "2342 -> Loss: 0.1263870745897293\n",
      "2343 -> Loss: 0.7326297760009766\n",
      "2344 -> Loss: 0.4553079307079315\n",
      "2345 -> Loss: 0.26104363799095154\n",
      "2346 -> Loss: 0.3463543653488159\n",
      "2347 -> Loss: 0.48770225048065186\n",
      "2348 -> Loss: 0.33193960785865784\n",
      "2349 -> Loss: 0.5311427712440491\n",
      "2350 -> Loss: 0.292100191116333\n",
      "2351 -> Loss: 0.3493235409259796\n",
      "2352 -> Loss: 0.4249561131000519\n",
      "2353 -> Loss: 0.44134172797203064\n",
      "2354 -> Loss: 0.15822790563106537\n",
      "2355 -> Loss: 0.46558645367622375\n",
      "2356 -> Loss: 0.6326306462287903\n",
      "2357 -> Loss: 0.6649771928787231\n",
      "2358 -> Loss: 1.137385606765747\n",
      "2359 -> Loss: 0.6780291795730591\n",
      "2360 -> Loss: 0.8359395861625671\n",
      "2361 -> Loss: 0.7129104137420654\n",
      "2362 -> Loss: 0.339846670627594\n",
      "2363 -> Loss: 0.45352235436439514\n",
      "2364 -> Loss: 0.6823866963386536\n",
      "2365 -> Loss: 0.9347645044326782\n",
      "2366 -> Loss: 0.48840558528900146\n",
      "2367 -> Loss: 0.18929040431976318\n",
      "2368 -> Loss: 0.25383633375167847\n",
      "2369 -> Loss: 0.6728639602661133\n",
      "2370 -> Loss: 0.6523553133010864\n",
      "2371 -> Loss: 0.3065244257450104\n",
      "2372 -> Loss: 0.22484272718429565\n",
      "2373 -> Loss: 0.6851268410682678\n",
      "2374 -> Loss: 0.4373658299446106\n",
      "2375 -> Loss: 0.28562310338020325\n",
      "2376 -> Loss: 0.6388204097747803\n",
      "2377 -> Loss: 0.19409912824630737\n",
      "2378 -> Loss: 1.2642126083374023\n",
      "2379 -> Loss: 0.942038893699646\n",
      "2380 -> Loss: 0.3195309340953827\n",
      "2381 -> Loss: 0.3428725004196167\n",
      "2382 -> Loss: 0.7389415502548218\n",
      "2383 -> Loss: 0.5065832138061523\n",
      "2384 -> Loss: 0.6479590535163879\n",
      "2385 -> Loss: 0.8614258766174316\n",
      "2386 -> Loss: 0.6426466703414917\n",
      "2387 -> Loss: 0.8215257525444031\n",
      "2388 -> Loss: 0.4051024615764618\n",
      "2389 -> Loss: 0.9978371262550354\n",
      "2390 -> Loss: 0.6610962152481079\n",
      "2391 -> Loss: 0.1961175799369812\n",
      "2392 -> Loss: 0.6131585836410522\n",
      "2393 -> Loss: 0.26104655861854553\n",
      "2394 -> Loss: 0.3804589509963989\n",
      "2395 -> Loss: 0.24737222492694855\n",
      "2396 -> Loss: 0.23466506600379944\n",
      "2397 -> Loss: 0.41647064685821533\n",
      "2398 -> Loss: 0.7415952682495117\n",
      "2399 -> Loss: 0.35489800572395325\n",
      "2400 -> Loss: 0.11479269713163376\n",
      "2401 -> Loss: 0.31624650955200195\n",
      "2402 -> Loss: 0.9916605353355408\n",
      "2403 -> Loss: 0.7437484860420227\n",
      "2404 -> Loss: 0.5251322388648987\n",
      "2405 -> Loss: 0.4812193214893341\n",
      "2406 -> Loss: 0.4607888162136078\n",
      "2407 -> Loss: 0.4166930317878723\n",
      "2408 -> Loss: 0.8202075362205505\n",
      "2409 -> Loss: 0.4451988637447357\n",
      "2410 -> Loss: 0.8058983087539673\n",
      "2411 -> Loss: 0.4631590247154236\n",
      "2412 -> Loss: 0.4544534981250763\n",
      "2413 -> Loss: 0.6603078842163086\n",
      "2414 -> Loss: 0.5014503598213196\n",
      "2415 -> Loss: 0.3179001212120056\n",
      "2416 -> Loss: 0.3308509886264801\n",
      "2417 -> Loss: 1.4235055446624756\n",
      "2418 -> Loss: 0.608149528503418\n",
      "2419 -> Loss: 0.30100834369659424\n",
      "2420 -> Loss: 0.6404004096984863\n",
      "2421 -> Loss: 0.35392916202545166\n",
      "2422 -> Loss: 0.29321080446243286\n",
      "2423 -> Loss: 0.5323673486709595\n",
      "2424 -> Loss: 0.29314160346984863\n",
      "2425 -> Loss: 0.6027779579162598\n",
      "2426 -> Loss: 0.4174536466598511\n",
      "2427 -> Loss: 0.16464094817638397\n",
      "2428 -> Loss: 0.13245190680027008\n",
      "2429 -> Loss: 0.3747811019420624\n",
      "2430 -> Loss: 0.43877390027046204\n",
      "2431 -> Loss: 0.5720033049583435\n",
      "2432 -> Loss: 0.589798092842102\n",
      "2433 -> Loss: 0.3638949990272522\n",
      "2434 -> Loss: 0.17291778326034546\n",
      "2435 -> Loss: 0.4420732259750366\n",
      "2436 -> Loss: 0.15724334120750427\n",
      "2437 -> Loss: 0.4470844268798828\n",
      "2438 -> Loss: 0.18830007314682007\n",
      "2439 -> Loss: 0.9087532162666321\n",
      "2440 -> Loss: 0.400870144367218\n",
      "2441 -> Loss: 0.3189854323863983\n",
      "2442 -> Loss: 0.37822961807250977\n",
      "2443 -> Loss: 0.4095795452594757\n",
      "2444 -> Loss: 0.7158651351928711\n",
      "2445 -> Loss: 0.33603882789611816\n",
      "2446 -> Loss: 0.5331317186355591\n",
      "2447 -> Loss: 0.6156709790229797\n",
      "2448 -> Loss: 0.17759034037590027\n",
      "2449 -> Loss: 0.4299550950527191\n",
      "2450 -> Loss: 0.2860081195831299\n",
      "2451 -> Loss: 1.3534705638885498\n",
      "2452 -> Loss: 0.6678502559661865\n",
      "2453 -> Loss: 0.6588261723518372\n",
      "2454 -> Loss: 1.091817855834961\n",
      "2455 -> Loss: 0.5209001898765564\n",
      "2456 -> Loss: 0.2713813781738281\n",
      "2457 -> Loss: 0.7811793088912964\n",
      "2458 -> Loss: 0.8008762001991272\n",
      "2459 -> Loss: 0.5310227870941162\n",
      "2460 -> Loss: 0.16687317192554474\n",
      "2461 -> Loss: 0.7435203194618225\n",
      "2462 -> Loss: 0.4219047427177429\n",
      "2463 -> Loss: 0.4045219421386719\n",
      "2464 -> Loss: 0.2501262426376343\n",
      "2465 -> Loss: 0.47324997186660767\n",
      "2466 -> Loss: 0.3820376396179199\n",
      "2467 -> Loss: 0.4626246392726898\n",
      "2468 -> Loss: 0.2737935781478882\n",
      "2469 -> Loss: 0.34730854630470276\n",
      "2470 -> Loss: 0.2758290767669678\n",
      "2471 -> Loss: 0.1921883523464203\n",
      "2472 -> Loss: 0.4985116720199585\n",
      "2473 -> Loss: 0.6619834899902344\n",
      "2474 -> Loss: 0.5598583221435547\n",
      "2475 -> Loss: 0.48400455713272095\n",
      "2476 -> Loss: 0.7633690237998962\n",
      "2477 -> Loss: 0.3928529918193817\n",
      "2478 -> Loss: 0.26985108852386475\n",
      "2479 -> Loss: 0.39989474415779114\n",
      "2480 -> Loss: 0.1576356142759323\n",
      "2481 -> Loss: 0.4491472542285919\n",
      "2482 -> Loss: 0.7782115340232849\n",
      "2483 -> Loss: 0.5678730607032776\n",
      "2484 -> Loss: 0.31823790073394775\n",
      "2485 -> Loss: 0.5514039993286133\n",
      "2486 -> Loss: 0.536895751953125\n",
      "2487 -> Loss: 0.4867701530456543\n",
      "2488 -> Loss: 0.739851176738739\n",
      "2489 -> Loss: 0.3048526346683502\n",
      "2490 -> Loss: 0.4586438834667206\n",
      "2491 -> Loss: 0.45027250051498413\n",
      "2492 -> Loss: 0.541045606136322\n",
      "2493 -> Loss: 1.2128361463546753\n",
      "2494 -> Loss: 0.4284977316856384\n",
      "2495 -> Loss: 0.5265774130821228\n",
      "2496 -> Loss: 0.3014273941516876\n",
      "2497 -> Loss: 0.44753411412239075\n",
      "2498 -> Loss: 0.5382134914398193\n",
      "2499 -> Loss: 0.4226745665073395\n",
      "2500 -> Loss: 0.5670651793479919\n",
      "2501 -> Loss: 0.5245993137359619\n",
      "2502 -> Loss: 0.21016034483909607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2503 -> Loss: 0.7622277140617371\n",
      "2504 -> Loss: 0.22580160200595856\n",
      "2505 -> Loss: 0.6766939759254456\n",
      "2506 -> Loss: 0.5180466771125793\n",
      "2507 -> Loss: 0.6503024101257324\n",
      "2508 -> Loss: 0.4537903070449829\n",
      "2509 -> Loss: 0.44295811653137207\n",
      "2510 -> Loss: 1.4277722835540771\n",
      "2511 -> Loss: 1.0786546468734741\n",
      "2512 -> Loss: 0.7096835374832153\n",
      "2513 -> Loss: 0.3406650125980377\n",
      "2514 -> Loss: 0.45332494378089905\n",
      "2515 -> Loss: 0.5793893337249756\n",
      "2516 -> Loss: 0.45234400033950806\n",
      "2517 -> Loss: 0.2788439393043518\n",
      "2518 -> Loss: 0.7448671460151672\n",
      "2519 -> Loss: 0.06367488205432892\n",
      "2520 -> Loss: 0.7035291194915771\n",
      "2521 -> Loss: 0.7751990556716919\n",
      "2522 -> Loss: 0.3338624835014343\n",
      "2523 -> Loss: 0.37497276067733765\n",
      "2524 -> Loss: 0.44651931524276733\n",
      "2525 -> Loss: 0.4220639765262604\n",
      "2526 -> Loss: 0.329913854598999\n",
      "2527 -> Loss: 0.3794189393520355\n",
      "2528 -> Loss: 0.161190927028656\n",
      "2529 -> Loss: 0.5637768507003784\n",
      "2530 -> Loss: 0.6462589502334595\n",
      "2531 -> Loss: 0.6204675436019897\n",
      "2532 -> Loss: 0.903236985206604\n",
      "2533 -> Loss: 0.4531959891319275\n",
      "2534 -> Loss: 0.4795556962490082\n",
      "2535 -> Loss: 0.37754255533218384\n",
      "2536 -> Loss: 0.7210400700569153\n",
      "2537 -> Loss: 0.1829565465450287\n",
      "2538 -> Loss: 1.0692520141601562\n",
      "2539 -> Loss: 0.3055218458175659\n",
      "2540 -> Loss: 1.1001992225646973\n",
      "2541 -> Loss: 0.18692533671855927\n",
      "2542 -> Loss: 0.8294607400894165\n",
      "2543 -> Loss: 0.7239314913749695\n",
      "2544 -> Loss: 0.4350616931915283\n",
      "2545 -> Loss: 0.7888025045394897\n",
      "2546 -> Loss: 0.1268371045589447\n",
      "2547 -> Loss: 0.44933468103408813\n",
      "2548 -> Loss: 0.3179877996444702\n",
      "2549 -> Loss: 0.3536587357521057\n",
      "2550 -> Loss: 0.35780754685401917\n",
      "2551 -> Loss: 0.5325525999069214\n",
      "2552 -> Loss: 0.7456663846969604\n",
      "2553 -> Loss: 0.7132490873336792\n",
      "2554 -> Loss: 0.6423282623291016\n",
      "2555 -> Loss: 0.2093530148267746\n",
      "2556 -> Loss: 0.38830241560935974\n",
      "2557 -> Loss: 0.286133348941803\n",
      "2558 -> Loss: 0.3669149875640869\n",
      "2559 -> Loss: 0.40662112832069397\n",
      "2560 -> Loss: 0.22593890130519867\n",
      "2561 -> Loss: 0.8110719323158264\n",
      "2562 -> Loss: 0.34062373638153076\n",
      "2563 -> Loss: 0.4116710126399994\n",
      "2564 -> Loss: 0.6921268105506897\n",
      "2565 -> Loss: 0.6781560182571411\n",
      "2566 -> Loss: 0.31961360573768616\n",
      "2567 -> Loss: 0.8506476283073425\n",
      "2568 -> Loss: 0.600656270980835\n",
      "2569 -> Loss: 0.464961975812912\n",
      "2570 -> Loss: 0.6628255844116211\n",
      "2571 -> Loss: 0.6109015941619873\n",
      "2572 -> Loss: 0.29553261399269104\n",
      "2573 -> Loss: 0.37113669514656067\n",
      "2574 -> Loss: 0.4772775173187256\n",
      "2575 -> Loss: 0.0977257788181305\n",
      "2576 -> Loss: 0.20187236368656158\n",
      "2577 -> Loss: 0.6353381872177124\n",
      "2578 -> Loss: 0.9531533718109131\n",
      "2579 -> Loss: 0.7297806143760681\n",
      "2580 -> Loss: 0.8161281943321228\n",
      "2581 -> Loss: 0.6074023246765137\n",
      "2582 -> Loss: 0.3043321967124939\n",
      "2583 -> Loss: 0.14195407927036285\n",
      "2584 -> Loss: 0.5313221216201782\n",
      "2585 -> Loss: 0.9805158376693726\n",
      "2586 -> Loss: 0.32451239228248596\n",
      "2587 -> Loss: 0.4191594421863556\n",
      "2588 -> Loss: 0.37699905037879944\n",
      "2589 -> Loss: 0.4789294898509979\n",
      "2590 -> Loss: 0.6295523047447205\n",
      "2591 -> Loss: 0.5325747132301331\n",
      "2592 -> Loss: 0.3743646442890167\n",
      "2593 -> Loss: 0.6929993629455566\n",
      "2594 -> Loss: 0.3645502030849457\n",
      "2595 -> Loss: 0.3740435540676117\n",
      "2596 -> Loss: 0.17514073848724365\n",
      "2597 -> Loss: 0.5910751223564148\n",
      "2598 -> Loss: 0.9845157861709595\n",
      "2599 -> Loss: 0.32414448261260986\n",
      "2600 -> Loss: 0.3535117208957672\n",
      "2601 -> Loss: 0.8825425505638123\n",
      "2602 -> Loss: 0.5501108169555664\n",
      "2603 -> Loss: 0.35263755917549133\n",
      "2604 -> Loss: 0.2039848268032074\n",
      "2605 -> Loss: 0.5567156076431274\n",
      "2606 -> Loss: 0.322622686624527\n",
      "2607 -> Loss: 0.4388176202774048\n",
      "2608 -> Loss: 0.8670409321784973\n",
      "2609 -> Loss: 0.26395174860954285\n",
      "2610 -> Loss: 0.8998160362243652\n",
      "2611 -> Loss: 0.5427972674369812\n",
      "2612 -> Loss: 0.25687476992607117\n",
      "2613 -> Loss: 0.7494269013404846\n",
      "2614 -> Loss: 0.34126898646354675\n",
      "2615 -> Loss: 0.3032180070877075\n",
      "2616 -> Loss: 0.6658749580383301\n",
      "2617 -> Loss: 0.23683279752731323\n",
      "2618 -> Loss: 0.7619612812995911\n",
      "2619 -> Loss: 0.38331928849220276\n",
      "2620 -> Loss: 0.4156542420387268\n",
      "2621 -> Loss: 0.46489661931991577\n",
      "2622 -> Loss: 0.43468841910362244\n",
      "2623 -> Loss: 0.6130762696266174\n",
      "2624 -> Loss: 0.5940756797790527\n",
      "2625 -> Loss: 0.3138532042503357\n",
      "2626 -> Loss: 0.35224199295043945\n",
      "2627 -> Loss: 0.541562020778656\n",
      "2628 -> Loss: 0.4367525577545166\n",
      "2629 -> Loss: 0.3033381402492523\n",
      "2630 -> Loss: 0.41787606477737427\n",
      "2631 -> Loss: 0.6752114295959473\n",
      "2632 -> Loss: 0.23595726490020752\n",
      "2633 -> Loss: 0.5967354774475098\n",
      "2634 -> Loss: 0.2930646538734436\n",
      "2635 -> Loss: 0.3541197180747986\n",
      "2636 -> Loss: 0.5103924870491028\n",
      "2637 -> Loss: 0.3285274803638458\n",
      "2638 -> Loss: 1.0483113527297974\n",
      "2639 -> Loss: 0.47359371185302734\n",
      "2640 -> Loss: 0.7736290097236633\n",
      "2641 -> Loss: 0.3285956382751465\n",
      "2642 -> Loss: 0.2738995850086212\n",
      "2643 -> Loss: 0.5354019999504089\n",
      "2644 -> Loss: 0.6348236203193665\n",
      "2645 -> Loss: 0.2892739176750183\n",
      "2646 -> Loss: 0.6216831207275391\n",
      "2647 -> Loss: 0.44468146562576294\n",
      "2648 -> Loss: 0.48885515332221985\n",
      "2649 -> Loss: 0.4327066242694855\n",
      "2650 -> Loss: 0.3141939342021942\n",
      "2651 -> Loss: 0.3412887752056122\n",
      "2652 -> Loss: 0.7079600691795349\n",
      "2653 -> Loss: 0.662620484828949\n",
      "2654 -> Loss: 0.2761367857456207\n",
      "2655 -> Loss: 0.2995636463165283\n",
      "2656 -> Loss: 0.609243631362915\n",
      "2657 -> Loss: 0.5678077936172485\n",
      "2658 -> Loss: 0.48953720927238464\n",
      "2659 -> Loss: 0.6896032094955444\n",
      "2660 -> Loss: 0.8068175911903381\n",
      "2661 -> Loss: 0.8760519027709961\n",
      "2662 -> Loss: 0.5969869494438171\n",
      "2663 -> Loss: 0.5360857248306274\n",
      "2664 -> Loss: 0.9549179673194885\n",
      "2665 -> Loss: 0.3844747543334961\n",
      "2666 -> Loss: 0.44226890802383423\n",
      "2667 -> Loss: 1.072371244430542\n",
      "2668 -> Loss: 0.4057193994522095\n",
      "2669 -> Loss: 0.6373423933982849\n",
      "2670 -> Loss: 0.9993431568145752\n",
      "2671 -> Loss: 0.6518787145614624\n",
      "2672 -> Loss: 0.36636218428611755\n",
      "2673 -> Loss: 0.22807298600673676\n",
      "2674 -> Loss: 0.5513885021209717\n",
      "2675 -> Loss: 0.2010403424501419\n",
      "2676 -> Loss: 0.169472798705101\n",
      "2677 -> Loss: 0.3575410544872284\n",
      "2678 -> Loss: 0.7683067321777344\n",
      "2679 -> Loss: 0.38572537899017334\n",
      "2680 -> Loss: 0.40945401787757874\n",
      "2681 -> Loss: 0.4746563732624054\n",
      "2682 -> Loss: 0.43461480736732483\n",
      "2683 -> Loss: 0.6470463871955872\n",
      "2684 -> Loss: 0.33273449540138245\n",
      "2685 -> Loss: 0.8188516497612\n",
      "2686 -> Loss: 0.34958070516586304\n",
      "2687 -> Loss: 0.36565473675727844\n",
      "2688 -> Loss: 0.3228536546230316\n",
      "2689 -> Loss: 0.6681737303733826\n",
      "2690 -> Loss: 1.4423059225082397\n",
      "2691 -> Loss: 0.7131869196891785\n",
      "2692 -> Loss: 0.5104362964630127\n",
      "2693 -> Loss: 0.6140918135643005\n",
      "2694 -> Loss: 0.5372166037559509\n",
      "2695 -> Loss: 0.28961262106895447\n",
      "2696 -> Loss: 0.40745115280151367\n",
      "2697 -> Loss: 0.6572774052619934\n",
      "2698 -> Loss: 0.5378605127334595\n",
      "2699 -> Loss: 0.5155802965164185\n",
      "2700 -> Loss: 0.26398247480392456\n",
      "2701 -> Loss: 0.4852312505245209\n",
      "2702 -> Loss: 0.44691333174705505\n",
      "2703 -> Loss: 0.9019036889076233\n",
      "2704 -> Loss: 0.5044041872024536\n",
      "2705 -> Loss: 0.43895673751831055\n",
      "2706 -> Loss: 0.3770347833633423\n",
      "2707 -> Loss: 0.28237608075141907\n",
      "2708 -> Loss: 0.6582121849060059\n",
      "2709 -> Loss: 0.31605803966522217\n",
      "2710 -> Loss: 0.3966243267059326\n",
      "2711 -> Loss: 0.3830895721912384\n",
      "2712 -> Loss: 0.5674936771392822\n",
      "2713 -> Loss: 0.30857017636299133\n",
      "2714 -> Loss: 0.36683788895606995\n",
      "2715 -> Loss: 0.6079906225204468\n",
      "2716 -> Loss: 0.24050559103488922\n",
      "2717 -> Loss: 0.2741324305534363\n",
      "2718 -> Loss: 0.35503917932510376\n",
      "2719 -> Loss: 0.6162474155426025\n",
      "2720 -> Loss: 0.5694543719291687\n",
      "2721 -> Loss: 0.5442294478416443\n",
      "2722 -> Loss: 0.6994602084159851\n",
      "2723 -> Loss: 0.45307305455207825\n",
      "2724 -> Loss: 0.7207239866256714\n",
      "2725 -> Loss: 0.3296605348587036\n",
      "2726 -> Loss: 0.3092985451221466\n",
      "2727 -> Loss: 0.9018833637237549\n",
      "2728 -> Loss: 0.18710695207118988\n",
      "2729 -> Loss: 0.3662407398223877\n",
      "2730 -> Loss: 0.42254725098609924\n",
      "2731 -> Loss: 0.8786493539810181\n",
      "2732 -> Loss: 0.506499171257019\n",
      "2733 -> Loss: 0.3165763020515442\n",
      "2734 -> Loss: 0.4413047134876251\n",
      "2735 -> Loss: 0.4516872465610504\n",
      "2736 -> Loss: 0.5928959846496582\n",
      "2737 -> Loss: 0.688452422618866\n",
      "2738 -> Loss: 1.3189424276351929\n",
      "2739 -> Loss: 0.4178239405155182\n",
      "2740 -> Loss: 0.26864302158355713\n",
      "2741 -> Loss: 0.3193303644657135\n",
      "2742 -> Loss: 0.71072918176651\n",
      "2743 -> Loss: 0.8600046634674072\n",
      "2744 -> Loss: 0.3081444203853607\n",
      "2745 -> Loss: 0.5331120491027832\n",
      "2746 -> Loss: 0.5166051983833313\n",
      "2747 -> Loss: 0.5040039420127869\n",
      "2748 -> Loss: 1.1664419174194336\n",
      "2749 -> Loss: 0.5080298185348511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750 -> Loss: 0.29512736201286316\n",
      "2751 -> Loss: 0.7316688299179077\n",
      "2752 -> Loss: 0.15580902993679047\n",
      "2753 -> Loss: 0.8404857516288757\n",
      "2754 -> Loss: 0.08417962491512299\n",
      "2755 -> Loss: 0.400633841753006\n",
      "2756 -> Loss: 0.7255812287330627\n",
      "2757 -> Loss: 0.2553991973400116\n",
      "2758 -> Loss: 0.13882137835025787\n",
      "2759 -> Loss: 0.8030213117599487\n",
      "2760 -> Loss: 0.2520498037338257\n",
      "2761 -> Loss: 0.32619917392730713\n",
      "2762 -> Loss: 0.6761478185653687\n",
      "2763 -> Loss: 0.6059584021568298\n",
      "2764 -> Loss: 0.29340195655822754\n",
      "2765 -> Loss: 0.5281155109405518\n",
      "2766 -> Loss: 0.3348442316055298\n",
      "2767 -> Loss: 0.43723106384277344\n",
      "2768 -> Loss: 0.6890143156051636\n",
      "2769 -> Loss: 0.5693326592445374\n",
      "2770 -> Loss: 0.512026309967041\n",
      "2771 -> Loss: 0.6937447190284729\n",
      "2772 -> Loss: 0.31797298789024353\n",
      "2773 -> Loss: 0.33162617683410645\n",
      "2774 -> Loss: 0.8420431017875671\n",
      "2775 -> Loss: 0.5494641661643982\n",
      "2776 -> Loss: 0.6599085330963135\n",
      "2777 -> Loss: 0.3318813443183899\n",
      "2778 -> Loss: 0.2893619239330292\n",
      "2779 -> Loss: 0.43129104375839233\n",
      "2780 -> Loss: 0.3110087513923645\n",
      "2781 -> Loss: 0.3375847339630127\n",
      "2782 -> Loss: 0.18609023094177246\n",
      "2783 -> Loss: 0.34845858812332153\n",
      "2784 -> Loss: 0.4768747091293335\n",
      "2785 -> Loss: 0.47395387291908264\n",
      "2786 -> Loss: 0.6028296947479248\n",
      "2787 -> Loss: 0.2546006739139557\n",
      "2788 -> Loss: 0.2528095245361328\n",
      "2789 -> Loss: 0.5071837902069092\n",
      "2790 -> Loss: 0.5807501077651978\n",
      "2791 -> Loss: 0.16424447298049927\n",
      "2792 -> Loss: 0.4459967017173767\n",
      "2793 -> Loss: 0.411237895488739\n",
      "2794 -> Loss: 0.7334024310112\n",
      "2795 -> Loss: 0.38123074173927307\n",
      "2796 -> Loss: 0.866407036781311\n",
      "2797 -> Loss: 0.25228971242904663\n",
      "2798 -> Loss: 0.6141571998596191\n",
      "2799 -> Loss: 0.2252580225467682\n",
      "2800 -> Loss: 0.6259558796882629\n",
      "2801 -> Loss: 0.24465128779411316\n",
      "2802 -> Loss: 0.8832045197486877\n",
      "2803 -> Loss: 0.6598891019821167\n",
      "2804 -> Loss: 0.38249945640563965\n",
      "2805 -> Loss: 0.5653040409088135\n",
      "2806 -> Loss: 0.5490179657936096\n",
      "2807 -> Loss: 0.5866570472717285\n",
      "2808 -> Loss: 0.5922271013259888\n",
      "2809 -> Loss: 0.6245714426040649\n",
      "2810 -> Loss: 0.2989497482776642\n",
      "2811 -> Loss: 0.29034173488616943\n",
      "2812 -> Loss: 0.47040241956710815\n",
      "2813 -> Loss: 0.33213314414024353\n",
      "2814 -> Loss: 0.47963613271713257\n",
      "2815 -> Loss: 0.27404752373695374\n",
      "2816 -> Loss: 0.43069741129875183\n",
      "2817 -> Loss: 0.5825766921043396\n",
      "2818 -> Loss: 0.44251418113708496\n",
      "2819 -> Loss: 0.707423210144043\n",
      "2820 -> Loss: 0.3470197021961212\n",
      "2821 -> Loss: 0.3123936951160431\n",
      "2822 -> Loss: 0.6185539960861206\n",
      "2823 -> Loss: 0.28475451469421387\n",
      "2824 -> Loss: 0.6234620809555054\n",
      "2825 -> Loss: 0.27939993143081665\n",
      "2826 -> Loss: 0.8077123165130615\n",
      "2827 -> Loss: 0.33877041935920715\n",
      "2828 -> Loss: 0.30098986625671387\n",
      "2829 -> Loss: 0.4613147974014282\n",
      "2830 -> Loss: 0.9770864844322205\n",
      "2831 -> Loss: 0.9911083579063416\n",
      "2832 -> Loss: 1.0864874124526978\n",
      "2833 -> Loss: 0.4051752984523773\n",
      "2834 -> Loss: 0.7402356863021851\n",
      "2835 -> Loss: 0.40976324677467346\n",
      "2836 -> Loss: 0.41207966208457947\n",
      "2837 -> Loss: 0.48644188046455383\n",
      "2838 -> Loss: 0.6006975769996643\n",
      "2839 -> Loss: 0.541097104549408\n",
      "2840 -> Loss: 0.68696528673172\n",
      "2841 -> Loss: 0.7232675552368164\n",
      "2842 -> Loss: 0.08186013996601105\n",
      "2843 -> Loss: 0.41659852862358093\n",
      "2844 -> Loss: 0.4233018159866333\n",
      "2845 -> Loss: 0.46141567826271057\n",
      "2846 -> Loss: 0.6362098455429077\n",
      "2847 -> Loss: 1.0191917419433594\n",
      "2848 -> Loss: 0.218516007065773\n",
      "2849 -> Loss: 0.37361443042755127\n",
      "2850 -> Loss: 0.45696088671684265\n",
      "2851 -> Loss: 0.5804826021194458\n",
      "2852 -> Loss: 0.48953062295913696\n",
      "2853 -> Loss: 0.4798208475112915\n",
      "2854 -> Loss: 0.4879222810268402\n",
      "2855 -> Loss: 0.2463912069797516\n",
      "2856 -> Loss: 0.6644017100334167\n",
      "2857 -> Loss: 0.4512304961681366\n",
      "2858 -> Loss: 0.7367744445800781\n",
      "2859 -> Loss: 0.7037292122840881\n",
      "2860 -> Loss: 0.9683771729469299\n",
      "2861 -> Loss: 0.5790407657623291\n",
      "2862 -> Loss: 0.4002055525779724\n",
      "2863 -> Loss: 0.9006695747375488\n",
      "2864 -> Loss: 0.2500610649585724\n",
      "2865 -> Loss: 0.24588488042354584\n",
      "2866 -> Loss: 0.48924675583839417\n",
      "2867 -> Loss: 0.7499842047691345\n",
      "2868 -> Loss: 0.7638430595397949\n",
      "2869 -> Loss: 0.42311951518058777\n",
      "2870 -> Loss: 0.6564329266548157\n",
      "2871 -> Loss: 0.4622572362422943\n",
      "2872 -> Loss: 0.5060538053512573\n",
      "2873 -> Loss: 0.7788881063461304\n",
      "2874 -> Loss: 0.37584027647972107\n",
      "2875 -> Loss: 0.4746234714984894\n",
      "2876 -> Loss: 0.12214300781488419\n",
      "2877 -> Loss: 0.4761222302913666\n",
      "2878 -> Loss: 0.4735267758369446\n",
      "2879 -> Loss: 0.45961737632751465\n",
      "2880 -> Loss: 0.5240568518638611\n",
      "2881 -> Loss: 1.3151524066925049\n",
      "2882 -> Loss: 0.39615994691848755\n",
      "2883 -> Loss: 0.6201159954071045\n",
      "2884 -> Loss: 0.5108913779258728\n",
      "2885 -> Loss: 0.6857649683952332\n",
      "2886 -> Loss: 0.12110616266727448\n",
      "2887 -> Loss: 0.5683286190032959\n",
      "2888 -> Loss: 0.33154815435409546\n",
      "2889 -> Loss: 0.5630955696105957\n",
      "2890 -> Loss: 0.6701911687850952\n",
      "2891 -> Loss: 0.96146160364151\n",
      "2892 -> Loss: 0.8185255527496338\n",
      "2893 -> Loss: 0.17895761132240295\n",
      "2894 -> Loss: 0.2382097989320755\n",
      "2895 -> Loss: 0.5969480872154236\n",
      "2896 -> Loss: 0.39655667543411255\n",
      "2897 -> Loss: 0.29422780871391296\n",
      "2898 -> Loss: 0.48819100856781006\n",
      "2899 -> Loss: 0.4094170033931732\n",
      "2900 -> Loss: 0.4683702886104584\n",
      "2901 -> Loss: 0.387751042842865\n",
      "2902 -> Loss: 0.2773364186286926\n",
      "2903 -> Loss: 0.19540415704250336\n",
      "2904 -> Loss: 0.4431329667568207\n",
      "2905 -> Loss: 0.8427839279174805\n",
      "2906 -> Loss: 0.4581352770328522\n",
      "2907 -> Loss: 0.13528403639793396\n",
      "2908 -> Loss: 0.41196247935295105\n",
      "2909 -> Loss: 0.38066089153289795\n",
      "2910 -> Loss: 0.5206797122955322\n",
      "2911 -> Loss: 1.1340256929397583\n",
      "2912 -> Loss: 0.41040194034576416\n",
      "2913 -> Loss: 0.32096752524375916\n",
      "2914 -> Loss: 0.36801785230636597\n",
      "2915 -> Loss: 0.7829476594924927\n",
      "2916 -> Loss: 0.413794606924057\n",
      "2917 -> Loss: 0.511624813079834\n",
      "2918 -> Loss: 0.613742470741272\n",
      "2919 -> Loss: 0.7269213199615479\n",
      "2920 -> Loss: 0.26488152146339417\n",
      "2921 -> Loss: 0.16534575819969177\n",
      "2922 -> Loss: 0.6952305436134338\n",
      "2923 -> Loss: 0.5068627595901489\n",
      "2924 -> Loss: 1.0274423360824585\n",
      "2925 -> Loss: 0.9972937107086182\n",
      "2926 -> Loss: 0.38927748799324036\n",
      "2927 -> Loss: 0.34257596731185913\n",
      "2928 -> Loss: 0.6384943723678589\n",
      "2929 -> Loss: 0.16200204193592072\n",
      "2930 -> Loss: 0.3581993579864502\n",
      "2931 -> Loss: 0.9426843523979187\n",
      "2932 -> Loss: 0.4198204278945923\n",
      "2933 -> Loss: 0.9804677367210388\n",
      "2934 -> Loss: 0.6474060416221619\n",
      "2935 -> Loss: 1.0824551582336426\n",
      "2936 -> Loss: 0.3380962908267975\n",
      "2937 -> Loss: 0.7562645077705383\n",
      "2938 -> Loss: 1.0248801708221436\n",
      "2939 -> Loss: 0.28412532806396484\n",
      "2940 -> Loss: 0.6445860266685486\n",
      "2941 -> Loss: 0.36552006006240845\n",
      "2942 -> Loss: 0.4045867323875427\n",
      "2943 -> Loss: 0.6421113610267639\n",
      "2944 -> Loss: 0.5101646780967712\n",
      "2945 -> Loss: 0.7026112675666809\n",
      "2946 -> Loss: 0.2772305905818939\n",
      "2947 -> Loss: 0.24292320013046265\n",
      "2948 -> Loss: 0.8010329008102417\n",
      "2949 -> Loss: 0.36993512511253357\n",
      "2950 -> Loss: 0.7727823257446289\n",
      "2951 -> Loss: 0.32461097836494446\n",
      "2952 -> Loss: 0.5376654863357544\n",
      "2953 -> Loss: 0.22116060554981232\n",
      "2954 -> Loss: 0.49643489718437195\n",
      "2955 -> Loss: 0.2192445546388626\n",
      "2956 -> Loss: 0.8020040988922119\n",
      "2957 -> Loss: 0.9010370969772339\n",
      "2958 -> Loss: 0.13349133729934692\n",
      "2959 -> Loss: 0.30970120429992676\n",
      "2960 -> Loss: 0.1586117297410965\n",
      "2961 -> Loss: 0.293032169342041\n",
      "2962 -> Loss: 0.26458922028541565\n",
      "2963 -> Loss: 0.1673506796360016\n",
      "2964 -> Loss: 0.860795259475708\n",
      "2965 -> Loss: 0.7167984843254089\n",
      "2966 -> Loss: 0.3625809848308563\n",
      "2967 -> Loss: 0.6099629402160645\n",
      "2968 -> Loss: 0.4485345780849457\n",
      "2969 -> Loss: 0.4975639283657074\n",
      "2970 -> Loss: 0.5477601885795593\n",
      "2971 -> Loss: 0.7109718322753906\n",
      "2972 -> Loss: 0.23471756279468536\n",
      "2973 -> Loss: 0.5233327150344849\n",
      "2974 -> Loss: 0.5722373127937317\n",
      "2975 -> Loss: 0.5867867469787598\n",
      "2976 -> Loss: 0.6864362955093384\n",
      "2977 -> Loss: 0.24021777510643005\n",
      "2978 -> Loss: 0.11925029009580612\n",
      "2979 -> Loss: 0.22549769282341003\n",
      "2980 -> Loss: 0.4592839777469635\n",
      "2981 -> Loss: 0.6561772227287292\n",
      "2982 -> Loss: 0.6124798059463501\n",
      "2983 -> Loss: 0.6779205203056335\n",
      "2984 -> Loss: 0.19645212590694427\n",
      "2985 -> Loss: 0.6017385721206665\n",
      "2986 -> Loss: 0.4688815474510193\n",
      "2987 -> Loss: 0.553544819355011\n",
      "2988 -> Loss: 0.49364173412323\n",
      "2989 -> Loss: 0.22372789680957794\n",
      "2990 -> Loss: 0.2409716248512268\n",
      "2991 -> Loss: 0.4892403781414032\n",
      "2992 -> Loss: 0.4494580328464508\n",
      "2993 -> Loss: 0.2173815667629242\n",
      "2994 -> Loss: 0.5736693143844604\n",
      "2995 -> Loss: 0.40956392884254456\n",
      "2996 -> Loss: 0.6271889805793762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2997 -> Loss: 0.2953836917877197\n",
      "2998 -> Loss: 0.4084415137767792\n",
      "2999 -> Loss: 0.1472795009613037\n",
      "3000 -> Loss: 0.6400266885757446\n",
      "\n",
      "Validation Accuracy: 66.0, Test Accuracy: 69.0 \n",
      "\n",
      "3001 -> Loss: 0.5581330060958862\n",
      "3002 -> Loss: 0.23533594608306885\n",
      "3003 -> Loss: 0.6867280006408691\n",
      "3004 -> Loss: 0.5135515928268433\n",
      "3005 -> Loss: 0.9730560779571533\n",
      "3006 -> Loss: 0.46886277198791504\n",
      "3007 -> Loss: 1.2490272521972656\n",
      "3008 -> Loss: 0.5014830231666565\n",
      "3009 -> Loss: 0.25987911224365234\n",
      "3010 -> Loss: 0.5308150053024292\n",
      "3011 -> Loss: 0.4832765460014343\n",
      "3012 -> Loss: 0.6552945971488953\n",
      "3013 -> Loss: 0.3839279115200043\n",
      "3014 -> Loss: 0.2182316780090332\n",
      "3015 -> Loss: 0.5197250843048096\n",
      "3016 -> Loss: 0.36965394020080566\n",
      "3017 -> Loss: 0.6047237515449524\n",
      "3018 -> Loss: 0.5339654088020325\n",
      "3019 -> Loss: 0.29821810126304626\n",
      "3020 -> Loss: 0.31071415543556213\n",
      "3021 -> Loss: 1.0663871765136719\n",
      "3022 -> Loss: 0.48596853017807007\n",
      "3023 -> Loss: 0.213052898645401\n",
      "3024 -> Loss: 0.34535348415374756\n",
      "3025 -> Loss: 0.5351247191429138\n",
      "3026 -> Loss: 0.9992870092391968\n",
      "3027 -> Loss: 0.38820329308509827\n",
      "3028 -> Loss: 0.6042162179946899\n",
      "3029 -> Loss: 0.5844753980636597\n",
      "3030 -> Loss: 0.15172460675239563\n",
      "3031 -> Loss: 0.5398901104927063\n",
      "3032 -> Loss: 0.3157568573951721\n",
      "3033 -> Loss: 0.28165608644485474\n",
      "3034 -> Loss: 0.3028073310852051\n",
      "3035 -> Loss: 0.7389528155326843\n",
      "3036 -> Loss: 0.43069425225257874\n",
      "3037 -> Loss: 0.21051721274852753\n",
      "3038 -> Loss: 0.34182724356651306\n",
      "3039 -> Loss: 0.6534507870674133\n",
      "3040 -> Loss: 0.19563250243663788\n",
      "3041 -> Loss: 0.8141480684280396\n",
      "3042 -> Loss: 1.0181080102920532\n",
      "3043 -> Loss: 0.44509974122047424\n",
      "3044 -> Loss: 0.5172781944274902\n",
      "3045 -> Loss: 0.4720414876937866\n",
      "3046 -> Loss: 1.2710386514663696\n",
      "3047 -> Loss: 0.5554952621459961\n",
      "3048 -> Loss: 0.4678442180156708\n",
      "3049 -> Loss: 0.367863267660141\n",
      "3050 -> Loss: 0.9911012649536133\n",
      "3051 -> Loss: 0.5679733753204346\n",
      "3052 -> Loss: 0.4948936700820923\n",
      "3053 -> Loss: 0.9545214772224426\n",
      "3054 -> Loss: 0.425322949886322\n",
      "3055 -> Loss: 0.6066684722900391\n",
      "3056 -> Loss: 0.19020985066890717\n",
      "3057 -> Loss: 0.9145330190658569\n",
      "3058 -> Loss: 0.41739848256111145\n",
      "3059 -> Loss: 0.6035595536231995\n",
      "3060 -> Loss: 0.5473431944847107\n",
      "3061 -> Loss: 0.36448389291763306\n",
      "3062 -> Loss: 0.4235764145851135\n",
      "3063 -> Loss: 0.39357927441596985\n",
      "3064 -> Loss: 0.7758931517601013\n",
      "3065 -> Loss: 0.5542535781860352\n",
      "3066 -> Loss: 0.5123454332351685\n",
      "3067 -> Loss: 0.60151207447052\n",
      "3068 -> Loss: 0.5343714356422424\n",
      "3069 -> Loss: 0.9752477407455444\n",
      "3070 -> Loss: 0.47099003195762634\n",
      "3071 -> Loss: 0.35905906558036804\n",
      "3072 -> Loss: 0.29864245653152466\n",
      "3073 -> Loss: 0.38857150077819824\n",
      "3074 -> Loss: 0.4845823347568512\n",
      "3075 -> Loss: 0.31711119413375854\n",
      "3076 -> Loss: 0.16441667079925537\n",
      "3077 -> Loss: 0.9993748068809509\n",
      "3078 -> Loss: 0.6247413754463196\n",
      "3079 -> Loss: 0.17701716721057892\n",
      "3080 -> Loss: 0.09940675646066666\n",
      "3081 -> Loss: 0.12836113572120667\n",
      "3082 -> Loss: 0.6998647451400757\n",
      "3083 -> Loss: 0.4065103232860565\n",
      "3084 -> Loss: 0.44800060987472534\n",
      "3085 -> Loss: 0.5909663438796997\n",
      "3086 -> Loss: 1.0894725322723389\n",
      "3087 -> Loss: 0.6099880933761597\n",
      "3088 -> Loss: 0.7095258235931396\n",
      "3089 -> Loss: 0.511876106262207\n",
      "3090 -> Loss: 0.8976160883903503\n",
      "3091 -> Loss: 0.7426297068595886\n",
      "3092 -> Loss: 0.6206645965576172\n",
      "3093 -> Loss: 0.1932477056980133\n",
      "3094 -> Loss: 0.39374852180480957\n",
      "3095 -> Loss: 0.31829485297203064\n",
      "3096 -> Loss: 0.2884567677974701\n",
      "3097 -> Loss: 0.6902109384536743\n",
      "3098 -> Loss: 0.6677031517028809\n",
      "3099 -> Loss: 0.938132643699646\n",
      "3100 -> Loss: 0.3733884394168854\n",
      "3101 -> Loss: 1.1126877069473267\n",
      "3102 -> Loss: 0.6093654036521912\n",
      "3103 -> Loss: 0.5330662727355957\n",
      "3104 -> Loss: 0.2965742349624634\n",
      "3105 -> Loss: 0.3158344328403473\n",
      "3106 -> Loss: 0.38420650362968445\n",
      "3107 -> Loss: 0.7441706657409668\n",
      "3108 -> Loss: 0.8869420886039734\n",
      "3109 -> Loss: 0.9334957003593445\n",
      "3110 -> Loss: 0.4340159595012665\n",
      "3111 -> Loss: 0.496945858001709\n",
      "3112 -> Loss: 0.21590249240398407\n",
      "3113 -> Loss: 0.9738425612449646\n",
      "3114 -> Loss: 0.46961092948913574\n",
      "3115 -> Loss: 0.6770416498184204\n",
      "3116 -> Loss: 0.6089903116226196\n",
      "3117 -> Loss: 0.8887867331504822\n",
      "3118 -> Loss: 0.7764727473258972\n",
      "3119 -> Loss: 0.7955166697502136\n",
      "3120 -> Loss: 0.5954978466033936\n",
      "3121 -> Loss: 0.5206435918807983\n",
      "3122 -> Loss: 0.43355780839920044\n",
      "3123 -> Loss: 0.6674591898918152\n",
      "3124 -> Loss: 0.3826306462287903\n",
      "3125 -> Loss: 0.3596894443035126\n",
      "3126 -> Loss: 0.34261655807495117\n",
      "3127 -> Loss: 0.9075955748558044\n",
      "3128 -> Loss: 0.6184698343276978\n",
      "3129 -> Loss: 0.35655248165130615\n",
      "3130 -> Loss: 0.5389719009399414\n",
      "3131 -> Loss: 0.5712642669677734\n",
      "3132 -> Loss: 0.19455336034297943\n",
      "3133 -> Loss: 0.8410089015960693\n",
      "3134 -> Loss: 0.5837329626083374\n",
      "3135 -> Loss: 0.5193320512771606\n",
      "3136 -> Loss: 0.3800975978374481\n",
      "3137 -> Loss: 0.07397231459617615\n",
      "3138 -> Loss: 0.3566824793815613\n",
      "3139 -> Loss: 0.20907430350780487\n",
      "3140 -> Loss: 0.4144471287727356\n",
      "3141 -> Loss: 0.4472057819366455\n",
      "3142 -> Loss: 0.8279962539672852\n",
      "3143 -> Loss: 0.3060840964317322\n",
      "3144 -> Loss: 0.4948597252368927\n",
      "3145 -> Loss: 0.3100939393043518\n",
      "3146 -> Loss: 0.3168877363204956\n",
      "3147 -> Loss: 0.43425363302230835\n",
      "3148 -> Loss: 0.43227913975715637\n",
      "3149 -> Loss: 0.4710162580013275\n",
      "3150 -> Loss: 0.12096121162176132\n",
      "3151 -> Loss: 0.7209562063217163\n",
      "3152 -> Loss: 0.6477010846138\n",
      "3153 -> Loss: 0.6011741161346436\n",
      "3154 -> Loss: 0.4778520166873932\n",
      "3155 -> Loss: 0.8684235215187073\n",
      "3156 -> Loss: 0.27324843406677246\n",
      "3157 -> Loss: 0.7047889232635498\n",
      "3158 -> Loss: 0.36554810404777527\n",
      "3159 -> Loss: 0.7014987468719482\n",
      "3160 -> Loss: 0.22994793951511383\n",
      "3161 -> Loss: 0.4773370623588562\n",
      "3162 -> Loss: 0.21201248466968536\n",
      "3163 -> Loss: 0.635586678981781\n",
      "3164 -> Loss: 0.41465428471565247\n",
      "3165 -> Loss: 0.3312269151210785\n",
      "3166 -> Loss: 0.3123103380203247\n",
      "3167 -> Loss: 0.5303397178649902\n",
      "3168 -> Loss: 0.5167856216430664\n",
      "3169 -> Loss: 0.4156876504421234\n",
      "3170 -> Loss: 0.3268725574016571\n",
      "3171 -> Loss: 0.19536927342414856\n",
      "3172 -> Loss: 0.6007652282714844\n",
      "3173 -> Loss: 0.5525853037834167\n",
      "3174 -> Loss: 0.26645052433013916\n",
      "3175 -> Loss: 0.4238862991333008\n",
      "3176 -> Loss: 0.7149081826210022\n",
      "3177 -> Loss: 0.24170777201652527\n",
      "3178 -> Loss: 0.13717567920684814\n",
      "3179 -> Loss: 0.3934434652328491\n",
      "3180 -> Loss: 0.7897212505340576\n",
      "3181 -> Loss: 0.27825242280960083\n",
      "3182 -> Loss: 0.5074566602706909\n",
      "3183 -> Loss: 0.3990681767463684\n",
      "3184 -> Loss: 0.4425770044326782\n",
      "3185 -> Loss: 0.513903021812439\n",
      "3186 -> Loss: 0.529381513595581\n",
      "3187 -> Loss: 0.25682133436203003\n",
      "3188 -> Loss: 0.6157124042510986\n",
      "3189 -> Loss: 0.9383742809295654\n",
      "3190 -> Loss: 0.5488659739494324\n",
      "3191 -> Loss: 0.3060528635978699\n",
      "3192 -> Loss: 0.16871219873428345\n",
      "3193 -> Loss: 0.3757937550544739\n",
      "3194 -> Loss: 0.36326250433921814\n",
      "3195 -> Loss: 0.56208735704422\n",
      "3196 -> Loss: 0.6670932769775391\n",
      "3197 -> Loss: 0.27810391783714294\n",
      "3198 -> Loss: 0.28628814220428467\n",
      "3199 -> Loss: 0.5636915564537048\n",
      "3200 -> Loss: 0.21445076167583466\n",
      "3201 -> Loss: 0.5806905031204224\n",
      "3202 -> Loss: 0.2327883094549179\n",
      "3203 -> Loss: 0.27118611335754395\n",
      "3204 -> Loss: 0.4162340760231018\n",
      "3205 -> Loss: 0.22054439783096313\n",
      "3206 -> Loss: 0.7047953009605408\n",
      "3207 -> Loss: 0.5073190331459045\n",
      "3208 -> Loss: 0.2742695212364197\n",
      "3209 -> Loss: 0.18783481419086456\n",
      "3210 -> Loss: 0.2960907816886902\n",
      "3211 -> Loss: 0.3922998905181885\n",
      "3212 -> Loss: 0.6051301956176758\n",
      "3213 -> Loss: 0.4152645766735077\n",
      "3214 -> Loss: 0.9579979777336121\n",
      "3215 -> Loss: 0.2817226052284241\n",
      "3216 -> Loss: 0.8073047399520874\n",
      "3217 -> Loss: 0.02730875462293625\n",
      "3218 -> Loss: 0.6508840322494507\n",
      "3219 -> Loss: 1.0979394912719727\n",
      "3220 -> Loss: 0.3632854223251343\n",
      "3221 -> Loss: 0.3418107330799103\n",
      "3222 -> Loss: 0.49456167221069336\n",
      "3223 -> Loss: 0.27454251050949097\n",
      "3224 -> Loss: 0.40278854966163635\n",
      "3225 -> Loss: 0.22503934800624847\n",
      "3226 -> Loss: 0.3982948958873749\n",
      "3227 -> Loss: 0.6574448943138123\n",
      "3228 -> Loss: 0.7410978674888611\n",
      "3229 -> Loss: 0.30084407329559326\n",
      "3230 -> Loss: 0.12354331463575363\n",
      "3231 -> Loss: 0.952536404132843\n",
      "3232 -> Loss: 0.5201324224472046\n",
      "3233 -> Loss: 1.104560375213623\n",
      "3234 -> Loss: 0.39848092198371887\n",
      "3235 -> Loss: 0.22440053522586823\n",
      "3236 -> Loss: 0.40770959854125977\n",
      "3237 -> Loss: 0.13820120692253113\n",
      "3238 -> Loss: 0.2879452407360077\n",
      "3239 -> Loss: 0.19693394005298615\n",
      "3240 -> Loss: 0.4370911121368408\n",
      "3241 -> Loss: 0.08863017708063126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3242 -> Loss: 0.7791478037834167\n",
      "3243 -> Loss: 0.20682628452777863\n",
      "3244 -> Loss: 0.56416255235672\n",
      "3245 -> Loss: 0.31709474325180054\n",
      "3246 -> Loss: 0.5480600595474243\n",
      "3247 -> Loss: 0.6978244781494141\n",
      "3248 -> Loss: 0.6663452386856079\n",
      "3249 -> Loss: 0.4410147964954376\n",
      "3250 -> Loss: 0.6533072590827942\n",
      "3251 -> Loss: 0.746029257774353\n",
      "3252 -> Loss: 0.6160250902175903\n",
      "3253 -> Loss: 0.6651992201805115\n",
      "3254 -> Loss: 0.21638745069503784\n",
      "3255 -> Loss: 0.49191635847091675\n",
      "3256 -> Loss: 0.2883581817150116\n",
      "3257 -> Loss: 0.36123549938201904\n",
      "3258 -> Loss: 0.8632410764694214\n",
      "3259 -> Loss: 0.46077194809913635\n",
      "3260 -> Loss: 0.9752052426338196\n",
      "3261 -> Loss: 0.4846882224082947\n",
      "3262 -> Loss: 0.3124257028102875\n",
      "3263 -> Loss: 0.3093239367008209\n",
      "3264 -> Loss: 0.5019283294677734\n",
      "3265 -> Loss: 0.4434535503387451\n",
      "3266 -> Loss: 0.5530391335487366\n",
      "3267 -> Loss: 0.6261914968490601\n",
      "3268 -> Loss: 0.5550099611282349\n",
      "3269 -> Loss: 0.31767648458480835\n",
      "3270 -> Loss: 0.29302558302879333\n",
      "3271 -> Loss: 0.23900045454502106\n",
      "3272 -> Loss: 0.5161817073822021\n",
      "3273 -> Loss: 0.8076831102371216\n",
      "3274 -> Loss: 0.19822940230369568\n",
      "3275 -> Loss: 0.9342875480651855\n",
      "3276 -> Loss: 0.37173259258270264\n",
      "3277 -> Loss: 0.6467850208282471\n",
      "3278 -> Loss: 0.3546451926231384\n",
      "3279 -> Loss: 0.5794130563735962\n",
      "3280 -> Loss: 0.7353007197380066\n",
      "3281 -> Loss: 0.3353883922100067\n",
      "3282 -> Loss: 0.6599546074867249\n",
      "3283 -> Loss: 0.12687495350837708\n",
      "3284 -> Loss: 0.6432293653488159\n",
      "3285 -> Loss: 0.5443540215492249\n",
      "3286 -> Loss: 0.24706287682056427\n",
      "3287 -> Loss: 0.20766441524028778\n",
      "3288 -> Loss: 0.3478251099586487\n",
      "3289 -> Loss: 0.19876623153686523\n",
      "3290 -> Loss: 0.7578023076057434\n",
      "3291 -> Loss: 0.7165236473083496\n",
      "3292 -> Loss: 1.141747236251831\n",
      "3293 -> Loss: 0.861598014831543\n",
      "3294 -> Loss: 1.0699418783187866\n",
      "3295 -> Loss: 0.760396420955658\n",
      "3296 -> Loss: 0.30607685446739197\n",
      "3297 -> Loss: 0.1634826958179474\n",
      "3298 -> Loss: 0.3546210527420044\n",
      "3299 -> Loss: 0.4317035973072052\n",
      "3300 -> Loss: 0.28228044509887695\n",
      "3301 -> Loss: 1.1413172483444214\n",
      "3302 -> Loss: 0.5174933671951294\n",
      "3303 -> Loss: 0.8162752389907837\n",
      "3304 -> Loss: 0.20055042207241058\n",
      "3305 -> Loss: 0.49505770206451416\n",
      "3306 -> Loss: 0.5245630741119385\n",
      "3307 -> Loss: 0.5621378421783447\n",
      "3308 -> Loss: 0.364095002412796\n",
      "3309 -> Loss: 0.20796918869018555\n",
      "3310 -> Loss: 0.21111923456192017\n",
      "3311 -> Loss: 0.5426021218299866\n",
      "3312 -> Loss: 0.276897668838501\n",
      "3313 -> Loss: 1.115026831626892\n",
      "3314 -> Loss: 0.5014428496360779\n",
      "3315 -> Loss: 0.7890373468399048\n",
      "3316 -> Loss: 0.867778480052948\n",
      "3317 -> Loss: 0.672787070274353\n",
      "3318 -> Loss: 0.281025767326355\n",
      "3319 -> Loss: 0.7229427099227905\n",
      "3320 -> Loss: 0.6520463228225708\n",
      "3321 -> Loss: 0.47692573070526123\n",
      "3322 -> Loss: 0.5567615628242493\n",
      "3323 -> Loss: 0.24392487108707428\n",
      "3324 -> Loss: 0.5164839625358582\n",
      "3325 -> Loss: 0.725100040435791\n",
      "3326 -> Loss: 0.432985782623291\n",
      "3327 -> Loss: 0.7145587205886841\n",
      "3328 -> Loss: 0.9296488761901855\n",
      "3329 -> Loss: 0.34214621782302856\n",
      "3330 -> Loss: 0.23419733345508575\n",
      "3331 -> Loss: 1.3006033897399902\n",
      "3332 -> Loss: 0.2974562644958496\n",
      "3333 -> Loss: 0.6262571811676025\n",
      "3334 -> Loss: 0.46249085664749146\n",
      "3335 -> Loss: 0.5843223929405212\n",
      "3336 -> Loss: 0.6734237670898438\n",
      "3337 -> Loss: 0.5090585947036743\n",
      "3338 -> Loss: 0.23769685626029968\n",
      "3339 -> Loss: 0.8118444681167603\n",
      "3340 -> Loss: 0.8894671201705933\n",
      "3341 -> Loss: 0.8807257413864136\n",
      "3342 -> Loss: 0.41119384765625\n",
      "3343 -> Loss: 0.5886390209197998\n",
      "3344 -> Loss: 0.5550171732902527\n",
      "3345 -> Loss: 0.23282074928283691\n",
      "3346 -> Loss: 0.5178223252296448\n",
      "3347 -> Loss: 0.21711288392543793\n",
      "3348 -> Loss: 0.26789945363998413\n",
      "3349 -> Loss: 0.16630449891090393\n",
      "3350 -> Loss: 0.7162164449691772\n",
      "3351 -> Loss: 0.33741021156311035\n",
      "3352 -> Loss: 0.2440696507692337\n",
      "3353 -> Loss: 0.4826325476169586\n",
      "3354 -> Loss: 0.5186959505081177\n",
      "3355 -> Loss: 0.41132083535194397\n",
      "3356 -> Loss: 0.16062211990356445\n",
      "3357 -> Loss: 0.4904579520225525\n",
      "3358 -> Loss: 0.6224209070205688\n",
      "3359 -> Loss: 0.28597724437713623\n",
      "3360 -> Loss: 0.356097936630249\n",
      "3361 -> Loss: 0.6915013194084167\n",
      "3362 -> Loss: 0.2573046088218689\n",
      "3363 -> Loss: 0.22874321043491364\n",
      "3364 -> Loss: 0.8877847790718079\n",
      "3365 -> Loss: 0.3474378287792206\n",
      "3366 -> Loss: 0.9985553622245789\n",
      "3367 -> Loss: 0.5233771204948425\n",
      "3368 -> Loss: 0.33127373456954956\n",
      "3369 -> Loss: 0.4989018440246582\n",
      "3370 -> Loss: 0.6917370557785034\n",
      "3371 -> Loss: 0.20192860066890717\n",
      "3372 -> Loss: 2.2659192085266113\n",
      "3373 -> Loss: 0.3201839327812195\n",
      "3374 -> Loss: 0.8141430616378784\n",
      "3375 -> Loss: 0.3318583369255066\n",
      "3376 -> Loss: 0.66058748960495\n",
      "3377 -> Loss: 0.606878399848938\n",
      "3378 -> Loss: 0.858519434928894\n",
      "3379 -> Loss: 0.24422957003116608\n",
      "3380 -> Loss: 0.24590131640434265\n",
      "3381 -> Loss: 0.6737676858901978\n",
      "3382 -> Loss: 0.5140505433082581\n",
      "3383 -> Loss: 0.15244482457637787\n",
      "3384 -> Loss: 0.6699700355529785\n",
      "3385 -> Loss: 0.7790733575820923\n",
      "3386 -> Loss: 0.4174354076385498\n",
      "3387 -> Loss: 0.2315160185098648\n",
      "3388 -> Loss: 0.4828345477581024\n",
      "3389 -> Loss: 0.4017026722431183\n",
      "3390 -> Loss: 0.7060267925262451\n",
      "3391 -> Loss: 0.3243560194969177\n",
      "3392 -> Loss: 0.4713961184024811\n",
      "3393 -> Loss: 0.17803163826465607\n",
      "3394 -> Loss: 0.2946324646472931\n",
      "3395 -> Loss: 0.515194296836853\n",
      "3396 -> Loss: 0.21409039199352264\n",
      "3397 -> Loss: 1.1876879930496216\n",
      "3398 -> Loss: 0.5033029317855835\n",
      "3399 -> Loss: 0.35941216349601746\n",
      "3400 -> Loss: 0.6361055970191956\n",
      "3401 -> Loss: 0.5233469009399414\n",
      "3402 -> Loss: 0.5696635246276855\n",
      "3403 -> Loss: 0.9126196503639221\n",
      "3404 -> Loss: 0.47185832262039185\n",
      "3405 -> Loss: 0.48121434450149536\n",
      "3406 -> Loss: 0.3380119800567627\n",
      "3407 -> Loss: 0.2759137451648712\n",
      "3408 -> Loss: 0.2590399384498596\n",
      "3409 -> Loss: 0.6907057762145996\n",
      "3410 -> Loss: 0.41575849056243896\n",
      "3411 -> Loss: 0.736427366733551\n",
      "3412 -> Loss: 0.8993589878082275\n",
      "3413 -> Loss: 0.2744262218475342\n",
      "3414 -> Loss: 0.9614335298538208\n",
      "3415 -> Loss: 0.46152010560035706\n",
      "3416 -> Loss: 1.1724152565002441\n",
      "3417 -> Loss: 0.5189707279205322\n",
      "3418 -> Loss: 0.5173641443252563\n",
      "3419 -> Loss: 0.6259772777557373\n",
      "3420 -> Loss: 0.11566095799207687\n",
      "3421 -> Loss: 0.5093963146209717\n",
      "3422 -> Loss: 0.5053005218505859\n",
      "3423 -> Loss: 0.3843921720981598\n",
      "3424 -> Loss: 0.3170483708381653\n",
      "3425 -> Loss: 0.3665623068809509\n",
      "3426 -> Loss: 0.30499663949012756\n",
      "3427 -> Loss: 0.4601060152053833\n",
      "3428 -> Loss: 0.07142741978168488\n",
      "3429 -> Loss: 0.126890629529953\n",
      "3430 -> Loss: 0.6051874160766602\n",
      "3431 -> Loss: 0.3870791494846344\n",
      "3432 -> Loss: 0.5750165581703186\n",
      "3433 -> Loss: 0.6886492371559143\n",
      "3434 -> Loss: 0.24761810898780823\n",
      "3435 -> Loss: 0.40487509965896606\n",
      "3436 -> Loss: 0.14402496814727783\n",
      "3437 -> Loss: 0.13536150753498077\n",
      "3438 -> Loss: 0.31659385561943054\n",
      "3439 -> Loss: 0.39917781949043274\n",
      "3440 -> Loss: 0.43986693024635315\n",
      "3441 -> Loss: 0.4035574793815613\n",
      "3442 -> Loss: 0.3628040850162506\n",
      "3443 -> Loss: 0.05946047976613045\n",
      "3444 -> Loss: 0.28571516275405884\n",
      "3445 -> Loss: 0.31009045243263245\n",
      "3446 -> Loss: 0.2017979770898819\n",
      "3447 -> Loss: 0.9549955129623413\n",
      "3448 -> Loss: 0.5564476251602173\n",
      "3449 -> Loss: 0.6316060423851013\n",
      "3450 -> Loss: 0.28402140736579895\n",
      "3451 -> Loss: 0.6385325193405151\n",
      "3452 -> Loss: 0.4213748276233673\n",
      "3453 -> Loss: 0.12862758338451385\n",
      "3454 -> Loss: 0.4038412570953369\n",
      "3455 -> Loss: 0.7013580203056335\n",
      "3456 -> Loss: 0.13401158154010773\n",
      "3457 -> Loss: 0.15504318475723267\n",
      "3458 -> Loss: 0.5260735154151917\n",
      "3459 -> Loss: 0.4134674072265625\n",
      "3460 -> Loss: 0.737872838973999\n",
      "3461 -> Loss: 0.643143892288208\n",
      "3462 -> Loss: 0.11221931129693985\n",
      "3463 -> Loss: 0.24572591483592987\n",
      "3464 -> Loss: 0.18528032302856445\n",
      "3465 -> Loss: 0.20389485359191895\n",
      "3466 -> Loss: 1.0771257877349854\n",
      "3467 -> Loss: 0.4936426281929016\n",
      "3468 -> Loss: 0.21481378376483917\n",
      "3469 -> Loss: 0.6502484083175659\n",
      "3470 -> Loss: 0.2930133044719696\n",
      "3471 -> Loss: 0.5504180192947388\n",
      "3472 -> Loss: 0.4217921495437622\n",
      "3473 -> Loss: 0.8647686243057251\n",
      "3474 -> Loss: 0.42399168014526367\n",
      "3475 -> Loss: 0.41861578822135925\n",
      "3476 -> Loss: 0.37198108434677124\n",
      "3477 -> Loss: 0.5423871874809265\n",
      "3478 -> Loss: 0.35800692439079285\n",
      "3479 -> Loss: 0.5111145973205566\n",
      "3480 -> Loss: 0.33428457379341125\n",
      "3481 -> Loss: 0.5751048922538757\n",
      "3482 -> Loss: 0.43378716707229614\n",
      "3483 -> Loss: 0.37814491987228394\n",
      "3484 -> Loss: 0.39766913652420044\n",
      "3485 -> Loss: 0.37594401836395264\n",
      "3486 -> Loss: 0.5293257832527161\n",
      "3487 -> Loss: 0.3691056966781616\n",
      "3488 -> Loss: 0.4329409599304199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3489 -> Loss: 0.49097028374671936\n",
      "3490 -> Loss: 0.9671489596366882\n",
      "3491 -> Loss: 0.6158559322357178\n",
      "3492 -> Loss: 0.5108720064163208\n",
      "3493 -> Loss: 0.8883898854255676\n",
      "3494 -> Loss: 0.8236611485481262\n",
      "3495 -> Loss: 0.33331841230392456\n",
      "3496 -> Loss: 0.39126530289649963\n",
      "3497 -> Loss: 0.41070684790611267\n",
      "3498 -> Loss: 0.4509291350841522\n",
      "3499 -> Loss: 0.5128753185272217\n",
      "3500 -> Loss: 0.08263424038887024\n",
      "3501 -> Loss: 0.3150462210178375\n",
      "3502 -> Loss: 0.40181106328964233\n",
      "3503 -> Loss: 0.5398712158203125\n",
      "3504 -> Loss: 0.4579780697822571\n",
      "3505 -> Loss: 0.40026459097862244\n",
      "3506 -> Loss: 0.6796720027923584\n",
      "3507 -> Loss: 0.4406299889087677\n",
      "3508 -> Loss: 0.28926408290863037\n",
      "3509 -> Loss: 0.4215927720069885\n",
      "3510 -> Loss: 0.7705248594284058\n",
      "3511 -> Loss: 0.23431746661663055\n",
      "3512 -> Loss: 0.8801308870315552\n",
      "3513 -> Loss: 0.5623769760131836\n",
      "3514 -> Loss: 0.9035126566886902\n",
      "3515 -> Loss: 0.6095193028450012\n",
      "3516 -> Loss: 0.7568979859352112\n",
      "3517 -> Loss: 0.34291794896125793\n",
      "3518 -> Loss: 0.6805120706558228\n",
      "3519 -> Loss: 0.3739551603794098\n",
      "3520 -> Loss: 0.2815397381782532\n",
      "3521 -> Loss: 0.38111481070518494\n",
      "3522 -> Loss: 0.6537005305290222\n",
      "3523 -> Loss: 0.2887887954711914\n",
      "3524 -> Loss: 0.21678899228572845\n",
      "3525 -> Loss: 0.31591349840164185\n",
      "3526 -> Loss: 0.49071651697158813\n",
      "3527 -> Loss: 0.4687817692756653\n",
      "3528 -> Loss: 0.8417102098464966\n",
      "3529 -> Loss: 0.18788005411624908\n",
      "3530 -> Loss: 0.5818897485733032\n",
      "3531 -> Loss: 0.7697368264198303\n",
      "3532 -> Loss: 0.5199989676475525\n",
      "3533 -> Loss: 0.5663531422615051\n",
      "3534 -> Loss: 0.611029863357544\n",
      "3535 -> Loss: 0.309327632188797\n",
      "3536 -> Loss: 0.4145965874195099\n",
      "3537 -> Loss: 0.6004589796066284\n",
      "3538 -> Loss: 0.4946378767490387\n",
      "3539 -> Loss: 0.36788055300712585\n",
      "3540 -> Loss: 0.582366406917572\n",
      "3541 -> Loss: 0.3684422969818115\n",
      "3542 -> Loss: 0.2379995882511139\n",
      "3543 -> Loss: 0.374952495098114\n",
      "3544 -> Loss: 0.6347123980522156\n",
      "3545 -> Loss: 0.18779867887496948\n",
      "3546 -> Loss: 0.7742516994476318\n",
      "3547 -> Loss: 0.3071693778038025\n",
      "3548 -> Loss: 0.2582865059375763\n",
      "3549 -> Loss: 0.2348848283290863\n",
      "3550 -> Loss: 0.6145584583282471\n",
      "3551 -> Loss: 0.5873027443885803\n",
      "3552 -> Loss: 0.3988492488861084\n",
      "3553 -> Loss: 0.3772999346256256\n",
      "3554 -> Loss: 0.28438055515289307\n",
      "3555 -> Loss: 0.8840333819389343\n",
      "3556 -> Loss: 0.7690211534500122\n",
      "3557 -> Loss: 0.6380585432052612\n",
      "3558 -> Loss: 0.8223069310188293\n",
      "3559 -> Loss: 0.492701917886734\n",
      "3560 -> Loss: 0.22222355008125305\n",
      "3561 -> Loss: 0.43719133734703064\n",
      "3562 -> Loss: 0.3608652651309967\n",
      "3563 -> Loss: 0.23164470493793488\n",
      "3564 -> Loss: 0.44154971837997437\n",
      "3565 -> Loss: 0.36594071984291077\n",
      "3566 -> Loss: 0.9247128963470459\n",
      "3567 -> Loss: 0.43182069063186646\n",
      "3568 -> Loss: 0.5982449054718018\n",
      "3569 -> Loss: 0.5536036491394043\n",
      "3570 -> Loss: 0.6910305619239807\n",
      "3571 -> Loss: 0.9910311102867126\n",
      "3572 -> Loss: 0.6463929414749146\n",
      "3573 -> Loss: 0.9976720809936523\n",
      "3574 -> Loss: 0.680963933467865\n",
      "3575 -> Loss: 0.48868098855018616\n",
      "3576 -> Loss: 0.4756665825843811\n",
      "3577 -> Loss: 0.6987748742103577\n",
      "3578 -> Loss: 0.5982621908187866\n",
      "3579 -> Loss: 0.4391448497772217\n",
      "3580 -> Loss: 0.47966304421424866\n",
      "3581 -> Loss: 0.6022497415542603\n",
      "3582 -> Loss: 0.18717467784881592\n",
      "3583 -> Loss: 0.6274945735931396\n",
      "3584 -> Loss: 0.5396970510482788\n",
      "3585 -> Loss: 0.48508673906326294\n",
      "3586 -> Loss: 0.5017544627189636\n",
      "3587 -> Loss: 0.8615685105323792\n",
      "3588 -> Loss: 0.9144551157951355\n",
      "3589 -> Loss: 0.18296223878860474\n",
      "3590 -> Loss: 0.8359008431434631\n",
      "3591 -> Loss: 0.6144858002662659\n",
      "3592 -> Loss: 0.49104225635528564\n",
      "3593 -> Loss: 0.4505068063735962\n",
      "3594 -> Loss: 0.29197341203689575\n",
      "3595 -> Loss: 0.6451783180236816\n",
      "3596 -> Loss: 0.3061516582965851\n",
      "3597 -> Loss: 0.6946672797203064\n",
      "3598 -> Loss: 0.12372434139251709\n",
      "3599 -> Loss: 0.4277304708957672\n",
      "3600 -> Loss: 0.3196675181388855\n",
      "3601 -> Loss: 0.47166529297828674\n",
      "3602 -> Loss: 0.2474154680967331\n",
      "3603 -> Loss: 0.47262728214263916\n",
      "3604 -> Loss: 0.5696720480918884\n",
      "3605 -> Loss: 0.3605736792087555\n",
      "3606 -> Loss: 0.6733818054199219\n",
      "3607 -> Loss: 0.3221152424812317\n",
      "3608 -> Loss: 0.2105514258146286\n",
      "3609 -> Loss: 0.2707866430282593\n",
      "3610 -> Loss: 0.6125217080116272\n",
      "3611 -> Loss: 0.6114835143089294\n",
      "3612 -> Loss: 0.21903519332408905\n",
      "3613 -> Loss: 0.40793776512145996\n",
      "3614 -> Loss: 0.8550918698310852\n",
      "3615 -> Loss: 0.20485791563987732\n",
      "3616 -> Loss: 0.5595917701721191\n",
      "3617 -> Loss: 0.46984151005744934\n",
      "3618 -> Loss: 0.5810002684593201\n",
      "3619 -> Loss: 0.563453197479248\n",
      "3620 -> Loss: 0.5366137027740479\n",
      "3621 -> Loss: 0.6736562252044678\n",
      "3622 -> Loss: 0.23694878816604614\n",
      "3623 -> Loss: 0.4994712769985199\n",
      "3624 -> Loss: 0.6267342567443848\n",
      "3625 -> Loss: 0.7027595043182373\n",
      "3626 -> Loss: 0.4344636797904968\n",
      "3627 -> Loss: 0.5767250657081604\n",
      "3628 -> Loss: 0.21423634886741638\n",
      "3629 -> Loss: 0.7539976835250854\n",
      "3630 -> Loss: 0.44457462430000305\n",
      "3631 -> Loss: 0.7579733729362488\n",
      "3632 -> Loss: 0.17881479859352112\n",
      "3633 -> Loss: 0.7387718558311462\n",
      "3634 -> Loss: 0.10732567310333252\n",
      "3635 -> Loss: 0.455852210521698\n",
      "3636 -> Loss: 0.5071211457252502\n",
      "3637 -> Loss: 0.7520268559455872\n",
      "3638 -> Loss: 0.6571728587150574\n",
      "3639 -> Loss: 0.28433334827423096\n",
      "3640 -> Loss: 0.32316136360168457\n",
      "3641 -> Loss: 0.40184569358825684\n",
      "3642 -> Loss: 0.19489113986492157\n",
      "3643 -> Loss: 0.4251246452331543\n",
      "3644 -> Loss: 0.5337547659873962\n",
      "3645 -> Loss: 0.33184996247291565\n",
      "3646 -> Loss: 0.49797654151916504\n",
      "3647 -> Loss: 0.5418688654899597\n",
      "3648 -> Loss: 0.7376666069030762\n",
      "3649 -> Loss: 0.521628737449646\n",
      "3650 -> Loss: 0.8261619806289673\n",
      "3651 -> Loss: 0.22771428525447845\n",
      "3652 -> Loss: 0.6581059694290161\n",
      "3653 -> Loss: 1.0208089351654053\n",
      "3654 -> Loss: 0.4793528616428375\n",
      "3655 -> Loss: 0.5730361342430115\n",
      "3656 -> Loss: 0.3780762255191803\n",
      "3657 -> Loss: 0.4633506238460541\n",
      "3658 -> Loss: 0.6959052085876465\n",
      "3659 -> Loss: 0.47699809074401855\n",
      "3660 -> Loss: 0.43574148416519165\n",
      "3661 -> Loss: 0.6125105619430542\n",
      "3662 -> Loss: 0.4184066653251648\n",
      "3663 -> Loss: 0.21555864810943604\n",
      "3664 -> Loss: 0.3722018003463745\n",
      "3665 -> Loss: 0.3744444251060486\n",
      "3666 -> Loss: 0.6196404099464417\n",
      "3667 -> Loss: 0.37941575050354004\n",
      "3668 -> Loss: 0.28496649861335754\n",
      "3669 -> Loss: 0.44719061255455017\n",
      "3670 -> Loss: 0.9639440774917603\n",
      "3671 -> Loss: 0.0928710550069809\n",
      "3672 -> Loss: 0.2955482006072998\n",
      "3673 -> Loss: 0.9625051617622375\n",
      "3674 -> Loss: 0.48946183919906616\n",
      "3675 -> Loss: 0.7770510315895081\n",
      "3676 -> Loss: 0.7201211452484131\n",
      "3677 -> Loss: 0.4598495364189148\n",
      "3678 -> Loss: 0.3173390030860901\n",
      "3679 -> Loss: 0.6239079833030701\n",
      "3680 -> Loss: 0.8336531519889832\n",
      "3681 -> Loss: 0.9669651985168457\n",
      "3682 -> Loss: 0.09970743209123611\n",
      "3683 -> Loss: 0.6933743357658386\n",
      "3684 -> Loss: 0.6345372200012207\n",
      "3685 -> Loss: 0.3832840323448181\n",
      "3686 -> Loss: 0.3247596025466919\n",
      "3687 -> Loss: 0.54117351770401\n",
      "3688 -> Loss: 0.22342227399349213\n",
      "3689 -> Loss: 1.0049335956573486\n",
      "3690 -> Loss: 0.7011287212371826\n",
      "3691 -> Loss: 0.4226876497268677\n",
      "3692 -> Loss: 0.2806866765022278\n",
      "3693 -> Loss: 0.8072448968887329\n",
      "3694 -> Loss: 1.0086891651153564\n",
      "3695 -> Loss: 0.48302629590034485\n",
      "3696 -> Loss: 0.46809983253479004\n",
      "3697 -> Loss: 0.4851362109184265\n",
      "3698 -> Loss: 0.7314081788063049\n",
      "3699 -> Loss: 0.669357180595398\n",
      "3700 -> Loss: 0.39414703845977783\n",
      "3701 -> Loss: 0.33923834562301636\n",
      "3702 -> Loss: 0.3621947169303894\n",
      "3703 -> Loss: 0.4904327988624573\n",
      "3704 -> Loss: 0.44480541348457336\n",
      "3705 -> Loss: 0.5647273659706116\n",
      "3706 -> Loss: 0.41389718651771545\n",
      "3707 -> Loss: 0.6192992925643921\n",
      "3708 -> Loss: 0.6723337769508362\n",
      "3709 -> Loss: 0.830524206161499\n",
      "3710 -> Loss: 0.5199045538902283\n",
      "3711 -> Loss: 0.769207775592804\n",
      "3712 -> Loss: 0.3869864344596863\n",
      "3713 -> Loss: 0.6989077925682068\n",
      "3714 -> Loss: 0.426749587059021\n",
      "3715 -> Loss: 0.5400829911231995\n",
      "3716 -> Loss: 0.3394319415092468\n",
      "3717 -> Loss: 0.8276397585868835\n",
      "3718 -> Loss: 0.6913560628890991\n",
      "3719 -> Loss: 0.36948639154434204\n",
      "3720 -> Loss: 0.2471764236688614\n",
      "3721 -> Loss: 1.1134343147277832\n",
      "3722 -> Loss: 0.4328311085700989\n",
      "3723 -> Loss: 0.5602878928184509\n",
      "3724 -> Loss: 0.857759416103363\n",
      "3725 -> Loss: 0.4684939682483673\n",
      "3726 -> Loss: 0.4267890453338623\n",
      "3727 -> Loss: 0.4789749085903168\n",
      "3728 -> Loss: 0.7652345299720764\n",
      "3729 -> Loss: 0.6600490808486938\n",
      "3730 -> Loss: 0.6138852834701538\n",
      "3731 -> Loss: 0.5984960198402405\n",
      "3732 -> Loss: 0.39647895097732544\n",
      "3733 -> Loss: 0.4519629180431366\n",
      "3734 -> Loss: 0.8413577675819397\n",
      "3735 -> Loss: 0.799048662185669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3736 -> Loss: 0.3432021737098694\n",
      "3737 -> Loss: 0.42579054832458496\n",
      "3738 -> Loss: 0.35568559169769287\n",
      "3739 -> Loss: 0.292233407497406\n",
      "3740 -> Loss: 0.5338556170463562\n",
      "3741 -> Loss: 0.5247376561164856\n",
      "3742 -> Loss: 0.9093618392944336\n",
      "3743 -> Loss: 0.38599830865859985\n",
      "3744 -> Loss: 0.6417112946510315\n",
      "3745 -> Loss: 0.6375554800033569\n",
      "3746 -> Loss: 0.40475842356681824\n",
      "3747 -> Loss: 0.30372026562690735\n",
      "3748 -> Loss: 0.2742557227611542\n",
      "3749 -> Loss: 1.20908784866333\n",
      "3750 -> Loss: 0.270112007856369\n",
      "3751 -> Loss: 0.44411394000053406\n",
      "3752 -> Loss: 0.8584640622138977\n",
      "3753 -> Loss: 0.7182532548904419\n",
      "3754 -> Loss: 0.10936320573091507\n",
      "3755 -> Loss: 0.5495408773422241\n",
      "3756 -> Loss: 0.38925567269325256\n",
      "3757 -> Loss: 0.16524986922740936\n",
      "3758 -> Loss: 0.4498109817504883\n",
      "3759 -> Loss: 0.5899953842163086\n",
      "3760 -> Loss: 0.34367311000823975\n",
      "3761 -> Loss: 0.37960389256477356\n",
      "3762 -> Loss: 0.4367661476135254\n",
      "3763 -> Loss: 0.7000197172164917\n",
      "3764 -> Loss: 0.3369613587856293\n",
      "3765 -> Loss: 0.3144649267196655\n",
      "3766 -> Loss: 0.3634278178215027\n",
      "3767 -> Loss: 0.7367768883705139\n",
      "3768 -> Loss: 0.3194417655467987\n",
      "3769 -> Loss: 0.4160286486148834\n",
      "3770 -> Loss: 0.39881008863449097\n",
      "3771 -> Loss: 0.8707802295684814\n",
      "3772 -> Loss: 0.48650071024894714\n",
      "3773 -> Loss: 0.41575631499290466\n",
      "3774 -> Loss: 0.8217299580574036\n",
      "3775 -> Loss: 0.4153765141963959\n",
      "3776 -> Loss: 0.5722776651382446\n",
      "3777 -> Loss: 0.5183725357055664\n",
      "3778 -> Loss: 0.8927688002586365\n",
      "3779 -> Loss: 0.3860531449317932\n",
      "3780 -> Loss: 0.6971675157546997\n",
      "3781 -> Loss: 0.7421301007270813\n",
      "3782 -> Loss: 0.3168138265609741\n",
      "3783 -> Loss: 0.7495040893554688\n",
      "3784 -> Loss: 0.42242226004600525\n",
      "3785 -> Loss: 0.5752761363983154\n",
      "3786 -> Loss: 0.16743506491184235\n",
      "3787 -> Loss: 0.6511714458465576\n",
      "3788 -> Loss: 0.621349036693573\n",
      "3789 -> Loss: 0.18241046369075775\n",
      "3790 -> Loss: 0.2862652838230133\n",
      "3791 -> Loss: 0.7890159487724304\n",
      "3792 -> Loss: 0.21280938386917114\n",
      "3793 -> Loss: 0.42807674407958984\n",
      "3794 -> Loss: 0.6448607444763184\n",
      "3795 -> Loss: 0.6450492143630981\n",
      "3796 -> Loss: 0.21484144032001495\n",
      "3797 -> Loss: 0.38086608052253723\n",
      "3798 -> Loss: 0.07977743446826935\n",
      "3799 -> Loss: 0.2387816309928894\n",
      "3800 -> Loss: 0.6452412605285645\n",
      "3801 -> Loss: 1.124751329421997\n",
      "3802 -> Loss: 0.3169679343700409\n",
      "3803 -> Loss: 0.3522014319896698\n",
      "3804 -> Loss: 0.41119253635406494\n",
      "3805 -> Loss: 0.3675089180469513\n",
      "3806 -> Loss: 0.41415151953697205\n",
      "3807 -> Loss: 0.5979740619659424\n",
      "3808 -> Loss: 0.3444339632987976\n",
      "3809 -> Loss: 0.9718003273010254\n",
      "3810 -> Loss: 0.30741333961486816\n",
      "3811 -> Loss: 0.8707245588302612\n",
      "3812 -> Loss: 0.49405747652053833\n",
      "3813 -> Loss: 0.5682919025421143\n",
      "3814 -> Loss: 0.7529650926589966\n",
      "3815 -> Loss: 0.2226392775774002\n",
      "3816 -> Loss: 0.4912479817867279\n",
      "3817 -> Loss: 0.3245011866092682\n",
      "3818 -> Loss: 0.36889252066612244\n",
      "3819 -> Loss: 0.35283195972442627\n",
      "3820 -> Loss: 0.10034341365098953\n",
      "3821 -> Loss: 0.5428547859191895\n",
      "3822 -> Loss: 0.5384936332702637\n",
      "3823 -> Loss: 0.5271782875061035\n",
      "3824 -> Loss: 0.4012812674045563\n",
      "3825 -> Loss: 0.4974321722984314\n",
      "3826 -> Loss: 0.45916008949279785\n",
      "3827 -> Loss: 0.37301966547966003\n",
      "3828 -> Loss: 0.6658430695533752\n",
      "3829 -> Loss: 0.42063724994659424\n",
      "3830 -> Loss: 0.42363473773002625\n",
      "3831 -> Loss: 0.4000726044178009\n",
      "3832 -> Loss: 0.21396593749523163\n",
      "3833 -> Loss: 0.22832688689231873\n",
      "3834 -> Loss: 0.7953450083732605\n",
      "3835 -> Loss: 0.23891928791999817\n",
      "3836 -> Loss: 0.5330958366394043\n",
      "3837 -> Loss: 0.6239625811576843\n",
      "3838 -> Loss: 0.7467832565307617\n",
      "3839 -> Loss: 0.36142870783805847\n",
      "3840 -> Loss: 0.45133987069129944\n",
      "3841 -> Loss: 0.5939222574234009\n",
      "3842 -> Loss: 0.22413882613182068\n",
      "3843 -> Loss: 0.30479511618614197\n",
      "3844 -> Loss: 0.98103928565979\n",
      "3845 -> Loss: 0.4946304261684418\n",
      "3846 -> Loss: 0.5229001641273499\n",
      "3847 -> Loss: 0.5838610529899597\n",
      "3848 -> Loss: 0.24676086008548737\n",
      "3849 -> Loss: 0.10133230686187744\n",
      "3850 -> Loss: 0.7497397661209106\n",
      "3851 -> Loss: 0.27145662903785706\n",
      "3852 -> Loss: 0.37616047263145447\n",
      "3853 -> Loss: 0.5677293539047241\n",
      "3854 -> Loss: 0.6929678916931152\n",
      "3855 -> Loss: 0.4248104691505432\n",
      "3856 -> Loss: 0.3042033314704895\n",
      "3857 -> Loss: 1.3752410411834717\n",
      "3858 -> Loss: 0.5032817125320435\n",
      "3859 -> Loss: 0.14581722021102905\n",
      "3860 -> Loss: 0.6281042098999023\n",
      "3861 -> Loss: 0.3882021903991699\n",
      "3862 -> Loss: 0.2065773755311966\n",
      "3863 -> Loss: 0.6126593351364136\n",
      "3864 -> Loss: 0.24246719479560852\n",
      "3865 -> Loss: 0.17151328921318054\n",
      "3866 -> Loss: 0.7101534008979797\n",
      "3867 -> Loss: 0.3059447407722473\n",
      "3868 -> Loss: 0.30271804332733154\n",
      "3869 -> Loss: 0.39144018292427063\n",
      "3870 -> Loss: 0.7729920148849487\n",
      "3871 -> Loss: 0.5018342137336731\n",
      "3872 -> Loss: 0.3024623394012451\n",
      "3873 -> Loss: 0.43738144636154175\n",
      "3874 -> Loss: 0.28148090839385986\n",
      "3875 -> Loss: 0.45731106400489807\n",
      "3876 -> Loss: 0.7992990612983704\n",
      "3877 -> Loss: 0.45383816957473755\n",
      "3878 -> Loss: 0.7380420565605164\n",
      "3879 -> Loss: 0.490561306476593\n",
      "3880 -> Loss: 0.49072813987731934\n",
      "3881 -> Loss: 1.0093270540237427\n",
      "3882 -> Loss: 0.4961158335208893\n",
      "3883 -> Loss: 0.4973547160625458\n",
      "3884 -> Loss: 0.2580838203430176\n",
      "3885 -> Loss: 0.2531518340110779\n",
      "3886 -> Loss: 0.35374715924263\n",
      "3887 -> Loss: 0.5821283459663391\n",
      "3888 -> Loss: 0.8472043871879578\n",
      "3889 -> Loss: 0.823232889175415\n",
      "3890 -> Loss: 0.3737867474555969\n",
      "3891 -> Loss: 0.38999220728874207\n",
      "3892 -> Loss: 0.6817724108695984\n",
      "3893 -> Loss: 0.3941769301891327\n",
      "3894 -> Loss: 0.6419321894645691\n",
      "3895 -> Loss: 0.6444521546363831\n",
      "3896 -> Loss: 0.6202809810638428\n",
      "3897 -> Loss: 0.5584364533424377\n",
      "3898 -> Loss: 0.321331262588501\n",
      "3899 -> Loss: 0.17263279855251312\n",
      "3900 -> Loss: 0.16320788860321045\n",
      "3901 -> Loss: 0.12712864577770233\n",
      "3902 -> Loss: 0.37355634570121765\n",
      "3903 -> Loss: 0.54961097240448\n",
      "3904 -> Loss: 0.5111831426620483\n",
      "3905 -> Loss: 0.5466266870498657\n",
      "3906 -> Loss: 0.21235501766204834\n",
      "3907 -> Loss: 0.30627790093421936\n",
      "3908 -> Loss: 0.562243640422821\n",
      "3909 -> Loss: 0.6196264028549194\n",
      "3910 -> Loss: 0.26559919118881226\n",
      "3911 -> Loss: 0.12080129981040955\n",
      "3912 -> Loss: 0.6401001811027527\n",
      "3913 -> Loss: 0.6297521591186523\n",
      "3914 -> Loss: 0.12081589549779892\n",
      "3915 -> Loss: 0.8417085409164429\n",
      "3916 -> Loss: 0.6463496685028076\n",
      "3917 -> Loss: 0.6586118936538696\n",
      "3918 -> Loss: 0.7641854882240295\n",
      "3919 -> Loss: 0.3756447434425354\n",
      "3920 -> Loss: 0.37356674671173096\n",
      "3921 -> Loss: 0.613847017288208\n",
      "3922 -> Loss: 0.12166725099086761\n",
      "3923 -> Loss: 0.4525270164012909\n",
      "3924 -> Loss: 0.36789432168006897\n",
      "3925 -> Loss: 0.8826252818107605\n",
      "3926 -> Loss: 0.2781258821487427\n",
      "3927 -> Loss: 0.5518046617507935\n",
      "3928 -> Loss: 0.5451341867446899\n",
      "3929 -> Loss: 0.48229819536209106\n",
      "3930 -> Loss: 0.3420924246311188\n",
      "3931 -> Loss: 1.10079824924469\n",
      "3932 -> Loss: 0.7769739031791687\n",
      "3933 -> Loss: 0.5687977075576782\n",
      "3934 -> Loss: 0.32078298926353455\n",
      "3935 -> Loss: 0.454313188791275\n",
      "3936 -> Loss: 0.6499581933021545\n",
      "3937 -> Loss: 0.676280677318573\n",
      "3938 -> Loss: 0.8310565948486328\n",
      "3939 -> Loss: 0.42189645767211914\n",
      "3940 -> Loss: 0.34658434987068176\n",
      "3941 -> Loss: 0.3540227711200714\n",
      "3942 -> Loss: 0.6944291591644287\n",
      "3943 -> Loss: 0.3725179433822632\n",
      "3944 -> Loss: 0.40465930104255676\n",
      "3945 -> Loss: 0.6687735319137573\n",
      "3946 -> Loss: 0.896265983581543\n",
      "3947 -> Loss: 0.2551400363445282\n",
      "3948 -> Loss: 0.09285318106412888\n",
      "3949 -> Loss: 0.6627282500267029\n",
      "3950 -> Loss: 0.335611492395401\n",
      "3951 -> Loss: 0.3209232687950134\n",
      "3952 -> Loss: 0.5765178203582764\n",
      "3953 -> Loss: 0.5190932154655457\n",
      "3954 -> Loss: 0.6356255412101746\n",
      "3955 -> Loss: 0.8858888745307922\n",
      "3956 -> Loss: 0.41704368591308594\n",
      "3957 -> Loss: 0.4375714361667633\n",
      "3958 -> Loss: 0.6142764687538147\n",
      "3959 -> Loss: 0.32705968618392944\n",
      "3960 -> Loss: 0.34390538930892944\n",
      "3961 -> Loss: 0.21130801737308502\n",
      "3962 -> Loss: 0.5224623084068298\n",
      "3963 -> Loss: 0.6395040154457092\n",
      "3964 -> Loss: 0.34437063336372375\n",
      "3965 -> Loss: 0.710635781288147\n",
      "3966 -> Loss: 0.4476792812347412\n",
      "3967 -> Loss: 0.37580710649490356\n",
      "3968 -> Loss: 0.31045860052108765\n",
      "3969 -> Loss: 0.4476606845855713\n",
      "3970 -> Loss: 0.9338633418083191\n",
      "3971 -> Loss: 0.40905889868736267\n",
      "3972 -> Loss: 1.000059962272644\n",
      "3973 -> Loss: 0.6775646805763245\n",
      "3974 -> Loss: 0.34574228525161743\n",
      "3975 -> Loss: 1.0602097511291504\n",
      "3976 -> Loss: 0.8217297196388245\n",
      "3977 -> Loss: 0.38441428542137146\n",
      "3978 -> Loss: 1.0097711086273193\n",
      "3979 -> Loss: 0.7446016669273376\n",
      "3980 -> Loss: 0.4803106486797333\n",
      "3981 -> Loss: 0.39364176988601685\n",
      "3982 -> Loss: 0.37323784828186035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3983 -> Loss: 0.28351345658302307\n",
      "3984 -> Loss: 0.45766931772232056\n",
      "3985 -> Loss: 0.6193770170211792\n",
      "3986 -> Loss: 0.5360029339790344\n",
      "3987 -> Loss: 0.2959366738796234\n",
      "3988 -> Loss: 0.35712164640426636\n",
      "3989 -> Loss: 0.6055095791816711\n",
      "3990 -> Loss: 0.16504666209220886\n",
      "3991 -> Loss: 0.6373705863952637\n",
      "3992 -> Loss: 0.7779238820075989\n",
      "3993 -> Loss: 0.8513798117637634\n",
      "3994 -> Loss: 0.777021586894989\n",
      "3995 -> Loss: 0.7404495477676392\n",
      "3996 -> Loss: 0.28082290291786194\n",
      "3997 -> Loss: 0.7418543100357056\n",
      "3998 -> Loss: 0.8973482251167297\n",
      "3999 -> Loss: 0.6786487102508545\n",
      "4000 -> Loss: 0.4906977117061615\n",
      "\n",
      "Validation Accuracy: 68.5, Test Accuracy: 73.0 \n",
      "\n",
      "4001 -> Loss: 1.2212183475494385\n",
      "4002 -> Loss: 0.381523072719574\n",
      "4003 -> Loss: 0.3047163188457489\n",
      "4004 -> Loss: 0.6080929040908813\n",
      "4005 -> Loss: 0.5316324234008789\n",
      "4006 -> Loss: 0.5097926259040833\n",
      "4007 -> Loss: 0.24223873019218445\n",
      "4008 -> Loss: 0.7684056162834167\n",
      "4009 -> Loss: 0.4153101146221161\n",
      "4010 -> Loss: 0.6498619914054871\n",
      "4011 -> Loss: 0.4398912489414215\n",
      "4012 -> Loss: 1.0710805654525757\n",
      "4013 -> Loss: 0.2635134160518646\n",
      "4014 -> Loss: 0.4839228093624115\n",
      "4015 -> Loss: 0.37755125761032104\n",
      "4016 -> Loss: 0.252491295337677\n",
      "4017 -> Loss: 0.8246474862098694\n",
      "4018 -> Loss: 0.5310910940170288\n",
      "4019 -> Loss: 0.22825291752815247\n",
      "4020 -> Loss: 0.4183884859085083\n",
      "4021 -> Loss: 0.7545413970947266\n",
      "4022 -> Loss: 0.8816204071044922\n",
      "4023 -> Loss: 0.5728297829627991\n",
      "4024 -> Loss: 0.47655487060546875\n",
      "4025 -> Loss: 0.4652591347694397\n",
      "4026 -> Loss: 0.3191105127334595\n",
      "4027 -> Loss: 0.4465726315975189\n",
      "4028 -> Loss: 0.992472767829895\n",
      "4029 -> Loss: 0.6934804320335388\n",
      "4030 -> Loss: 0.7596338391304016\n",
      "4031 -> Loss: 1.3119635581970215\n",
      "4032 -> Loss: 0.2720203399658203\n",
      "4033 -> Loss: 0.10664601624011993\n",
      "4034 -> Loss: 0.24368816614151\n",
      "4035 -> Loss: 0.7779415845870972\n",
      "4036 -> Loss: 0.5802141427993774\n",
      "4037 -> Loss: 0.3274679481983185\n",
      "4038 -> Loss: 0.5291752815246582\n",
      "4039 -> Loss: 0.7403586506843567\n",
      "4040 -> Loss: 0.6007009744644165\n",
      "4041 -> Loss: 1.2954974174499512\n",
      "4042 -> Loss: 0.37330150604248047\n",
      "4043 -> Loss: 0.3063508868217468\n",
      "4044 -> Loss: 0.5008982419967651\n",
      "4045 -> Loss: 0.334895521402359\n",
      "4046 -> Loss: 0.4415532052516937\n",
      "4047 -> Loss: 1.006459355354309\n",
      "4048 -> Loss: 0.2851576507091522\n",
      "4049 -> Loss: 0.24935181438922882\n",
      "4050 -> Loss: 0.4134170413017273\n",
      "4051 -> Loss: 0.8562234044075012\n",
      "4052 -> Loss: 0.16174259781837463\n",
      "4053 -> Loss: 0.5462107062339783\n",
      "4054 -> Loss: 0.4491061270236969\n",
      "4055 -> Loss: 0.35878807306289673\n",
      "4056 -> Loss: 0.6083217263221741\n",
      "4057 -> Loss: 0.17149537801742554\n",
      "4058 -> Loss: 0.3584420084953308\n",
      "4059 -> Loss: 0.3993905484676361\n",
      "4060 -> Loss: 0.48148003220558167\n",
      "4061 -> Loss: 0.40542072057724\n",
      "4062 -> Loss: 0.8257721066474915\n",
      "4063 -> Loss: 0.48294031620025635\n",
      "4064 -> Loss: 0.45222291350364685\n",
      "4065 -> Loss: 0.7335083484649658\n",
      "4066 -> Loss: 0.24603739380836487\n",
      "4067 -> Loss: 0.5139423608779907\n",
      "4068 -> Loss: 0.5648073554039001\n",
      "4069 -> Loss: 0.2518174946308136\n",
      "4070 -> Loss: 0.9807841181755066\n",
      "4071 -> Loss: 0.7113283276557922\n",
      "4072 -> Loss: 0.9477370381355286\n",
      "4073 -> Loss: 0.6992892026901245\n",
      "4074 -> Loss: 0.33816197514533997\n",
      "4075 -> Loss: 0.20357418060302734\n",
      "4076 -> Loss: 0.3710780143737793\n",
      "4077 -> Loss: 0.39915841817855835\n",
      "4078 -> Loss: 0.6287094354629517\n",
      "4079 -> Loss: 0.17887598276138306\n",
      "4080 -> Loss: 0.6245967149734497\n",
      "4081 -> Loss: 0.35322731733322144\n",
      "4082 -> Loss: 0.2858683168888092\n",
      "4083 -> Loss: 0.4519636332988739\n",
      "4084 -> Loss: 1.0373302698135376\n",
      "4085 -> Loss: 0.6730486154556274\n",
      "4086 -> Loss: 0.4995274543762207\n",
      "4087 -> Loss: 0.32099127769470215\n",
      "4088 -> Loss: 0.4948585033416748\n",
      "4089 -> Loss: 0.816459059715271\n",
      "4090 -> Loss: 0.34635502099990845\n",
      "4091 -> Loss: 0.5973610877990723\n",
      "4092 -> Loss: 0.37909233570098877\n",
      "4093 -> Loss: 0.8323019742965698\n",
      "4094 -> Loss: 0.29659584164619446\n",
      "4095 -> Loss: 0.536045491695404\n",
      "4096 -> Loss: 0.31555283069610596\n",
      "4097 -> Loss: 1.0195341110229492\n",
      "4098 -> Loss: 0.5529349446296692\n",
      "4099 -> Loss: 0.5878937244415283\n",
      "4100 -> Loss: 0.715961217880249\n",
      "4101 -> Loss: 0.5628564357757568\n",
      "4102 -> Loss: 0.697374701499939\n",
      "4103 -> Loss: 0.6542834639549255\n",
      "4104 -> Loss: 0.7287800312042236\n",
      "4105 -> Loss: 0.6101163029670715\n",
      "4106 -> Loss: 0.7045171856880188\n",
      "4107 -> Loss: 0.38374602794647217\n",
      "4108 -> Loss: 0.26381146907806396\n",
      "4109 -> Loss: 0.7070357799530029\n",
      "4110 -> Loss: 0.7002705335617065\n",
      "4111 -> Loss: 0.6300045847892761\n",
      "4112 -> Loss: 0.5337152481079102\n",
      "4113 -> Loss: 1.0460504293441772\n",
      "4114 -> Loss: 0.6396006345748901\n",
      "4115 -> Loss: 0.7877559065818787\n",
      "4116 -> Loss: 0.5982071161270142\n",
      "4117 -> Loss: 0.47886204719543457\n",
      "4118 -> Loss: 0.09096334129571915\n",
      "4119 -> Loss: 0.3796237111091614\n",
      "4120 -> Loss: 0.5744128823280334\n",
      "4121 -> Loss: 0.16417570412158966\n",
      "4122 -> Loss: 0.4347033202648163\n",
      "4123 -> Loss: 0.45434948801994324\n",
      "4124 -> Loss: 0.45502668619155884\n",
      "4125 -> Loss: 0.45543453097343445\n",
      "4126 -> Loss: 0.6055103540420532\n",
      "4127 -> Loss: 0.5060535073280334\n",
      "4128 -> Loss: 0.3879343569278717\n",
      "4129 -> Loss: 0.992332935333252\n",
      "4130 -> Loss: 0.4955390989780426\n",
      "4131 -> Loss: 0.851949155330658\n",
      "4132 -> Loss: 0.35289886593818665\n",
      "4133 -> Loss: 0.7764197587966919\n",
      "4134 -> Loss: 0.34213119745254517\n",
      "4135 -> Loss: 1.063507080078125\n",
      "4136 -> Loss: 0.40775227546691895\n",
      "4137 -> Loss: 0.5296218991279602\n",
      "4138 -> Loss: 0.4402189552783966\n",
      "4139 -> Loss: 0.6166388392448425\n",
      "4140 -> Loss: 0.419890433549881\n",
      "4141 -> Loss: 0.719367504119873\n",
      "4142 -> Loss: 0.7733954191207886\n",
      "4143 -> Loss: 0.6784018278121948\n",
      "4144 -> Loss: 0.5825611352920532\n",
      "4145 -> Loss: 0.07005176693201065\n",
      "4146 -> Loss: 0.2107621133327484\n",
      "4147 -> Loss: 0.44656243920326233\n",
      "4148 -> Loss: 0.5017751455307007\n",
      "4149 -> Loss: 0.20292875170707703\n",
      "4150 -> Loss: 0.38769087195396423\n",
      "4151 -> Loss: 0.5689647793769836\n",
      "4152 -> Loss: 0.7079711556434631\n",
      "4153 -> Loss: 0.6535722017288208\n",
      "4154 -> Loss: 0.5861973762512207\n",
      "4155 -> Loss: 0.803749144077301\n",
      "4156 -> Loss: 0.4722050726413727\n",
      "4157 -> Loss: 0.8131424188613892\n",
      "4158 -> Loss: 1.0024631023406982\n",
      "4159 -> Loss: 0.7236862182617188\n",
      "4160 -> Loss: 0.6947409510612488\n",
      "4161 -> Loss: 0.410484254360199\n",
      "4162 -> Loss: 0.8811596035957336\n",
      "4163 -> Loss: 0.6475945115089417\n",
      "4164 -> Loss: 0.49428585171699524\n",
      "4165 -> Loss: 0.42957890033721924\n",
      "4166 -> Loss: 0.5074796676635742\n",
      "4167 -> Loss: 0.44236522912979126\n",
      "4168 -> Loss: 0.6713703274726868\n",
      "4169 -> Loss: 0.5177474021911621\n",
      "4170 -> Loss: 0.24333804845809937\n",
      "4171 -> Loss: 0.6698815226554871\n",
      "4172 -> Loss: 0.5837560296058655\n",
      "4173 -> Loss: 0.30831432342529297\n",
      "4174 -> Loss: 0.19443029165267944\n",
      "4175 -> Loss: 0.4496173560619354\n",
      "4176 -> Loss: 0.3537195026874542\n",
      "4177 -> Loss: 0.351836234331131\n",
      "4178 -> Loss: 0.34950047731399536\n",
      "4179 -> Loss: 0.35690951347351074\n",
      "4180 -> Loss: 0.5863586664199829\n",
      "4181 -> Loss: 0.8428565859794617\n",
      "4182 -> Loss: 0.33269137144088745\n",
      "4183 -> Loss: 0.7479312419891357\n",
      "4184 -> Loss: 0.736979603767395\n",
      "4185 -> Loss: 0.26676368713378906\n",
      "4186 -> Loss: 0.6538114547729492\n",
      "4187 -> Loss: 0.5512902736663818\n",
      "4188 -> Loss: 0.362621009349823\n",
      "4189 -> Loss: 0.4366496503353119\n",
      "4190 -> Loss: 0.20194092392921448\n",
      "4191 -> Loss: 1.0850698947906494\n",
      "4192 -> Loss: 0.458673357963562\n",
      "4193 -> Loss: 0.49842748045921326\n",
      "4194 -> Loss: 0.616245687007904\n",
      "4195 -> Loss: 0.7230942249298096\n",
      "4196 -> Loss: 0.4048915505409241\n",
      "4197 -> Loss: 0.3490504324436188\n",
      "4198 -> Loss: 0.3502974808216095\n",
      "4199 -> Loss: 0.17090420424938202\n",
      "4200 -> Loss: 0.8922505974769592\n",
      "4201 -> Loss: 0.2659296691417694\n",
      "4202 -> Loss: 0.5145553350448608\n",
      "4203 -> Loss: 0.7145276069641113\n",
      "4204 -> Loss: 1.0067318677902222\n",
      "4205 -> Loss: 0.48951882123947144\n",
      "4206 -> Loss: 0.2478027641773224\n",
      "4207 -> Loss: 0.29547515511512756\n",
      "4208 -> Loss: 0.2466297447681427\n",
      "4209 -> Loss: 1.015610933303833\n",
      "4210 -> Loss: 0.37444013357162476\n",
      "4211 -> Loss: 0.5213047862052917\n",
      "4212 -> Loss: 0.5548802614212036\n",
      "4213 -> Loss: 0.25353869795799255\n",
      "4214 -> Loss: 0.4918949604034424\n",
      "4215 -> Loss: 0.29190731048583984\n",
      "4216 -> Loss: 0.7539512515068054\n",
      "4217 -> Loss: 0.3394649028778076\n",
      "4218 -> Loss: 0.4494237005710602\n",
      "4219 -> Loss: 0.2534540295600891\n",
      "4220 -> Loss: 0.6262087821960449\n",
      "4221 -> Loss: 0.49315503239631653\n",
      "4222 -> Loss: 0.2876637279987335\n",
      "4223 -> Loss: 1.4382729530334473\n",
      "4224 -> Loss: 0.4705720841884613\n",
      "4225 -> Loss: 0.5343459844589233\n",
      "4226 -> Loss: 0.4655591547489166\n",
      "4227 -> Loss: 0.43043041229248047\n",
      "4228 -> Loss: 0.3202241063117981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229 -> Loss: 0.9669020175933838\n",
      "4230 -> Loss: 0.4972416162490845\n",
      "4231 -> Loss: 0.6770495772361755\n",
      "4232 -> Loss: 0.617667555809021\n",
      "4233 -> Loss: 0.7423809170722961\n",
      "4234 -> Loss: 0.3555912673473358\n",
      "4235 -> Loss: 0.5299884676933289\n",
      "4236 -> Loss: 0.4626416862010956\n",
      "4237 -> Loss: 0.6321544647216797\n",
      "4238 -> Loss: 0.7998590469360352\n",
      "4239 -> Loss: 0.6336766481399536\n",
      "4240 -> Loss: 0.7092546224594116\n",
      "4241 -> Loss: 0.17118629813194275\n",
      "4242 -> Loss: 0.19824503362178802\n",
      "4243 -> Loss: 0.566721498966217\n",
      "4244 -> Loss: 0.45388442277908325\n",
      "4245 -> Loss: 0.3000195622444153\n",
      "4246 -> Loss: 0.39488354325294495\n",
      "4247 -> Loss: 0.33465251326560974\n",
      "4248 -> Loss: 0.6091470122337341\n",
      "4249 -> Loss: 0.36915451288223267\n",
      "4250 -> Loss: 0.8268702626228333\n",
      "4251 -> Loss: 0.3700551986694336\n",
      "4252 -> Loss: 0.8854940533638\n",
      "4253 -> Loss: 0.45941463112831116\n",
      "4254 -> Loss: 0.41017627716064453\n",
      "4255 -> Loss: 0.5586594939231873\n",
      "4256 -> Loss: 0.623632550239563\n",
      "4257 -> Loss: 0.39537787437438965\n",
      "4258 -> Loss: 0.13175277411937714\n",
      "4259 -> Loss: 0.6975724697113037\n",
      "4260 -> Loss: 0.7234787344932556\n",
      "4261 -> Loss: 0.8456075191497803\n",
      "4262 -> Loss: 0.2972049117088318\n",
      "4263 -> Loss: 0.3802125155925751\n",
      "4264 -> Loss: 0.5161848068237305\n",
      "4265 -> Loss: 0.6723605990409851\n",
      "4266 -> Loss: 0.36080750823020935\n",
      "4267 -> Loss: 0.25101032853126526\n",
      "4268 -> Loss: 0.7184160947799683\n",
      "4269 -> Loss: 0.4556318521499634\n",
      "4270 -> Loss: 0.4129345417022705\n",
      "4271 -> Loss: 0.1408987045288086\n",
      "4272 -> Loss: 0.804796040058136\n",
      "4273 -> Loss: 0.7731318473815918\n",
      "4274 -> Loss: 0.3576193153858185\n",
      "4275 -> Loss: 0.992606520652771\n",
      "4276 -> Loss: 0.5735415816307068\n",
      "4277 -> Loss: 0.3144353926181793\n",
      "4278 -> Loss: 0.3043847382068634\n",
      "4279 -> Loss: 0.48415085673332214\n",
      "4280 -> Loss: 0.46450644731521606\n",
      "4281 -> Loss: 0.4339470863342285\n",
      "4282 -> Loss: 0.3036922216415405\n",
      "4283 -> Loss: 0.8399214744567871\n",
      "4284 -> Loss: 0.41818633675575256\n",
      "4285 -> Loss: 0.3413337469100952\n",
      "4286 -> Loss: 0.24249833822250366\n",
      "4287 -> Loss: 0.39367911219596863\n",
      "4288 -> Loss: 0.34404486417770386\n",
      "4289 -> Loss: 0.6734209060668945\n",
      "4290 -> Loss: 0.3310754895210266\n",
      "4291 -> Loss: 0.24695023894309998\n",
      "4292 -> Loss: 0.46197474002838135\n",
      "4293 -> Loss: 0.5322179198265076\n",
      "4294 -> Loss: 0.780651867389679\n",
      "4295 -> Loss: 0.6102673411369324\n",
      "4296 -> Loss: 0.7445796728134155\n",
      "4297 -> Loss: 0.10531289130449295\n",
      "4298 -> Loss: 0.5705246925354004\n",
      "4299 -> Loss: 0.19912190735340118\n",
      "4300 -> Loss: 0.7548819780349731\n",
      "4301 -> Loss: 0.1689513623714447\n",
      "4302 -> Loss: 0.846464216709137\n",
      "4303 -> Loss: 0.3712519705295563\n",
      "4304 -> Loss: 0.6923446655273438\n",
      "4305 -> Loss: 0.4696083664894104\n",
      "4306 -> Loss: 0.1937382072210312\n",
      "4307 -> Loss: 0.48746034502983093\n",
      "4308 -> Loss: 0.2506002187728882\n",
      "4309 -> Loss: 0.3022890090942383\n",
      "4310 -> Loss: 1.006452202796936\n",
      "4311 -> Loss: 0.3078777492046356\n",
      "4312 -> Loss: 0.22814223170280457\n",
      "4313 -> Loss: 0.5511006116867065\n",
      "4314 -> Loss: 0.5210840702056885\n",
      "4315 -> Loss: 0.2411181479692459\n",
      "4316 -> Loss: 0.8575974106788635\n",
      "4317 -> Loss: 0.7485957145690918\n",
      "4318 -> Loss: 0.3820508122444153\n",
      "4319 -> Loss: 0.637524425983429\n",
      "4320 -> Loss: 1.353183388710022\n",
      "4321 -> Loss: 0.45773008465766907\n",
      "4322 -> Loss: 1.0863500833511353\n",
      "4323 -> Loss: 0.11759315431118011\n",
      "4324 -> Loss: 0.5353947281837463\n",
      "4325 -> Loss: 0.43524542450904846\n",
      "4326 -> Loss: 0.6589443683624268\n",
      "4327 -> Loss: 0.6092660427093506\n",
      "4328 -> Loss: 0.4898569583892822\n",
      "4329 -> Loss: 0.40335649251937866\n",
      "4330 -> Loss: 0.2746986150741577\n",
      "4331 -> Loss: 0.2945478856563568\n",
      "4332 -> Loss: 0.37141212821006775\n",
      "4333 -> Loss: 0.4813412129878998\n",
      "4334 -> Loss: 0.5287852883338928\n",
      "4335 -> Loss: 0.2734391391277313\n",
      "4336 -> Loss: 0.33041349053382874\n",
      "4337 -> Loss: 0.2737938165664673\n",
      "4338 -> Loss: 0.6062064170837402\n",
      "4339 -> Loss: 0.46483975648880005\n",
      "4340 -> Loss: 0.4800777733325958\n",
      "4341 -> Loss: 0.49606919288635254\n",
      "4342 -> Loss: 0.5554854869842529\n",
      "4343 -> Loss: 0.4887230396270752\n",
      "4344 -> Loss: 0.8257591724395752\n",
      "4345 -> Loss: 0.8702854514122009\n",
      "4346 -> Loss: 0.4144553542137146\n",
      "4347 -> Loss: 0.6542375087738037\n",
      "4348 -> Loss: 0.4202565848827362\n",
      "4349 -> Loss: 0.6886416077613831\n",
      "4350 -> Loss: 0.39921700954437256\n",
      "4351 -> Loss: 0.34728819131851196\n",
      "4352 -> Loss: 0.2528427243232727\n",
      "4353 -> Loss: 0.1741275191307068\n",
      "4354 -> Loss: 1.072827935218811\n",
      "4355 -> Loss: 0.7335085272789001\n",
      "4356 -> Loss: 0.5082594752311707\n",
      "4357 -> Loss: 0.6733863353729248\n",
      "4358 -> Loss: 0.3832896649837494\n",
      "4359 -> Loss: 0.7468273043632507\n",
      "4360 -> Loss: 0.304828941822052\n",
      "4361 -> Loss: 0.2936060428619385\n",
      "4362 -> Loss: 0.3987225890159607\n",
      "4363 -> Loss: 0.2821260690689087\n",
      "4364 -> Loss: 0.4646317958831787\n",
      "4365 -> Loss: 0.5446089506149292\n",
      "4366 -> Loss: 0.5230904817581177\n",
      "4367 -> Loss: 0.783082902431488\n",
      "4368 -> Loss: 0.5845863223075867\n",
      "4369 -> Loss: 0.21195805072784424\n",
      "4370 -> Loss: 0.5431445837020874\n",
      "4371 -> Loss: 0.43944478034973145\n",
      "4372 -> Loss: 0.7611885070800781\n",
      "4373 -> Loss: 0.5218159556388855\n",
      "4374 -> Loss: 0.368727445602417\n",
      "4375 -> Loss: 0.3475317060947418\n",
      "4376 -> Loss: 0.5478957891464233\n",
      "4377 -> Loss: 0.34810662269592285\n",
      "4378 -> Loss: 0.22783924639225006\n",
      "4379 -> Loss: 0.28578445315361023\n",
      "4380 -> Loss: 0.48284685611724854\n",
      "4381 -> Loss: 0.29102370142936707\n",
      "4382 -> Loss: 0.589002788066864\n",
      "4383 -> Loss: 0.1798344999551773\n",
      "4384 -> Loss: 0.6144891977310181\n",
      "4385 -> Loss: 1.0158329010009766\n",
      "4386 -> Loss: 0.5254749059677124\n",
      "4387 -> Loss: 0.24027247726917267\n",
      "4388 -> Loss: 0.4899318814277649\n",
      "4389 -> Loss: 0.6689244508743286\n",
      "4390 -> Loss: 0.36715584993362427\n",
      "4391 -> Loss: 0.5929166674613953\n",
      "4392 -> Loss: 0.5362765789031982\n",
      "4393 -> Loss: 0.3265199363231659\n",
      "4394 -> Loss: 0.3276884853839874\n",
      "4395 -> Loss: 0.4884259104728699\n",
      "4396 -> Loss: 0.8019211888313293\n",
      "4397 -> Loss: 0.8913226127624512\n",
      "4398 -> Loss: 0.5284750461578369\n",
      "4399 -> Loss: 1.1248664855957031\n",
      "4400 -> Loss: 0.14267197251319885\n",
      "4401 -> Loss: 0.41329264640808105\n",
      "4402 -> Loss: 0.4914955496788025\n",
      "4403 -> Loss: 0.36563754081726074\n",
      "4404 -> Loss: 0.47237375378608704\n",
      "4405 -> Loss: 0.4309605062007904\n",
      "4406 -> Loss: 0.46682676672935486\n",
      "4407 -> Loss: 0.35082879662513733\n",
      "4408 -> Loss: 1.0456770658493042\n",
      "4409 -> Loss: 0.3531607389450073\n",
      "4410 -> Loss: 0.16655443608760834\n",
      "4411 -> Loss: 0.30811652541160583\n",
      "4412 -> Loss: 0.20228828489780426\n",
      "4413 -> Loss: 0.18799853324890137\n",
      "4414 -> Loss: 0.6143014430999756\n",
      "4415 -> Loss: 0.33081692457199097\n",
      "4416 -> Loss: 0.8397859930992126\n",
      "4417 -> Loss: 0.543220579624176\n",
      "4418 -> Loss: 0.5132797360420227\n",
      "4419 -> Loss: 0.6696085333824158\n",
      "4420 -> Loss: 0.628015398979187\n",
      "4421 -> Loss: 0.33176231384277344\n",
      "4422 -> Loss: 0.7680902481079102\n",
      "4423 -> Loss: 0.27554622292518616\n",
      "4424 -> Loss: 0.41441041231155396\n",
      "4425 -> Loss: 0.5297558307647705\n",
      "4426 -> Loss: 0.7268077731132507\n",
      "4427 -> Loss: 0.7218407392501831\n",
      "4428 -> Loss: 0.6525518894195557\n",
      "4429 -> Loss: 0.14948011934757233\n",
      "4430 -> Loss: 0.5623568296432495\n",
      "4431 -> Loss: 0.5691722631454468\n",
      "4432 -> Loss: 0.4533931314945221\n",
      "4433 -> Loss: 0.6175983548164368\n",
      "4434 -> Loss: 0.6093795895576477\n",
      "4435 -> Loss: 0.3462800681591034\n",
      "4436 -> Loss: 0.9638234376907349\n",
      "4437 -> Loss: 0.7843005657196045\n",
      "4438 -> Loss: 0.2727118134498596\n",
      "4439 -> Loss: 0.5889230966567993\n",
      "4440 -> Loss: 0.8131939768791199\n",
      "4441 -> Loss: 0.630296528339386\n",
      "4442 -> Loss: 0.3976190388202667\n",
      "4443 -> Loss: 0.35955700278282166\n",
      "4444 -> Loss: 0.6004457473754883\n",
      "4445 -> Loss: 0.5462268590927124\n",
      "4446 -> Loss: 0.3905523419380188\n",
      "4447 -> Loss: 0.44581541419029236\n",
      "4448 -> Loss: 0.31524261832237244\n",
      "4449 -> Loss: 1.3850178718566895\n",
      "4450 -> Loss: 0.5437926650047302\n",
      "4451 -> Loss: 0.7167038917541504\n",
      "4452 -> Loss: 0.409800261259079\n",
      "4453 -> Loss: 0.2753687798976898\n",
      "4454 -> Loss: 0.4623830318450928\n",
      "4455 -> Loss: 0.45180243253707886\n",
      "4456 -> Loss: 0.3805367052555084\n",
      "4457 -> Loss: 0.915685772895813\n",
      "4458 -> Loss: 0.5259696245193481\n",
      "4459 -> Loss: 0.5092183351516724\n",
      "4460 -> Loss: 0.498649537563324\n",
      "4461 -> Loss: 0.6243839859962463\n",
      "4462 -> Loss: 0.7122544050216675\n",
      "4463 -> Loss: 0.3435094356536865\n",
      "4464 -> Loss: 0.2735775113105774\n",
      "4465 -> Loss: 0.18043844401836395\n",
      "4466 -> Loss: 0.5440166592597961\n",
      "4467 -> Loss: 0.44136497378349304\n",
      "4468 -> Loss: 0.8053930997848511\n",
      "4469 -> Loss: 0.13069453835487366\n",
      "4470 -> Loss: 0.48529553413391113\n",
      "4471 -> Loss: 0.7235879302024841\n",
      "4472 -> Loss: 0.7363183498382568\n",
      "4473 -> Loss: 0.7677844762802124\n",
      "4474 -> Loss: 0.23289255797863007\n",
      "4475 -> Loss: 0.3646717667579651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4476 -> Loss: 0.5878736972808838\n",
      "4477 -> Loss: 0.4675315320491791\n",
      "4478 -> Loss: 0.5279601216316223\n",
      "4479 -> Loss: 1.0035465955734253\n",
      "4480 -> Loss: 0.6351914405822754\n",
      "4481 -> Loss: 0.4929311275482178\n",
      "4482 -> Loss: 0.11803578585386276\n",
      "4483 -> Loss: 0.6235116720199585\n",
      "4484 -> Loss: 0.4695885181427002\n",
      "4485 -> Loss: 0.41513553261756897\n",
      "4486 -> Loss: 0.36554983258247375\n",
      "4487 -> Loss: 0.26845353841781616\n",
      "4488 -> Loss: 0.641502320766449\n",
      "4489 -> Loss: 0.5997942090034485\n",
      "4490 -> Loss: 0.45004355907440186\n",
      "4491 -> Loss: 0.904541015625\n",
      "4492 -> Loss: 0.5891513228416443\n",
      "4493 -> Loss: 0.35151320695877075\n",
      "4494 -> Loss: 0.24684825539588928\n",
      "4495 -> Loss: 0.5392006635665894\n",
      "4496 -> Loss: 0.8868497610092163\n",
      "4497 -> Loss: 0.6278976798057556\n",
      "4498 -> Loss: 0.41750213503837585\n",
      "4499 -> Loss: 0.7766048312187195\n",
      "4500 -> Loss: 0.5278530120849609\n",
      "4501 -> Loss: 0.8324658870697021\n",
      "4502 -> Loss: 0.1490786075592041\n",
      "4503 -> Loss: 0.41637587547302246\n",
      "4504 -> Loss: 0.04900688678026199\n",
      "4505 -> Loss: 0.654534101486206\n",
      "4506 -> Loss: 0.37501513957977295\n",
      "4507 -> Loss: 0.22894617915153503\n",
      "4508 -> Loss: 0.3260408341884613\n",
      "4509 -> Loss: 0.8152989149093628\n",
      "4510 -> Loss: 0.625568151473999\n",
      "4511 -> Loss: 0.6571415066719055\n",
      "4512 -> Loss: 0.5820763111114502\n",
      "4513 -> Loss: 0.3667643666267395\n",
      "4514 -> Loss: 1.2299202680587769\n",
      "4515 -> Loss: 0.7624648809432983\n",
      "4516 -> Loss: 0.683829665184021\n",
      "4517 -> Loss: 0.377145379781723\n",
      "4518 -> Loss: 0.5178006291389465\n",
      "4519 -> Loss: 0.5163072347640991\n",
      "4520 -> Loss: 0.6064804792404175\n",
      "4521 -> Loss: 0.508118748664856\n",
      "4522 -> Loss: 0.5459293127059937\n",
      "4523 -> Loss: 0.4389159083366394\n",
      "4524 -> Loss: 0.6776113510131836\n",
      "4525 -> Loss: 0.6568886041641235\n",
      "4526 -> Loss: 0.5953917503356934\n",
      "4527 -> Loss: 0.5029064416885376\n",
      "4528 -> Loss: 0.7908543944358826\n",
      "4529 -> Loss: 0.35566169023513794\n",
      "4530 -> Loss: 0.7015505433082581\n",
      "4531 -> Loss: 0.2151196449995041\n",
      "4532 -> Loss: 0.14918090403079987\n",
      "4533 -> Loss: 0.46414870023727417\n",
      "4534 -> Loss: 1.057502269744873\n",
      "4535 -> Loss: 0.4487549066543579\n",
      "4536 -> Loss: 0.2554280161857605\n",
      "4537 -> Loss: 0.2465975433588028\n",
      "4538 -> Loss: 0.7314398288726807\n",
      "4539 -> Loss: 0.9160133004188538\n",
      "4540 -> Loss: 0.15640144050121307\n",
      "4541 -> Loss: 0.18772491812705994\n",
      "4542 -> Loss: 0.6822444200515747\n",
      "4543 -> Loss: 0.746936023235321\n",
      "4544 -> Loss: 0.33899861574172974\n",
      "4545 -> Loss: 0.3631540536880493\n",
      "4546 -> Loss: 0.7433652877807617\n",
      "4547 -> Loss: 0.5339361429214478\n",
      "4548 -> Loss: 0.48325350880622864\n",
      "4549 -> Loss: 0.5767921805381775\n",
      "4550 -> Loss: 0.34562912583351135\n",
      "4551 -> Loss: 0.21013876795768738\n",
      "4552 -> Loss: 0.6129652261734009\n",
      "4553 -> Loss: 0.9592732191085815\n",
      "4554 -> Loss: 0.517737865447998\n",
      "4555 -> Loss: 0.4836907386779785\n",
      "4556 -> Loss: 0.44939571619033813\n",
      "4557 -> Loss: 0.402109295129776\n",
      "4558 -> Loss: 0.17395037412643433\n",
      "4559 -> Loss: 0.7472752928733826\n",
      "4560 -> Loss: 0.2745402753353119\n",
      "4561 -> Loss: 0.11867022514343262\n",
      "4562 -> Loss: 0.4754156470298767\n",
      "4563 -> Loss: 0.14727449417114258\n",
      "4564 -> Loss: 0.793920636177063\n",
      "4565 -> Loss: 0.8492825031280518\n",
      "4566 -> Loss: 0.7112478017807007\n",
      "4567 -> Loss: 0.17857348918914795\n",
      "4568 -> Loss: 0.20181052386760712\n",
      "4569 -> Loss: 0.5204122066497803\n",
      "4570 -> Loss: 0.44830140471458435\n",
      "4571 -> Loss: 0.16902796924114227\n",
      "4572 -> Loss: 0.31047582626342773\n",
      "4573 -> Loss: 0.34775808453559875\n",
      "4574 -> Loss: 0.5299311280250549\n",
      "4575 -> Loss: 0.4883700907230377\n",
      "4576 -> Loss: 0.637103259563446\n",
      "4577 -> Loss: 1.08543062210083\n",
      "4578 -> Loss: 0.2502562999725342\n",
      "4579 -> Loss: 0.7963285446166992\n",
      "4580 -> Loss: 0.5456993579864502\n",
      "4581 -> Loss: 0.3276485204696655\n",
      "4582 -> Loss: 0.15834493935108185\n",
      "4583 -> Loss: 0.5046584606170654\n",
      "4584 -> Loss: 0.9872454404830933\n",
      "4585 -> Loss: 0.18151415884494781\n",
      "4586 -> Loss: 0.9068741798400879\n",
      "4587 -> Loss: 0.7552972435951233\n",
      "4588 -> Loss: 0.4852145314216614\n",
      "4589 -> Loss: 0.29624325037002563\n",
      "4590 -> Loss: 1.0492192506790161\n",
      "4591 -> Loss: 0.39516979455947876\n",
      "4592 -> Loss: 0.531994640827179\n",
      "4593 -> Loss: 0.4633205235004425\n",
      "4594 -> Loss: 0.5662116408348083\n",
      "4595 -> Loss: 0.38815397024154663\n",
      "4596 -> Loss: 0.3484196662902832\n",
      "4597 -> Loss: 0.81777423620224\n",
      "4598 -> Loss: 0.509980320930481\n",
      "4599 -> Loss: 0.4424563944339752\n",
      "4600 -> Loss: 0.5101240873336792\n",
      "4601 -> Loss: 0.18666693568229675\n",
      "4602 -> Loss: 0.4379809498786926\n",
      "4603 -> Loss: 0.5132031440734863\n",
      "4604 -> Loss: 0.421310156583786\n",
      "4605 -> Loss: 0.5535240769386292\n",
      "4606 -> Loss: 0.77093505859375\n",
      "4607 -> Loss: 0.4246843159198761\n",
      "4608 -> Loss: 0.21020233631134033\n",
      "4609 -> Loss: 0.2265917807817459\n",
      "4610 -> Loss: 0.8249062299728394\n",
      "4611 -> Loss: 0.48628878593444824\n",
      "4612 -> Loss: 0.26946496963500977\n",
      "4613 -> Loss: 0.6095526814460754\n",
      "4614 -> Loss: 0.282050222158432\n",
      "4615 -> Loss: 0.4906935393810272\n",
      "4616 -> Loss: 0.4087654650211334\n",
      "4617 -> Loss: 0.4170430898666382\n",
      "4618 -> Loss: 0.1301107108592987\n",
      "4619 -> Loss: 0.5681875944137573\n",
      "4620 -> Loss: 0.513597846031189\n",
      "4621 -> Loss: 0.3417309522628784\n",
      "4622 -> Loss: 0.6308587193489075\n",
      "4623 -> Loss: 0.5310370922088623\n",
      "4624 -> Loss: 0.5837996006011963\n",
      "4625 -> Loss: 0.8591504096984863\n",
      "4626 -> Loss: 0.692674994468689\n",
      "4627 -> Loss: 0.5128027200698853\n",
      "4628 -> Loss: 0.7328702807426453\n",
      "4629 -> Loss: 0.44989675283432007\n",
      "4630 -> Loss: 0.6680110692977905\n",
      "4631 -> Loss: 0.24216733872890472\n",
      "4632 -> Loss: 0.2034159004688263\n",
      "4633 -> Loss: 0.39307311177253723\n",
      "4634 -> Loss: 0.7043749690055847\n",
      "4635 -> Loss: 0.6928333044052124\n",
      "4636 -> Loss: 0.7413859367370605\n",
      "4637 -> Loss: 0.6995724439620972\n",
      "4638 -> Loss: 0.22570890188217163\n",
      "4639 -> Loss: 0.5391099452972412\n",
      "4640 -> Loss: 0.4654959738254547\n",
      "4641 -> Loss: 0.8140316605567932\n",
      "4642 -> Loss: 0.3731555938720703\n",
      "4643 -> Loss: 0.2722844183444977\n",
      "4644 -> Loss: 0.6971192955970764\n",
      "4645 -> Loss: 0.525475800037384\n",
      "4646 -> Loss: 0.2779236435890198\n",
      "4647 -> Loss: 0.13384050130844116\n",
      "4648 -> Loss: 0.3764352798461914\n",
      "4649 -> Loss: 0.4803805351257324\n",
      "4650 -> Loss: 0.2583742141723633\n",
      "4651 -> Loss: 0.649948000907898\n",
      "4652 -> Loss: 0.43830281496047974\n",
      "4653 -> Loss: 0.6520428657531738\n",
      "4654 -> Loss: 0.38302409648895264\n",
      "4655 -> Loss: 0.2075556367635727\n",
      "4656 -> Loss: 0.560705304145813\n",
      "4657 -> Loss: 0.15385551750659943\n",
      "4658 -> Loss: 0.18614819645881653\n",
      "4659 -> Loss: 0.3684180676937103\n",
      "4660 -> Loss: 0.23078042268753052\n",
      "4661 -> Loss: 0.5626628994941711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [1:35:05<00:00, 5705.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved At:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(1)):  \n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        print(idx,\"-> Loss:\", loss.item())\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "        \n",
    "        # Plots in tensorboard\n",
    "    \n",
    "        if (idx != 0 ) and (idx % 1000 == 0):\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            acc_score_test = calculateAccuracyTest()\n",
    "            acc_score_val, validationLoss = calculateAccuracyVal()\n",
    "            \n",
    "            print(f'\\nValidation Accuracy: {acc_score_val}, Test Accuracy: {acc_score_test} \\n')\n",
    "            \n",
    "            #writer.add_scalar('Training Loss', loss.item(), epoch * tot_number_of_steps + idx)\n",
    "            #writer.add_scalar('Validation Loss', validationLoss, epoch * tot_number_of_steps + idx)\n",
    "\n",
    "            #writer.add_scalar('Accuracy Score On Val Set', acc_score_val, epoch * tot_number_of_steps + idx)\n",
    "            #writer.add_scalar('Accuracy Score On Test Set', acc_score_test, epoch * tot_number_of_steps + idx)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "    # Save model checkpoint\n",
    "    \n",
    "    save_path = os.path.join('./model_chkpts/test/', 'vilt_mlm_color_e' + '5' + '_cric_trained')\n",
    "    model.save_pretrained(save_path)\n",
    "    print(\"Model Saved At: \", epoch)\n",
    "    \n",
    "#writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c598233",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30034f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = val_dataset_object[index]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delLab = example.pop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension + move to GPU\n",
    "example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "\n",
    "# forward pass\n",
    "outputs = model(**example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c003637",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(logits).item())\n",
    "reverse_mapping[logits.argmax(-1).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "answerList[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = torch.sigmoid(logits)\n",
    "probs, classes = torch.topk(predicted_classes, 5)\n",
    "\n",
    "for prob, class_idx in zip(probs.squeeze().tolist(), classes.squeeze().tolist()):\n",
    "  print(prob, model.config.id2label[class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.open(imgPathList[index])\n",
    "i.thumbnail((300,300))\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c5e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e2538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a4c899",
   "metadata": {},
   "source": [
    "## Reports & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84a1efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the Validation Loss and accuracy on the Validation Set\n",
    "\n",
    "def calculateAccuracyVal():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    \n",
    "    for index in range(0,200):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        \n",
    "        val_example = val_dataset_object[index]\n",
    "        val_example = {k: v.unsqueeze(0).to(device) for k,v in val_example.items()}\n",
    "        val_outputs = model(**val_example)\n",
    "        \n",
    "        validationLoss = val_outputs.loss\n",
    "\n",
    "        val_logits = val_outputs.logits\n",
    "        val_predicted_classes = torch.sigmoid(val_logits)\n",
    "        val_ans = reverse_mapping[torch.argmax(val_predicted_classes).item()]\n",
    "        \n",
    "        \n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_val[index] == val_ans:\n",
    "            matchScore += 1\n",
    "                \n",
    "    #print(matchScore, loopCounter)\n",
    "    accuracyVal = (matchScore/loopCounter)*100\n",
    "    return ( accuracyVal,validationLoss.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateAccuracyVal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e9e34a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns accuracy on the Test Set\n",
    "\n",
    "def calculateAccuracyTest():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    for index in range(0, 200):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        \n",
    "        test_example = test_dataset_object[index]\n",
    "        test_example = {k: v.unsqueeze(0).to(device) for k,v in test_example.items()}\n",
    "        test_outputs = model(**test_example)\n",
    "\n",
    "        test_logits = test_outputs.logits\n",
    "        test_predicted_classes = torch.sigmoid(test_logits)\n",
    "        test_ans = reverse_mapping[torch.argmax(test_predicted_classes).item()]\n",
    "        \n",
    "        # print(f'T: {answerList_val[index]} <-> P: {test_ans}' )\n",
    "\n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == test_ans:\n",
    "            matchScore += 1\n",
    "                \n",
    "    #print(matchScore, loopCounter)\n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateAccuracyTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns report on the Test Set\n",
    "\n",
    "misclassifiedIndex = []\n",
    "def generateReport():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    for index in range(0,500):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        print(f'\\n{questionList_test[index]} ? Ans: {answerList_test[index]}\\n')\n",
    "        \n",
    "        example = test_dataset_object[index]\n",
    "        example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "        outputs = model(**example)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predicted_classes = torch.sigmoid(logits)\n",
    "        ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "        \n",
    "        print('Predicted Ans:', ans,'\\n')\n",
    "        \n",
    "        probs, classes = torch.topk(predicted_classes, 4)\n",
    "\n",
    "        for prob, class_idx in zip(probs.squeeze().tolist(), classes.squeeze().tolist()):\n",
    "            print(prob, model.config.id2label[class_idx])\n",
    "    \n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == ans:\n",
    "            matchScore += 1\n",
    "            print('Correct Prediction at index:', index)\n",
    "        \n",
    "        else:\n",
    "            misclassifiedIndex.append(index)\n",
    "            print('Wrong Prediction at index:', index)\n",
    "    \n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifiedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99346041",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.open(imgPathList_test[53054])\n",
    "i.thumbnail((500,500))\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b809f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214182d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fc99a95",
   "metadata": {},
   "source": [
    "## Find Questions With Color And Its Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the list of colors from the previously stored text files\n",
    "\n",
    "colors = []\n",
    "with open('./text_files/colors.txt', 'r') as file:\n",
    "    for color in file:\n",
    "        color = color.strip()\n",
    "        colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483039ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding leading and trailing space in the colors\n",
    "\n",
    "colors_spaces = [' '+ color + ' ' for color in colors] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_spaces[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isContainColor(targetString, colorList):\n",
    "    \n",
    "    for color in colorList:\n",
    "        if color in targetString:\n",
    "            return True\n",
    "    \n",
    "    return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da567432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the accuracy on color question and identifies the color question for which the result is misclassified\n",
    "\n",
    "misclassifiedIndex = []\n",
    "colorFrequency = {color: 0 for color in colors}\n",
    "\n",
    "def findColorQuestions():\n",
    "    \n",
    "    global colors\n",
    "    matchScore, questionCount = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    print('***** Question About Colors ************')\n",
    "    \n",
    "    for index in tqdm(range(1000,2000)):\n",
    "        \n",
    "        currQuestion = questionList_test[index]        \n",
    "        \n",
    "        if ('color' in currQuestion) or (isContainColor(currQuestion, colors_spaces)):\n",
    "            \n",
    "            questionCount += 1\n",
    "            \n",
    "            #print(f'\\n{questionList_test[index]} ? Ans: {answerList_test[index]}\\n')\n",
    "            \n",
    "            example = test_dataset_object[index]\n",
    "            example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "            outputs = model(**example)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predicted_classes = torch.sigmoid(logits)\n",
    "            ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "\n",
    "            # accuracy score\n",
    "\n",
    "            if answerList_test[index] == ans:\n",
    "                matchScore += 1\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if answerList_test[index] in colors:\n",
    "                    colorFrequency[ answerList_test[index] ] = colorFrequency[ answerList_test[index] ] + 1\n",
    "                    \n",
    "                misclassifiedIndex.append(index)\n",
    "                                \n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    \n",
    "    print(f'\\nTotal {questionCount} questions found')\n",
    "    return ((matchScore/questionCount)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d716fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "findColorQuestions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(misclassifiedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81990892",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = colorFrequency.keys()\n",
    "values = colorFrequency.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.xlabel(f\"Model Misclassified Total {sum(values)} Questions involving Colors\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Number of times Ground truth Colors which has been misclassified by the model\")\n",
    "\n",
    "plt.bar(colorFrequency.keys(), colorFrequency.values(), color='lightblue', edgecolor='black', width=0.4)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99550ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e419c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a14f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f5bd151",
   "metadata": {},
   "source": [
    "## Store Color Question Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcab574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the list of colors from the previously stored text files\n",
    "\n",
    "colors_train = []\n",
    "with open('./text_files/colors_train.txt', 'r') as file:\n",
    "    for color in file:\n",
    "        color = color.replace(\"\\n\",\"\")\n",
    "        colors_train.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function collects the indices of the color questions from the train set\n",
    "\n",
    "colorQuestionIndices = []\n",
    "\n",
    "def storeColorQuestionIndex():\n",
    "    \n",
    "    questionCount = 0 \n",
    "    print('********* Storing Color Questions Indices ************')\n",
    "    \n",
    "    for index in tqdm(range(0,len(answerList))):\n",
    "        \n",
    "        currAnswer = answerList[index]  \n",
    "        currQuestion = questionList[index]\n",
    "                \n",
    "        if ('color' in currQuestion) or (isContainColor(currQuestion,colors_train)):\n",
    "            #print(index,currQuestion)\n",
    "\n",
    "            questionCount += 1\n",
    "            colorQuestionIndices.append(index)\n",
    "        \n",
    "                \n",
    "    print(f'\\nTotal {questionCount} color questions found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b51862",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeColorQuestionIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2713324",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(colorQuestionIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfba6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorQuestionIndices[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList[2560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09beda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08f674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f336d61e",
   "metadata": {},
   "source": [
    "## Words in color Questions Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d17702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(wordList):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in wordList if word.lower() not in stop_words]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36782762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function gathers all the words from the color questions and their frequency from all the color questions to make histogram\n",
    "\n",
    "frquencyMap = {}\n",
    "\n",
    "def collectWords():\n",
    "    \n",
    "    for index in tqdm(misclassifiedIndex):\n",
    "        \n",
    "        currQuestion = questionList_test[index]\n",
    "        words = remove_stopwords(currQuestion.split())\n",
    "        \n",
    "        for word in words:\n",
    "            \n",
    "            if word in frquencyMap:\n",
    "                \n",
    "                frquencyMap[word] = frquencyMap[word] + 1\n",
    "            \n",
    "            else:\n",
    "            \n",
    "                frquencyMap[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frquencyMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list of tuples\n",
    "\n",
    "frquencyList = [(key,val) for key,val in frquencyMap.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frquencyList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frquencyList.sort(key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "frquencyList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c500a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-30 words\n",
    "\n",
    "frquencyList = frquencyList[0:30]\n",
    "labels = [ val[0] for val in frquencyList]\n",
    "frequncies = [ val[1] for val in frquencyList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=frequncies, y=labels, palette=\"viridis\")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set(xlabel=\"Frequency\", ylabel=\"Words\", title=\"Word Frequency\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df0ec3",
   "metadata": {},
   "source": [
    "# Experimenting With Accuracy By Removing Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questionList_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a676043",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tqdm(range(0,500)):\n",
    "\n",
    "    currQuestion = questionList_test[index]\n",
    "    if 'object' or 'used' in currQuestion:\n",
    "        currQuestion = ' '.join([word for word in currQuestion.split() if word not in ('object','used')])\n",
    "    \n",
    "    questionList_test[index] = currQuestion\n",
    "\n",
    "# creating HF dataset to map images fast of test_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_test, 'labels':labels_test, 'scores':scores_test, 'images':imgPathList_test}\n",
    "word_removed_test_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_removed_test_set = word_removed_test_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df406ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_removed_test_set[10]['questions'], modified_test_set[10]['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7949d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_removed_test_set_object = cric_dataset(word_removed_test_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns report on the Test Set\n",
    "\n",
    "misclassifiedIndex = []\n",
    "def removeWordsAndGenReport():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    for index in tqdm(range(0,1000)):\n",
    "        \n",
    "        loopCounter += 1                            \n",
    "\n",
    "        example = word_removed_test_set_object[index]\n",
    "        example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "        outputs = model(**example)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predicted_classes = torch.sigmoid(logits)\n",
    "        ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "        \n",
    "        # print('Predicted Ans:', ans,'\\n')\n",
    "        \n",
    "        probs, classes = torch.topk(predicted_classes, 4)\n",
    "\n",
    "        for prob, class_idx in zip(probs.squeeze().tolist(), classes.squeeze().tolist()):\n",
    "            print(end='')\n",
    "    \n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == ans:\n",
    "            matchScore += 1\n",
    "            #print('Correct Prediction at index:', index)\n",
    "        \n",
    "        else:\n",
    "            misclassifiedIndex.append(index)\n",
    "            #print('Wrong Prediction at index:', index)\n",
    "    \n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeWordsAndGenReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questionList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26de840",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat text_files/colors_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the color questions of the training set\n",
    "\n",
    "# This function identifies the color question for which the result is misclassified\n",
    "\n",
    "colorMap = {}\n",
    "questionCount = 0\n",
    "\n",
    "def findColorQuestionsTraining():\n",
    "        \n",
    "    print('***** Question About Colors ************')\n",
    "    \n",
    "    for index in tqdm(range(len(questionList))):\n",
    "        \n",
    "        currQuestion = questionList[index]        \n",
    "        #print(currQuestion)\n",
    "        \n",
    "        if ('color' in currQuestion):\n",
    "            \n",
    "            global questionCount\n",
    "            questionCount += 1\n",
    "            currAnswer = answerList[index]\n",
    "            \n",
    "            if currAnswer in colorMap:              \n",
    "                colorMap[currAnswer] = colorMap[currAnswer] + 1\n",
    "            else:\n",
    "                colorMap[currAnswer] = 1\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "    return (colorMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "findColorQuestionsTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9146f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
