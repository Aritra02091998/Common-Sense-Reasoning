{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b35b92",
   "metadata": {},
   "source": [
    "###### -----------------START--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e4e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b320d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1bf8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c5e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = '/home/aritra/cric/train_questions.json'\n",
    "val_file_path = '/home/aritra/cric/val_questions.json'\n",
    "test_file_path = '/home/aritra/cric/test_v1_questions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236c7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "\n",
    "with open(train_file_path, \"r\") as file:\n",
    "     train_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2e0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "\n",
    "with open(val_file_path, \"r\") as file:\n",
    "     val_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e00100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "\n",
    "with open(test_file_path, \"r\") as file:\n",
    "     test_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48972cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d15c9341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa20f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12fab983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which brown animal walking in the field could be used for transporting people'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5b16491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is there an object that is a type of public transports'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5dfd026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can the ceramic bird spread wings'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7e75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8190c199",
   "metadata": {},
   "source": [
    "### ------------------------------Extracting Data of Training Set-------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae6c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList = []\n",
    "answerList = []\n",
    "imgList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cdf3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[2]['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0248032",
   "metadata": {},
   "source": [
    "#### iter 1: from 0 , 149000 -> error1.txt -> 159\n",
    "#### iter 2: from 150000 , 240000 -> error2.txt -> 34\n",
    "#### iter 3: from 240000 , 365235 ->error3.txt -> 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b63642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying\n",
    "indexToExclude = []\n",
    "\n",
    "with open('error1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)\n",
    "        \n",
    "with open('error2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)\n",
    "        \n",
    "with open('error3.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d4ed441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexToExclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c8a79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████| 365235/365235 [00:01<00:00, 321343.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_json))):\n",
    "    \n",
    "    if i in indexToExclude:\n",
    "        continue\n",
    "        \n",
    "    pointer = train_json[i]\n",
    "    \n",
    "    questionList.append(pointer['question'])\n",
    "    answerList.append(pointer['answer'])\n",
    "    imgList.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5bc92f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364921, 364921, 364921)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questionList), len(answerList), len(imgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cf2a90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(answerList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6261",
   "metadata": {},
   "source": [
    "### ---------------------------------------Map Creation--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3638995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findUnique(targetList):\n",
    "    \n",
    "    uniqueList = []\n",
    "    \n",
    "    for word in targetList:\n",
    "        if word not in uniqueList:\n",
    "            uniqueList.append(word)\n",
    "    \n",
    "    return uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05afbb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(findUnique(answerList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b38e9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word to number mapping\n",
    "\n",
    "mapping = {}\n",
    "counter = 0\n",
    "\n",
    "uniqueAnsList = findUnique(answerList)\n",
    "\n",
    "for word in uniqueAnsList:\n",
    "    \n",
    "    if word not in mapping:\n",
    "        \n",
    "        mapping[word] = counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bfa346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'small', 'picture', 'table', 'bookshelf']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueAnsList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "143b6127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfClasses = max(mapping.values())\n",
    "numOfClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "815b20fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4811265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating number to word mapping\n",
    "\n",
    "reverse_mapping = dict([(value, key) for key, value in mapping.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8749a",
   "metadata": {},
   "source": [
    "### --------------------------------------Processing of Training Set--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e781d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for i in range(len(answerList)):\n",
    "    labels.append( mapping[ answerList[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in tqdm(range(len(answerList))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList[i]] ] = 1\n",
    "    \n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65951dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPathList = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList))):\n",
    "    \n",
    "    imgName = str(imgList[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75bbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import datasets\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afea404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgPathList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgPathList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65956469",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDictionary = {'questions':questionList, 'labels': labels, 'scores': scores, 'images':imgPathList}\n",
    "modified_train_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe569437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath to images in the directory\n",
    "\n",
    "modified_train_set = modified_train_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a43c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b28f14",
   "metadata": {},
   "source": [
    "### ------------------------------------------------Extracting Validation Set---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc81bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_val = []\n",
    "answerList_val = []\n",
    "imgList_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting the index containing errorneous images\n",
    "\n",
    "indexToExcludeVal = []\n",
    "with open('error_validation.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeVal.append(number)\n",
    "\n",
    "with open('error_validation2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())  # Convert the read line to an integer\n",
    "        indexToExcludeVal.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e36650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding the index containing errorneous images\n",
    "\n",
    "for i in tqdm(range(len(val_json))):\n",
    "    \n",
    "    if (i in indexToExcludeVal):\n",
    "        continue\n",
    "        \n",
    "    pointer = val_json[i]\n",
    "    \n",
    "    questionList_val.append(pointer['question'])\n",
    "    answerList_val.append(pointer['answer'])\n",
    "    imgList_val.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f547b",
   "metadata": {},
   "source": [
    "43112 -> 43068 -> 33175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77490cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questionList_val), len(answerList_val), len(imgList_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e215d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueAnswerListVal = list(set(answerList_val))\n",
    "len(uniqueAnswerListVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2927cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_val)):\n",
    "    \n",
    "    word = answerList_val[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff358202",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------Processing Validation Set-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = []\n",
    "\n",
    "for i in range(len(answerList_val)):\n",
    "    labels_val.append( mapping[ answerList_val[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da89dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b0916",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_val = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_val))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_val[i]] ] = 1\n",
    "    \n",
    "    scores_val.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def663bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPathList_val = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_val))):\n",
    "    \n",
    "    imgName = str(imgList_val[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_val.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPathList_val[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc43b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of Val_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_val, 'labels':labels_val, 'scores':scores_val, 'images':imgPathList_val}\n",
    "modified_val_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of Val Set to images in the directory\n",
    "\n",
    "modified_val_set = modified_val_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e854bad",
   "metadata": {},
   "source": [
    "### -------------------------------------------Extracting Test Set-------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_test = []\n",
    "answerList_test = []\n",
    "imgList_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToExcludeTest = []\n",
    "\n",
    "with open('error_testSet1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeTest.append(number)\n",
    "        \n",
    "with open('errorTestSet2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeTest.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171595e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexToExcludeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7964cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(test_json))):\n",
    "    \n",
    "    if i in indexToExcludeTest:\n",
    "        continue\n",
    "        \n",
    "    pointer = test_json[i]\n",
    "    \n",
    "    questionList_test.append(pointer['question'])\n",
    "    answerList_test.append(pointer['answer'])\n",
    "    imgList_test.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2107405",
   "metadata": {},
   "source": [
    "86003 -> 71863"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4885eea",
   "metadata": {},
   "source": [
    "### -------------------------------------- Processing Test Set ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd02d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_test)):\n",
    "    \n",
    "    word = answerList_test[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bca53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "\n",
    "for i in range(len(answerList_test)):\n",
    "    labels_test.append( mapping[ answerList_test[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_test))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_test[i]] ] = 1\n",
    "    \n",
    "    scores_test.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ef009",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPathList_test = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_test))):\n",
    "    \n",
    "    imgName = str(imgList_test[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_test.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450290c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgPathList_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac7c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPathList_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of test_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_test, 'labels':labels_test, 'scores':scores_test, 'images':imgPathList_test}\n",
    "modified_test_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of test Set to images in the directory\n",
    "\n",
    "modified_test_set = modified_test_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61741af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "607636d1",
   "metadata": {},
   "source": [
    "### -------------------------------End of Processing----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor, ViltForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltConfig\n",
    "config = ViltConfig.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-mlm\", id2label = reverse_mapping, label2id = mapping).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303430b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cric_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, processor):\n",
    "        self.processor = processor\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        #print(idx)\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        #print(item)\n",
    "        \n",
    "        encodings = self.processor(images = item[\"images\"], text = item[\"questions\"], padding=\"max_length\", truncation=True, return_tensors = \"pt\")\n",
    "        encodings = {k:v.squeeze() for k,v in encodings.items()}\n",
    "                                \n",
    "        encodings['labels'] = torch.tensor(item['scores'], dtype = torch.float32)\n",
    "        \n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa27f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_object = cric_dataset(modified_train_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_object = cric_dataset(modified_val_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_object = cric_dataset(modified_test_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b548a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  \n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    pixel_values = [item['pixel_values'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "        \n",
    "    # create padded pixel values and corresponding pixel mask\n",
    "    \n",
    "    encoding = processor.image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "    # create new batch\n",
    "    \n",
    "    batch = {}\n",
    "    \n",
    "    batch['input_ids'] = torch.stack(input_ids)\n",
    "    batch['attention_mask'] = torch.stack(attention_mask)\n",
    "    batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "    batch['pixel_values'] = encoding['pixel_values']\n",
    "    batch['pixel_mask'] = encoding['pixel_mask']\n",
    "    batch['labels'] = torch.stack(labels, dim = 0 )\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset_object, collate_fn = collate_fn, shuffle = True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ff26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in batch.items():\n",
    "    print(k, v.shape)\n",
    "    print()\n",
    "    \n",
    "#print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_number_of_steps = len(train_dataloader)\n",
    "tot_number_of_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec481fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp16 precision\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d848387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Visualisation for this Test Notebook\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dcaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 8e-5)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(10)):  \n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        print(idx,\"-> Loss:\", loss.item())\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "        \n",
    "        # Plots in tensorboard\n",
    "    \n",
    "        if (idx != 0 ) and (idx % 100 == 0):\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            acc_score_test = calculateAccuracyTest()\n",
    "            acc_score_val, validationLoss = calculateAccuracyVal()\n",
    "            \n",
    "            print(f'\\nValidation Accuracy: {acc_score_val}, Test Accuracy: {acc_score_test} \\n')\n",
    "            \n",
    "            #writer.add_scalar('Training Loss', loss.item(), epoch * tot_number_of_steps + idx)\n",
    "            #writer.add_scalar('Validation Loss', validationLoss, epoch * tot_number_of_steps + idx)\n",
    "\n",
    "            #writer.add_scalar('Accuracy Score On Val Set', acc_score_val, epoch * tot_number_of_steps + idx)\n",
    "            #writer.add_scalar('Accuracy Score On Test Set', acc_score_test, epoch * tot_number_of_steps + idx)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "    # Save model checkpoint\n",
    "    \n",
    "    save_path = os.path.join('./model_chkpts/test/', 'vilt_mlm_final_e' + str(epoch+1) + '_cric_trained')\n",
    "    model.save_pretrained(save_path)\n",
    "    print(\"Model Saved At: \", epoch)\n",
    "    \n",
    "#writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c598233",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30034f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = val_dataset_object[index]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delLab = example.pop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension + move to GPU\n",
    "example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "\n",
    "# forward pass\n",
    "outputs = model(**example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c003637",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(logits).item())\n",
    "reverse_mapping[logits.argmax(-1).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "answerList[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = torch.sigmoid(logits)\n",
    "probs, classes = torch.topk(predicted_classes, 5)\n",
    "\n",
    "for prob, class_idx in zip(probs.squeeze().tolist(), classes.squeeze().tolist()):\n",
    "  print(prob, model.config.id2label[class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.open(imgPathList[index])\n",
    "i.thumbnail((300,300))\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c5e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e2538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea20de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the Validation Loss and accuracy on the Validation Set\n",
    "\n",
    "def calculateAccuracyVal():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    \n",
    "    for index in range(0,100):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        \n",
    "        val_example = val_dataset_object[index]\n",
    "        val_example = {k: v.unsqueeze(0).to(device) for k,v in val_example.items()}\n",
    "        val_outputs = model(**val_example)\n",
    "        \n",
    "        validationLoss = val_outputs.loss\n",
    "\n",
    "        val_logits = val_outputs.logits\n",
    "        val_predicted_classes = torch.sigmoid(val_logits)\n",
    "        val_ans = reverse_mapping[torch.argmax(val_predicted_classes).item()]\n",
    "        \n",
    "        #print(f'T: {answerList_val[index]} <-> P: {val_ans}' )\n",
    "\n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_val[index] == val_ans:\n",
    "            matchScore += 1\n",
    "                \n",
    "    #print(matchScore, loopCounter)\n",
    "    accuracyVal = (matchScore/loopCounter)*100\n",
    "    return ( accuracyVal,validationLoss.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e34a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns accuracy on the Test Set\n",
    "# However, accuracy needs to be found out on the whole Test Set using the saved model chkpts\n",
    "\n",
    "def calculateAccuracyTest():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    for index in range(0,200):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        \n",
    "        test_example = test_dataset_object[index]\n",
    "        test_example = {k: v.unsqueeze(0).to(device) for k,v in test_example.items()}\n",
    "        test_outputs = model(**test_example)\n",
    "\n",
    "        test_logits = test_outputs.logits\n",
    "        test_predicted_classes = torch.sigmoid(test_logits)\n",
    "        test_ans = reverse_mapping[torch.argmax(test_predicted_classes).item()]\n",
    "        \n",
    "        # print(f'T: {answerList_val[index]} <-> P: {test_ans}' )\n",
    "\n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == test_ans:\n",
    "            matchScore += 1\n",
    "                \n",
    "    #print(matchScore, loopCounter)\n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateAccuracyTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c7a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642990b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99346041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da567432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
