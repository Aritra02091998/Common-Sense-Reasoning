{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b35b92",
   "metadata": {},
   "source": [
    "###### -----------------START--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e4e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c5e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = '/home/aritra/cric/train_questions.json'\n",
    "val_file_path = '/home/aritra/cric/val_questions.json'\n",
    "test_file_path = '/home/aritra/cric/test_v1_questions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236c7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "\n",
    "with open(train_file_path, \"r\") as file:\n",
    "     train_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2e0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "\n",
    "with open(val_file_path, \"r\") as file:\n",
    "     val_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e00100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "\n",
    "with open(test_file_path, \"r\") as file:\n",
    "     test_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48972cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15c9341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43112"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa20f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86003"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fab983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which brown animal walking in the field could be used for transporting people'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b16491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is there an object that is a type of public transports'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_json[1099]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5dfd026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can the ceramic bird spread wings'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json[1099]['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190c199",
   "metadata": {},
   "source": [
    "### ------------------------------Extracting Data of Training Set-------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae6c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList = []\n",
    "answerList = []\n",
    "imgList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cdf3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[2]['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0248032",
   "metadata": {},
   "source": [
    "#### iter 1: from 0 , 149000 -> error1.txt -> 159\n",
    "#### iter 2: from 150000 , 240000 -> error2.txt -> 34\n",
    "#### iter 3: from 240000 , 365235 ->error3.txt -> 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14b63642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying\n",
    "indexToExclude = []\n",
    "\n",
    "with open('error1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)\n",
    "        \n",
    "with open('error2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)\n",
    "        \n",
    "with open('error3.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExclude.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d4ed441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexToExclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8a79d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b238915cb004a5bb055b3ec41cf4e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/365235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_json))):\n",
    "    \n",
    "    if i in indexToExclude:\n",
    "        continue\n",
    "        \n",
    "    pointer = train_json[i]\n",
    "    \n",
    "    questionList.append(pointer['question'])\n",
    "    answerList.append(pointer['answer'])\n",
    "    imgList.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5bc92f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364921, 364921, 364921)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questionList), len(answerList), len(imgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67435a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList = questionList[0:5000]\n",
    "answerList = answerList[0:5000]\n",
    "imgList = imgList[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf2a90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(answerList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6261",
   "metadata": {},
   "source": [
    "### ---------------------------------------Map Creation--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3638995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findUnique(targetList):\n",
    "    \n",
    "    uniqueList = []\n",
    "    \n",
    "    for word in targetList:\n",
    "        if word not in uniqueList:\n",
    "            uniqueList.append(word)\n",
    "    \n",
    "    return uniqueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05afbb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(findUnique(answerList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b38e9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word to number mapping\n",
    "\n",
    "mapping = {}\n",
    "counter = 0\n",
    "\n",
    "uniqueAnsList = findUnique(answerList)\n",
    "\n",
    "for word in uniqueAnsList:\n",
    "    \n",
    "    if word not in mapping:\n",
    "        \n",
    "        mapping[word] = counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00bfa346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'small', 'picture', 'table', 'bookshelf']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueAnsList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "143b6127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfClasses = max(mapping.values())\n",
    "numOfClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "815b20fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4811265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating number to word mapping\n",
    "\n",
    "reverse_mapping = dict([(value, key) for key, value in mapping.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8749a",
   "metadata": {},
   "source": [
    "### --------------------------------------Processing of Training Set--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e781d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting answer labels of Train set into numbers\n",
    "labels = []\n",
    "\n",
    "for i in range(len(answerList)):\n",
    "    labels.append( mapping[ answerList[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f9d1248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd652be",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c03fdb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffb7453bbc7408f8efca37486d02250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in tqdm(range(len(answerList))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList[i]] ] = 1\n",
    "    \n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bab7b57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65951dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff1d5e6963b430fb57c5dd4081ff246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgPathList = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList))):\n",
    "    \n",
    "    imgName = str(imgList[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75bbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import datasets\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0afea404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1000.jpg',\n",
       " '/home/aritra/cric/images/img/1005.jpg',\n",
       " '/home/aritra/cric/images/img/1005.jpg',\n",
       " '/home/aritra/cric/images/img/1005.jpg',\n",
       " '/home/aritra/cric/images/img/1008.jpg']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "158e26b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgPathList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65956469",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDictionary = {'questions':questionList, 'labels': labels, 'scores': scores, 'images':imgPathList}\n",
    "modified_train_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe569437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath to images in the directory\n",
    "\n",
    "modified_train_set = modified_train_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01a43c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'labels', 'scores', 'images'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b28f14",
   "metadata": {},
   "source": [
    "### ------------------------------------------------Extracting Validation Set---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acc81bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_val = []\n",
    "answerList_val = []\n",
    "imgList_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce77628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting the index containing errorneous images\n",
    "\n",
    "indexToExcludeVal = []\n",
    "with open('error_validation.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeVal.append(number)\n",
    "\n",
    "with open('error_validation2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())  # Convert the read line to an integer\n",
    "        indexToExcludeVal.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08e36650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9497f2942ab4e079df39b43d62e7fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# excluding the index containing errorneous images\n",
    "\n",
    "for i in tqdm(range(len(val_json))):\n",
    "    \n",
    "    if (i in indexToExcludeVal):\n",
    "        continue\n",
    "        \n",
    "    pointer = val_json[i]\n",
    "    \n",
    "    questionList_val.append(pointer['question'])\n",
    "    answerList_val.append(pointer['answer'])\n",
    "    imgList_val.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f547b",
   "metadata": {},
   "source": [
    "43112 -> 43068 -> 33175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77490cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33175, 33175, 33175)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questionList_val), len(answerList_val), len(imgList_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e215d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueAnswerListVal = list(set(answerList_val))\n",
    "len(uniqueAnswerListVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2927cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers of validation set are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_val)):\n",
    "    \n",
    "    word = answerList_val[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdfb2dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33175"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff358202",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------Processing Validation Set-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23e8a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting labels of val_set into numbers\n",
    "\n",
    "labels_val = []\n",
    "\n",
    "for i in range(len(answerList_val)):\n",
    "    labels_val.append( mapping[ answerList_val[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0da89dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33175"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "008b0916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef21c38484fd4db3b835e4c88aab8e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_val = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_val))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_val[i]] ] = 1\n",
    "    \n",
    "    scores_val.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "def663bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33175"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b18cba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb09b593a4e447c0a8cf3c5756d44319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgPathList_val = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_val))):\n",
    "    \n",
    "    imgName = str(imgList_val[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_val.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae9e0ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1003.jpg',\n",
       " '/home/aritra/cric/images/img/1003.jpg',\n",
       " '/home/aritra/cric/images/img/1018.jpg',\n",
       " '/home/aritra/cric/images/img/1018.jpg',\n",
       " '/home/aritra/cric/images/img/1027.jpg']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList_val[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dc43b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of Val_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_val, 'labels':labels_val, 'scores':scores_val, 'images':imgPathList_val}\n",
    "modified_val_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0596e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of Val Set to images in the directory\n",
    "\n",
    "modified_val_set = modified_val_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e854bad",
   "metadata": {},
   "source": [
    "### -------------------------------------------Extracting Test Set-------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61abaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList_test = []\n",
    "answerList_test = []\n",
    "imgList_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0c136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToExcludeTest = []\n",
    "\n",
    "with open('error_testSet1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeTest.append(number)\n",
    "        \n",
    "with open('errorTestSet2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        number = int(line.strip())\n",
    "        indexToExcludeTest.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "171595e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14150"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexToExcludeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7964cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f51f42ff9284257966120e0de796002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_json))):\n",
    "    \n",
    "    if i in indexToExcludeTest:\n",
    "        continue\n",
    "        \n",
    "    pointer = test_json[i]\n",
    "    \n",
    "    questionList_test.append(pointer['question'])\n",
    "    answerList_test.append(pointer['answer'])\n",
    "    imgList_test.append(pointer['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2107405",
   "metadata": {},
   "source": [
    "86003 -> 71863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37adc669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answerList_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4885eea",
   "metadata": {},
   "source": [
    "### -------------------------------------- Processing Test Set ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd02d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the uniques answers of test_set are present in the mapping\n",
    "\n",
    "y,n = 0,0\n",
    "store = []\n",
    "for i in range(len(answerList_test)):\n",
    "    \n",
    "    word = answerList_test[i]\n",
    "    \n",
    "    if word in mapping:\n",
    "        y += 1\n",
    "    else:\n",
    "        n+=1\n",
    "        store.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5c6bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20bca53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting answer labels of test_set into numbers\n",
    "labels_test = []\n",
    "\n",
    "for i in range(len(answerList_test)):\n",
    "    labels_test.append( mapping[ answerList_test[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c325e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a603312d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da64ff3f7e2d46eaa3950a96a4934395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_test = []\n",
    "\n",
    "for i in tqdm(range(len(answerList_test))):\n",
    "    \n",
    "    s = [0] * (numOfClasses+1)\n",
    "    s[ mapping[ answerList_test[i]] ] = 1\n",
    "    \n",
    "    scores_test.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa0bce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b3ef009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c83da04e834be0b6070e089768c8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgPathList_test = []\n",
    "filepath = '/home/aritra/cric/images/img/'\n",
    "\n",
    "for i in tqdm(range(len(imgList_test))):\n",
    "    \n",
    "    imgName = str(imgList_test[i]) + '.jpg'\n",
    "    concatedPath = os.path.join(filepath,imgName)\n",
    "    \n",
    "    imgPathList_test.append(concatedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "450290c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71863"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgPathList_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ac7c315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg',\n",
       " '/home/aritra/cric/images/img/1004.jpg']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPathList_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cac47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HF dataset to map images fast of test_set\n",
    "\n",
    "listToDictionary = {'questions':questionList_test, 'labels':labels_test, 'scores':scores_test, 'images':imgPathList_test}\n",
    "modified_test_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a74c0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping each filepath of test Set to images in the directory\n",
    "\n",
    "modified_test_set = modified_test_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607636d1",
   "metadata": {},
   "source": [
    "### -------------------------------End of Processing----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4eb76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor, ViltForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8d574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltConfig\n",
    "config = ViltConfig.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0441da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f0e3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "276bc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViltForQuestionAnswering were not initialized from the model checkpoint at dandelin/vilt-b32-mlm and are newly initialized: ['classifier.1.weight', 'classifier.3.weight', 'classifier.1.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-mlm\", id2label = reverse_mapping, label2id = mapping).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dfafe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "303430b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cric_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, processor):\n",
    "        self.processor = processor\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        #print(idx)\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        #print(item)\n",
    "        \n",
    "        encodings = self.processor(images = item[\"images\"], text = item[\"questions\"], padding=\"max_length\", truncation=True, return_tensors = \"pt\")\n",
    "        encodings = {k:v.squeeze() for k,v in encodings.items()}\n",
    "                                \n",
    "        encodings['labels'] = torch.tensor(item['scores'], dtype = torch.float32)\n",
    "\n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa27f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_object = cric_dataset(modified_train_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fd2761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_object = cric_dataset(modified_val_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a27f70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_object = cric_dataset(modified_test_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b548a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  \n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    pixel_values = [item['pixel_values'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "        \n",
    "    # create padded pixel values and corresponding pixel mask\n",
    "    \n",
    "    encoding = processor.image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "    # create new batch\n",
    "    \n",
    "    batch = {}\n",
    "    \n",
    "    batch['input_ids'] = torch.stack(input_ids)\n",
    "    batch['attention_mask'] = torch.stack(attention_mask)\n",
    "    batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "    batch['pixel_values'] = encoding['pixel_values']\n",
    "    batch['pixel_mask'] = encoding['pixel_mask']\n",
    "    batch['labels'] = torch.stack(labels, dim = 0 )\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fec6556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset_object, collate_fn = collate_fn, shuffle = True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed4ff26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "925fb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([16, 40])\n",
      "\n",
      "attention_mask torch.Size([16, 40])\n",
      "\n",
      "token_type_ids torch.Size([16, 40])\n",
      "\n",
      "pixel_values torch.Size([16, 3, 608, 576])\n",
      "\n",
      "pixel_mask torch.Size([16, 608, 576])\n",
      "\n",
      "labels torch.Size([16, 596])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in batch.items():\n",
    "    print(k, v.shape)\n",
    "    print()\n",
    "    \n",
    "#print(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1feaee9",
   "metadata": {},
   "source": [
    "## Truncated Lq Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab38c73",
   "metadata": {},
   "source": [
    "##### Using L’Hôpital’s rule, it can be shown that the proposed loss function is equivalent to CCE for lim q→0 Lq(f(x), ej ), and becomes MAE/unhinged loss when q = 1. This loss is a generalization of CCE and MAE with 2 hyperparameters to vary q and k. \n",
    "\n",
    "Note that, when k → 0, the truncated Lq loss becomes the normal Lq loss.\n",
    "k = 1/c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33579580",
   "metadata": {},
   "source": [
    "###### According to paper, the best accuracy was obtained with q = 0.8, when the noise rate was 20%\n",
    "###### Another best accuracy was obtained with q = 0.8, when the noise rate was 60%, fast convergence (near to MAE)\n",
    "###### Another best accuracy was obtained with q = 1.0, when the noise rate was 60%, but with slow convergence (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81f2b1",
   "metadata": {},
   "source": [
    "##### Experimental Setup:\n",
    "\n",
    "LR: 0.01,\n",
    "Momentum: 0.9,\n",
    "Weight_Decay: 0.0001,\n",
    "Optimizer: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bbaf9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    2018 - nips - Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels.\n",
    "    \"\"\"\n",
    "    q = 0.8\n",
    "    k = 0.001\n",
    "    t_loss = ((1 - torch.pow(torch.sum(y_true * y_pred, dim = 1), q)) / q) - ( (1-(k**q))/q )\n",
    "    return torch.mean(t_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bb7fe",
   "metadata": {},
   "source": [
    "import torch\n",
    "p = torch.tensor(\n",
    "                    [\n",
    "                        [0.2,0.5,0.3],\n",
    "                        [0.1,0.1,0.8]\n",
    "                    ]\n",
    ")\n",
    "t = torch.tensor(\n",
    "                    [\n",
    "                        [0, 0, 1],\n",
    "                        [1, 0, 0]\n",
    "                    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee93af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a73bc",
   "metadata": {},
   "source": [
    "## Model Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d77e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2e234f76ac4b70ac79470da6dfe257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> GCE.Loss: -0.002442486584186554\n",
      "1 -> GCE.Loss: -0.0013354122638702393\n",
      "2 -> GCE.Loss: -0.0019480735063552856\n",
      "3 -> GCE.Loss: -0.0019735917448997498\n",
      "4 -> GCE.Loss: -0.001247987151145935\n",
      "5 -> GCE.Loss: -0.0017781183123588562\n",
      "6 -> GCE.Loss: -0.001027137041091919\n",
      "7 -> GCE.Loss: -0.0015478506684303284\n",
      "8 -> GCE.Loss: -0.0018725097179412842\n",
      "9 -> GCE.Loss: -0.0022353678941726685\n",
      "10 -> GCE.Loss: -0.0023505762219429016\n",
      "11 -> GCE.Loss: -0.0018247738480567932\n",
      "12 -> GCE.Loss: -0.0020718425512313843\n",
      "13 -> GCE.Loss: -0.0030510053038597107\n",
      "14 -> GCE.Loss: -0.0030230507254600525\n",
      "15 -> GCE.Loss: -0.0035108253359794617\n",
      "16 -> GCE.Loss: -0.00341913104057312\n",
      "17 -> GCE.Loss: -0.003985218703746796\n",
      "18 -> GCE.Loss: -0.002863071858882904\n",
      "19 -> GCE.Loss: -0.0030927881598472595\n",
      "20 -> GCE.Loss: -0.004137992858886719\n",
      "21 -> GCE.Loss: -0.002262301743030548\n",
      "22 -> GCE.Loss: -0.004064664244651794\n",
      "23 -> GCE.Loss: -0.0026146993041038513\n",
      "24 -> GCE.Loss: -0.004046298563480377\n",
      "25 -> GCE.Loss: -0.0030619576573371887\n",
      "26 -> GCE.Loss: -0.004099071025848389\n",
      "27 -> GCE.Loss: -0.0042367056012153625\n",
      "28 -> GCE.Loss: -0.003772623836994171\n",
      "29 -> GCE.Loss: -0.004364877939224243\n",
      "30 -> GCE.Loss: -0.0035970360040664673\n",
      "31 -> GCE.Loss: -0.0038007646799087524\n",
      "32 -> GCE.Loss: -0.005003049969673157\n",
      "33 -> GCE.Loss: -0.004126593470573425\n",
      "34 -> GCE.Loss: -0.00533381849527359\n",
      "35 -> GCE.Loss: -0.005435727536678314\n",
      "36 -> GCE.Loss: -0.007946938276290894\n",
      "37 -> GCE.Loss: -0.004484742879867554\n",
      "38 -> GCE.Loss: -0.0039810910820961\n",
      "39 -> GCE.Loss: -0.0032252296805381775\n",
      "40 -> GCE.Loss: -0.005567446351051331\n",
      "41 -> GCE.Loss: -0.008482225239276886\n",
      "42 -> GCE.Loss: -0.004959456622600555\n",
      "43 -> GCE.Loss: -0.011630043387413025\n",
      "44 -> GCE.Loss: -0.007839873433113098\n",
      "45 -> GCE.Loss: -0.007143102586269379\n",
      "46 -> GCE.Loss: -0.007966652512550354\n",
      "47 -> GCE.Loss: -0.011594071984291077\n",
      "48 -> GCE.Loss: -0.006802089512348175\n",
      "49 -> GCE.Loss: -0.010223276913166046\n",
      "50 -> GCE.Loss: -0.009628668427467346\n",
      "51 -> GCE.Loss: -0.017683833837509155\n",
      "52 -> GCE.Loss: -0.02098369598388672\n",
      "53 -> GCE.Loss: -0.02144673466682434\n",
      "54 -> GCE.Loss: -0.034816429018974304\n",
      "55 -> GCE.Loss: -0.10181255638599396\n",
      "56 -> GCE.Loss: -0.3133210837841034\n",
      "57 -> GCE.Loss: -0.29153138399124146\n",
      "58 -> GCE.Loss: -0.2968032956123352\n",
      "59 -> GCE.Loss: -0.1420205533504486\n",
      "60 -> GCE.Loss: -0.15084324777126312\n",
      "61 -> GCE.Loss: -0.30149200558662415\n",
      "62 -> GCE.Loss: -0.2278532236814499\n",
      "63 -> GCE.Loss: -0.07349628955125809\n",
      "64 -> GCE.Loss: -0.3822871148586273\n",
      "65 -> GCE.Loss: -0.15073122084140778\n",
      "66 -> GCE.Loss: -0.2276224046945572\n",
      "67 -> GCE.Loss: -0.3016660511493683\n",
      "68 -> GCE.Loss: -0.2285989224910736\n",
      "69 -> GCE.Loss: -0.4529607594013214\n",
      "70 -> GCE.Loss: -0.38230517506599426\n",
      "71 -> GCE.Loss: -0.2275421917438507\n",
      "72 -> GCE.Loss: -0.4541205167770386\n",
      "73 -> GCE.Loss: -0.14955857396125793\n",
      "74 -> GCE.Loss: -0.3065178692340851\n",
      "75 -> GCE.Loss: -0.1511334478855133\n",
      "76 -> GCE.Loss: -0.3054824769496918\n",
      "77 -> GCE.Loss: -0.3054029941558838\n",
      "78 -> GCE.Loss: -0.3051162660121918\n",
      "79 -> GCE.Loss: -0.14978766441345215\n",
      "80 -> GCE.Loss: -0.15084025263786316\n",
      "81 -> GCE.Loss: -0.07295562326908112\n",
      "82 -> GCE.Loss: -0.372052937746048\n",
      "83 -> GCE.Loss: -0.22929583489894867\n",
      "84 -> GCE.Loss: -0.15058790147304535\n",
      "85 -> GCE.Loss: -0.384318470954895\n",
      "86 -> GCE.Loss: -0.5393792390823364\n",
      "87 -> GCE.Loss: -0.2281678318977356\n",
      "88 -> GCE.Loss: -0.4616955518722534\n",
      "89 -> GCE.Loss: -0.07316964864730835\n",
      "90 -> GCE.Loss: -0.4584159553050995\n",
      "91 -> GCE.Loss: -0.30195507407188416\n",
      "92 -> GCE.Loss: -0.3851601481437683\n",
      "93 -> GCE.Loss: -0.07321953028440475\n",
      "94 -> GCE.Loss: -0.30698060989379883\n",
      "95 -> GCE.Loss: -0.3045668601989746\n",
      "96 -> GCE.Loss: -0.6170052289962769\n",
      "97 -> GCE.Loss: -0.2290480136871338\n",
      "98 -> GCE.Loss: -0.3046720027923584\n",
      "99 -> GCE.Loss: -0.2283306121826172\n",
      "100 -> GCE.Loss: -0.15115386247634888\n",
      "101 -> GCE.Loss: -0.3840690851211548\n",
      "102 -> GCE.Loss: -0.3844555616378784\n",
      "103 -> GCE.Loss: -0.3066396117210388\n",
      "104 -> GCE.Loss: -0.07329412549734116\n",
      "105 -> GCE.Loss: -0.22719848155975342\n",
      "106 -> GCE.Loss: -0.22823262214660645\n",
      "107 -> GCE.Loss: -0.5404344797134399\n",
      "108 -> GCE.Loss: -0.15107080340385437\n",
      "109 -> GCE.Loss: -0.3072926700115204\n",
      "110 -> GCE.Loss: -0.07346618920564651\n",
      "111 -> GCE.Loss: -0.15119579434394836\n",
      "112 -> GCE.Loss: -0.150759756565094\n",
      "113 -> GCE.Loss: -0.15086184442043304\n",
      "114 -> GCE.Loss: -0.22860828042030334\n",
      "115 -> GCE.Loss: -0.3850783705711365\n",
      "116 -> GCE.Loss: -0.1498083472251892\n",
      "117 -> GCE.Loss: -0.38527554273605347\n",
      "118 -> GCE.Loss: -0.6149778366088867\n",
      "119 -> GCE.Loss: -0.3847922682762146\n",
      "120 -> GCE.Loss: -0.3838273882865906\n",
      "121 -> GCE.Loss: -0.4974604845046997\n",
      "122 -> GCE.Loss: -0.1512874960899353\n",
      "123 -> GCE.Loss: -0.15134195983409882\n",
      "124 -> GCE.Loss: -0.38496676087379456\n",
      "125 -> GCE.Loss: -0.38480985164642334\n",
      "126 -> GCE.Loss: -0.385300874710083\n",
      "127 -> GCE.Loss: -0.22907400131225586\n",
      "128 -> GCE.Loss: -0.15101604163646698\n",
      "129 -> GCE.Loss: -0.22897869348526\n",
      "130 -> GCE.Loss: -0.22919273376464844\n",
      "131 -> GCE.Loss: -0.22903451323509216\n",
      "132 -> GCE.Loss: -0.22892433404922485\n",
      "133 -> GCE.Loss: -0.4627548158168793\n",
      "134 -> GCE.Loss: -0.3846786320209503\n",
      "135 -> GCE.Loss: -0.3068857192993164\n",
      "136 -> GCE.Loss: -0.3071109652519226\n",
      "137 -> GCE.Loss: -0.30594438314437866\n",
      "138 -> GCE.Loss: -0.3071238100528717\n",
      "139 -> GCE.Loss: -0.15125538408756256\n",
      "140 -> GCE.Loss: -0.46310293674468994\n",
      "141 -> GCE.Loss: -0.22907939553260803\n",
      "142 -> GCE.Loss: -0.30695462226867676\n",
      "143 -> GCE.Loss: -0.22905297577381134\n",
      "144 -> GCE.Loss: -0.4625871479511261\n",
      "145 -> GCE.Loss: -0.1511417031288147\n",
      "146 -> GCE.Loss: -0.38521522283554077\n",
      "147 -> GCE.Loss: -0.30732041597366333\n",
      "148 -> GCE.Loss: -0.2292322814464569\n",
      "149 -> GCE.Loss: -0.2292308509349823\n",
      "150 -> GCE.Loss: -0.2292170524597168\n",
      "\n",
      "Total Questions 300\n",
      "\n",
      "Correctly classified 49\n",
      "\n",
      "Validation Accuracy: 19.333333333333332, Test Accuracy: 16.333333333333332 \n",
      "\n",
      "151 -> GCE.Loss: -0.1512124389410019\n",
      "152 -> GCE.Loss: -0.2290477305650711\n",
      "153 -> GCE.Loss: -0.22923406958580017\n",
      "154 -> GCE.Loss: -0.15118718147277832\n",
      "155 -> GCE.Loss: -0.3069273829460144\n",
      "156 -> GCE.Loss: -0.2292632907629013\n",
      "157 -> GCE.Loss: -0.07316995412111282\n",
      "158 -> GCE.Loss: -0.07297929376363754\n",
      "159 -> GCE.Loss: -0.540794849395752\n",
      "160 -> GCE.Loss: -0.3853057622909546\n",
      "161 -> GCE.Loss: -0.5412940979003906\n",
      "162 -> GCE.Loss: -0.22920358180999756\n",
      "163 -> GCE.Loss: -0.30695778131484985\n",
      "164 -> GCE.Loss: -0.15114569664001465\n",
      "165 -> GCE.Loss: -0.30706238746643066\n",
      "166 -> GCE.Loss: -0.30728858709335327\n",
      "167 -> GCE.Loss: -0.15114668011665344\n",
      "168 -> GCE.Loss: -0.1513058990240097\n",
      "169 -> GCE.Loss: -0.22910557687282562\n",
      "170 -> GCE.Loss: -0.30722495913505554\n",
      "171 -> GCE.Loss: -0.2961026728153229\n",
      "172 -> GCE.Loss: -0.07320079952478409\n",
      "173 -> GCE.Loss: -0.3072139620780945\n",
      "174 -> GCE.Loss: -0.46335434913635254\n",
      "175 -> GCE.Loss: -0.30712786316871643\n",
      "176 -> GCE.Loss: -0.30731773376464844\n",
      "177 -> GCE.Loss: -0.30726391077041626\n",
      "178 -> GCE.Loss: -0.07317963242530823\n",
      "179 -> GCE.Loss: -0.15096117556095123\n",
      "180 -> GCE.Loss: -0.30708664655685425\n",
      "181 -> GCE.Loss: -0.38527700304985046\n",
      "182 -> GCE.Loss: -0.2292267084121704\n",
      "183 -> GCE.Loss: -0.3853527307510376\n",
      "184 -> GCE.Loss: -0.15099099278450012\n",
      "185 -> GCE.Loss: -0.15118196606636047\n",
      "186 -> GCE.Loss: -0.22930505871772766\n",
      "187 -> GCE.Loss: -0.3852323293685913\n",
      "188 -> GCE.Loss: -0.3073318302631378\n",
      "189 -> GCE.Loss: -0.4632924795150757\n",
      "190 -> GCE.Loss: -0.307277113199234\n",
      "191 -> GCE.Loss: -0.30724912881851196\n",
      "192 -> GCE.Loss: -0.3853437304496765\n",
      "193 -> GCE.Loss: -0.2293243110179901\n",
      "194 -> GCE.Loss: -0.46293550729751587\n",
      "195 -> GCE.Loss: -0.15121206641197205\n",
      "196 -> GCE.Loss: -0.1509259045124054\n",
      "197 -> GCE.Loss: -0.4633881747722626\n",
      "198 -> GCE.Loss: -0.3073701858520508\n",
      "199 -> GCE.Loss: -0.3072493374347687\n",
      "200 -> GCE.Loss: -0.15108558535575867\n",
      "201 -> GCE.Loss: -0.30719470977783203\n",
      "202 -> GCE.Loss: -0.22929039597511292\n",
      "203 -> GCE.Loss: -0.30732545256614685\n",
      "204 -> GCE.Loss: -0.15104973316192627\n",
      "205 -> GCE.Loss: -0.1512460559606552\n",
      "206 -> GCE.Loss: -0.38536369800567627\n",
      "207 -> GCE.Loss: -0.3853738009929657\n",
      "208 -> GCE.Loss: -0.0731826052069664\n",
      "209 -> GCE.Loss: -0.22934862971305847\n",
      "210 -> GCE.Loss: -0.46302756667137146\n",
      "211 -> GCE.Loss: -0.22923366725444794\n",
      "212 -> GCE.Loss: -0.3853779435157776\n",
      "213 -> GCE.Loss: -0.22917747497558594\n",
      "214 -> GCE.Loss: -0.22919905185699463\n",
      "215 -> GCE.Loss: -0.15126755833625793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 -> GCE.Loss: -0.4634559154510498\n",
      "217 -> GCE.Loss: -0.15124577283859253\n",
      "218 -> GCE.Loss: -0.22920545935630798\n",
      "219 -> GCE.Loss: -0.4631769061088562\n",
      "220 -> GCE.Loss: -0.30731815099716187\n",
      "221 -> GCE.Loss: -0.22927403450012207\n",
      "222 -> GCE.Loss: -0.30729007720947266\n",
      "223 -> GCE.Loss: -0.2292766571044922\n",
      "224 -> GCE.Loss: -0.38543301820755005\n",
      "225 -> GCE.Loss: -0.30707505345344543\n",
      "226 -> GCE.Loss: -0.3852681815624237\n",
      "227 -> GCE.Loss: -0.5412495732307434\n",
      "228 -> GCE.Loss: -0.3852483630180359\n",
      "229 -> GCE.Loss: -0.15109099447727203\n",
      "230 -> GCE.Loss: -0.5413094162940979\n",
      "231 -> GCE.Loss: -0.15106305480003357\n",
      "232 -> GCE.Loss: -0.3853345811367035\n",
      "233 -> GCE.Loss: -0.5413899421691895\n",
      "234 -> GCE.Loss: -0.2292691171169281\n",
      "235 -> GCE.Loss: -0.5409880876541138\n",
      "236 -> GCE.Loss: -0.2292684018611908\n",
      "237 -> GCE.Loss: -0.22877439856529236\n",
      "238 -> GCE.Loss: -0.5414581298828125\n",
      "239 -> GCE.Loss: -0.1512691080570221\n",
      "240 -> GCE.Loss: -0.07314638793468475\n",
      "241 -> GCE.Loss: -0.30719006061553955\n",
      "242 -> GCE.Loss: -0.22927121818065643\n",
      "243 -> GCE.Loss: -0.385358601808548\n",
      "244 -> GCE.Loss: -0.5413954257965088\n",
      "245 -> GCE.Loss: -0.22931520640850067\n",
      "246 -> GCE.Loss: -0.5413489937782288\n",
      "247 -> GCE.Loss: -0.38541433215141296\n",
      "248 -> GCE.Loss: -0.22935448586940765\n",
      "249 -> GCE.Loss: -0.30733808875083923\n",
      "250 -> GCE.Loss: -0.5415698289871216\n",
      "251 -> GCE.Loss: -0.3854258060455322\n",
      "252 -> GCE.Loss: -0.3073677718639374\n",
      "253 -> GCE.Loss: -0.30734556913375854\n",
      "254 -> GCE.Loss: -0.15126970410346985\n",
      "255 -> GCE.Loss: -0.30733317136764526\n",
      "256 -> GCE.Loss: -0.15130624175071716\n",
      "257 -> GCE.Loss: -0.2292671501636505\n",
      "258 -> GCE.Loss: -0.22923904657363892\n",
      "259 -> GCE.Loss: -0.38538333773612976\n",
      "260 -> GCE.Loss: -0.46336114406585693\n",
      "261 -> GCE.Loss: -0.3853881359100342\n",
      "262 -> GCE.Loss: -0.38546323776245117\n",
      "263 -> GCE.Loss: -0.38519811630249023\n",
      "264 -> GCE.Loss: -0.3854801654815674\n",
      "265 -> GCE.Loss: -0.3072490394115448\n",
      "266 -> GCE.Loss: -0.2292458713054657\n",
      "267 -> GCE.Loss: -0.3068688213825226\n",
      "268 -> GCE.Loss: -0.38550877571105957\n",
      "269 -> GCE.Loss: -0.4634931981563568\n",
      "270 -> GCE.Loss: -0.22933337092399597\n",
      "271 -> GCE.Loss: -0.4632599353790283\n",
      "272 -> GCE.Loss: -0.151262566447258\n",
      "273 -> GCE.Loss: -0.22932368516921997\n",
      "274 -> GCE.Loss: -0.38519155979156494\n",
      "275 -> GCE.Loss: -0.07313716411590576\n",
      "276 -> GCE.Loss: -0.07321822643280029\n",
      "277 -> GCE.Loss: -0.1511966586112976\n",
      "278 -> GCE.Loss: -0.38533684611320496\n",
      "279 -> GCE.Loss: -0.54152512550354\n",
      "280 -> GCE.Loss: -0.3854221999645233\n",
      "281 -> GCE.Loss: -0.3852631151676178\n",
      "282 -> GCE.Loss: -0.22919237613677979\n",
      "283 -> GCE.Loss: -0.22910314798355103\n",
      "284 -> GCE.Loss: -0.07290954887866974\n",
      "285 -> GCE.Loss: -0.3073993921279907\n",
      "286 -> GCE.Loss: -0.15122205018997192\n",
      "287 -> GCE.Loss: -0.3073684275150299\n",
      "288 -> GCE.Loss: -0.5410911440849304\n",
      "289 -> GCE.Loss: -0.307363897562027\n",
      "290 -> GCE.Loss: -0.4635046422481537\n",
      "291 -> GCE.Loss: -0.3854765295982361\n",
      "292 -> GCE.Loss: -0.3072974979877472\n",
      "293 -> GCE.Loss: -0.1512557864189148\n",
      "294 -> GCE.Loss: -0.22931206226348877\n",
      "295 -> GCE.Loss: -0.3853747248649597\n",
      "296 -> GCE.Loss: -0.30737870931625366\n",
      "297 -> GCE.Loss: -0.38546451926231384\n",
      "298 -> GCE.Loss: -0.3854968547821045\n",
      "299 -> GCE.Loss: -0.22931569814682007\n",
      "300 -> GCE.Loss: -0.3073175549507141\n",
      "\n",
      "Total Questions 300\n",
      "\n",
      "Correctly classified 49\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(7)):  \n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        y_true = batch['labels']\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        \n",
    "        y_pred = torch.softmax(outputs.logits, dim = 1)\n",
    "        \n",
    "        #print(y_true)\n",
    "        #print(y_pred)\n",
    "     \n",
    "        loss = generalized_cross_entropy(y_true, y_pred)\n",
    "        #print(loss)        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(batch_idx,\"-> GCE.Loss:\", loss.item())\n",
    "        \n",
    "        if (batch_idx != 0 ) and (batch_idx % 150 == 0):\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            acc_score_test = calculateAccuracyTest()\n",
    "            acc_score_val, validationLoss = calculateAccuracyVal()\n",
    "            \n",
    "            print(f'\\nValidation Accuracy: {acc_score_val}, Test Accuracy: {acc_score_test} \\n')\n",
    "            \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4c899",
   "metadata": {},
   "source": [
    "## Reports & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84a1efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the Validation Loss and accuracy on the Validation Set\n",
    "\n",
    "def calculateAccuracyVal():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    \n",
    "    for index in range(100,400):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        \n",
    "        val_example = val_dataset_object[index]\n",
    "        val_example = {k: v.unsqueeze(0).to(device) for k,v in val_example.items()}\n",
    "        val_outputs = model(**val_example)\n",
    "        \n",
    "        validationLoss = val_outputs.loss\n",
    "\n",
    "        val_logits = val_outputs.logits\n",
    "        val_predicted_classes = torch.sigmoid(val_logits)\n",
    "        val_ans = reverse_mapping[torch.argmax(val_predicted_classes).item()]\n",
    "        \n",
    "        \n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_val[index] == val_ans:\n",
    "            matchScore += 1\n",
    "                \n",
    "    #print(matchScore, loopCounter)\n",
    "    accuracyVal = (matchScore/loopCounter)*100\n",
    "    return ( accuracyVal,validationLoss.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9e34a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns accuracy on the Test Set\n",
    "\n",
    "def calculateAccuracyTest():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    for index in range(100, 400):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        \n",
    "        test_example = test_dataset_object[index]\n",
    "        test_example = {k: v.unsqueeze(0).to(device) for k,v in test_example.items()}\n",
    "        test_outputs = model(**test_example)\n",
    "\n",
    "        test_logits = test_outputs.logits\n",
    "        test_predicted_classes = torch.sigmoid(test_logits)\n",
    "        test_ans = reverse_mapping[torch.argmax(test_predicted_classes).item()]\n",
    "        \n",
    "        # print(f'T: {answerList_val[index]} <-> P: {test_ans}' )\n",
    "\n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == test_ans:\n",
    "            matchScore += 1\n",
    "                \n",
    "    \n",
    "    print(f'\\nTotal Questions {loopCounter}')\n",
    "    print(f'\\nCorrectly classified {matchScore}')\n",
    "    \n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateAccuracyTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns report on the Test Set\n",
    "\n",
    "misclassifiedIndex = []\n",
    "def generateReport():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    for index in range(16080,17000):\n",
    "        \n",
    "        loopCounter += 1\n",
    "        print(f'\\n{questionList_test[index]} ? Ans: {answerList_test[index]}\\n')\n",
    "        \n",
    "        example = test_dataset_object[index]\n",
    "        example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "        outputs = model(**example)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predicted_classes = torch.sigmoid(logits)\n",
    "        ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "        \n",
    "        print('Predicted Ans:', ans,'\\n')\n",
    "        \n",
    "        probs, classes = torch.topk(predicted_classes, 4)\n",
    "\n",
    "        for prob, class_idx in zip(probs.squeeze().tolist(), classes.squeeze().tolist()):\n",
    "            print(prob, model.config.id2label[class_idx])\n",
    "    \n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == ans:\n",
    "            matchScore += 1\n",
    "            print('Correct Prediction at index:', index)\n",
    "        \n",
    "        else:\n",
    "            misclassifiedIndex.append(index)\n",
    "            print('Wrong Prediction at index:', index)\n",
    "    \n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifiedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99346041",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.open(imgPathList_test[16087])\n",
    "i.thumbnail((500,500))\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b809f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647dc7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5e32930",
   "metadata": {},
   "source": [
    "### Finding Color Questions Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the list of colors from the previously stored text files\n",
    "\n",
    "colors = []\n",
    "with open('./text_files/colors.txt', 'r') as file:\n",
    "    for color in file:\n",
    "        color = color.strip()\n",
    "        colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483039ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding leading and trailing space in the colors\n",
    "\n",
    "colors_spaces = [' '+ color + ' ' for color in colors] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_spaces[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isContainColor(targetString):\n",
    "    \n",
    "    for color in colors_spaces:\n",
    "        if color in targetString:\n",
    "            return True\n",
    "    \n",
    "    return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca45424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da567432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function identifies the color question for which the result is misclassified\n",
    "\n",
    "misclassifiedIndex = []\n",
    "matchScore = 0\n",
    "\n",
    "def findAccuracyColorQuestions():\n",
    "    \n",
    "    global matchScore\n",
    "    questionCount = 0\n",
    "    model.eval()\n",
    "    \n",
    "    print('***** Question About Colors ************')\n",
    "    \n",
    "    for index in tqdm(range(0,71860)):\n",
    "        \n",
    "        currQuestion = questionList_test[index]        \n",
    "        \n",
    "        if ('color' in currQuestion) or (isContainColor(currQuestion)):\n",
    "            \n",
    "            questionCount += 1\n",
    "            \n",
    "            #print(f'\\n{questionList_test[index]} ? Ans: {answerList_test[index]}\\n')\n",
    "            \n",
    "            example = test_dataset_object[index]\n",
    "            example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "            outputs = model(**example)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predicted_classes = torch.sigmoid(logits)\n",
    "            ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "\n",
    "            # accuracy score\n",
    "\n",
    "            if answerList_test[index] == ans:\n",
    "                matchScore += 1\n",
    "\n",
    "            else:    \n",
    "                misclassifiedIndex.append(index)\n",
    "                                \n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    \n",
    "    print(f'\\nTotal {questionCount} questions found')\n",
    "    print(f'\\nCorrectly Classified {matchScore}')\n",
    "    print(f'\\nMistakenly Classified {len(misclassifiedIndex)}')\n",
    "\n",
    "    return ((matchScore/questionCount)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d716fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "findAccuracyColorQuestions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(misclassifiedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73691b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rightClassified = matchScore\n",
    "missClassified = len(misclassifiedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81990892",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Rightly Classified', 'MisClassified']\n",
    "values = [rightClassified, missClassified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.xlabel(f\"Model Misclassified Total {len(misclassifiedIndex)} Color based Questions\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(f\"{rightClassified + missClassified} Color Based Question-Answers present in the dataset\")\n",
    "\n",
    "plt.bar(labels, values, color='lightgreen', edgecolor='black', width=0.2)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626d7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115a30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9c550e8",
   "metadata": {},
   "source": [
    "## Find Yes/No Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function identifies the yes/no type questions for which the result is misclassified\n",
    "\n",
    "misclassifiedIndex = []\n",
    "\n",
    "def findYesNoQuestions():\n",
    "    \n",
    "    matchScore, questionCount = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    print('********* Yes/No Questions ************')\n",
    "    \n",
    "    for index in tqdm(range(0,71860)):\n",
    "        \n",
    "        currAnswer = answerList_test[index]        \n",
    "        \n",
    "        if ('yes' in currAnswer) or ('no' in currAnswer):\n",
    "            \n",
    "            questionCount += 1\n",
    "            \n",
    "            #print(f'\\n{questionList_test[index]} ? Ans: {answerList_test[index]}\\n')\n",
    "            \n",
    "            example = test_dataset_object[index]\n",
    "            example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "            outputs = model(**example)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predicted_classes = torch.sigmoid(logits)\n",
    "            ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "\n",
    "            # check if answer is correct or not\n",
    "\n",
    "            if answerList_test[index] == ans:\n",
    "                matchScore += 1\n",
    "            else:\n",
    "                misclassifiedIndex.append(index)\n",
    "                     \n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    \n",
    "    print(f'\\nTotal {questionCount} questions found')\n",
    "    print(f'\\nCorrectly Classified {matchScore}')\n",
    "    print(f'\\nMistakenly Classified {len(misclassifiedIndex)}')\n",
    "\n",
    "    return ((matchScore/questionCount)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "findYesNoQuestions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02cacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rightClassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missClassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Rightly Classified', 'MisClassified']\n",
    "values = [rightClassified, missClassified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.xlabel(f\"Model Misclassified Total {missClassified} Yes/No Questions\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(f\"25171 Yes/No Question-Answers present in the dataset\")\n",
    "\n",
    "plt.bar(labels, values, color='lightgreen', edgecolor='black', width=0.2)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76abbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d128d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37cf0a09",
   "metadata": {},
   "source": [
    "### FInd Common sense Reasoning Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function roughly identifies the common-sense based questions for which the result is misclassified\n",
    "\n",
    "misclassifiedIndex = []\n",
    "\n",
    "def findCSRQuestions():\n",
    "    \n",
    "    matchScore, questionCount = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    print('********* Commonsense Reasoning Questions ************')\n",
    "    \n",
    "    for index in tqdm(range(0,100)):\n",
    "        \n",
    "        currAnswer = answerList_test[index]  \n",
    "        currQuestion = questionList_test[index]\n",
    "        \n",
    "        if ('yes' in currAnswer) or ('no' in currAnswer) or ('color' in currQuestion) or (isContainColor(currQuestion)):\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "\n",
    "            questionCount += 1\n",
    "            \n",
    "            example = test_dataset_object[index]\n",
    "            example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "            outputs = model(**example)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predicted_classes = torch.sigmoid(logits)\n",
    "            ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "    \n",
    "            # check if answer is correct or not\n",
    "\n",
    "            if answerList_test[index] == ans:\n",
    "                matchScore += 1\n",
    "\n",
    "            else:\n",
    "                missClassified += 1\n",
    "                misclassifiedIndex.append(index)\n",
    "                \n",
    "                \n",
    "    print(f'\\nTotal {questionCount} questions found')\n",
    "    print(f'\\nCorrectly Classified {matchScore}')\n",
    "    print(f'\\nMistakenly Classified {len(misclassifiedIndex)}')\n",
    "\n",
    "    return ((matchScore/questionCount)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "findCSRQuestions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda09cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missClassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rightClassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Rightly Classified', 'MisClassified']\n",
    "values = [rightClassified, missClassified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.xlabel(f\"Model Misclassified Total {missClassified} commonsense-based Questions\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(f\"27277 Common-sense-based Questions present in the dataset\")\n",
    "\n",
    "plt.bar(labels, values, color='lightgreen', edgecolor='black', width=0.2)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ddb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcab574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function collects the indices of the color questions from the test set\n",
    "\n",
    "colorQuestionIndices = []\n",
    "\n",
    "def storeColorQuestionIndex():\n",
    "    \n",
    "    questionCount = 0 \n",
    "    print('********* Storing Color Questions Indices ************')\n",
    "    \n",
    "    for index in tqdm(range(0,500)):\n",
    "        \n",
    "        currAnswer = answerList_test[index]  \n",
    "        currQuestion = questionList_test[index]\n",
    "                \n",
    "        if ('color' in currQuestion) or (isContainColor(currQuestion)):\n",
    "            #print(index,currQuestion)\n",
    "\n",
    "            questionCount += 1\n",
    "            colorQuestionIndices.append(index)\n",
    "        \n",
    "                \n",
    "    print(f'\\nTotal {questionCount} color questions found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b51862",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeColorQuestionIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2713324",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(colorQuestionIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d17702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(wordList):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in wordList if word.lower() not in stop_words]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36782762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function gathers all the words from the color questions and their frequency from all the color questions to make histogram\n",
    "\n",
    "frquencyMap = {}\n",
    "\n",
    "def collectWords():\n",
    "    \n",
    "    for index in tqdm(misclassifiedIndex):\n",
    "        \n",
    "        currQuestion = questionList_test[index]\n",
    "        words = remove_stopwords(currQuestion.split())\n",
    "        \n",
    "        for word in words:\n",
    "            \n",
    "            if word in frquencyMap:\n",
    "                \n",
    "                frquencyMap[word] = frquencyMap[word] + 1\n",
    "            \n",
    "            else:\n",
    "            \n",
    "                frquencyMap[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frquencyMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list of tuples\n",
    "\n",
    "frquencyList = [(key,val) for key,val in frquencyMap.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frquencyList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frquencyList.sort(key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "frquencyList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c500a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-30 words\n",
    "\n",
    "frquencyList = frquencyList[0:30]\n",
    "labels = [ val[0] for val in frquencyList]\n",
    "frequncies = [ val[1] for val in frquencyList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=frequncies, y=labels, palette=\"viridis\")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set(xlabel=\"Frequency\", ylabel=\"Words\", title=\"Word Frequency\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3018dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if ('object' or 'used' or 'usually' or 'type') in currQuestion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ee34f",
   "metadata": {},
   "source": [
    "## Experimenting With Accuracy By Removing Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questionList_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsAffected = 0\n",
    "\n",
    "for index in tqdm(range(0,71860)):\n",
    "\n",
    "    currQuestion = questionList_test[index]\n",
    "    \n",
    "    if ('object' in currQuestion) or ('used' in currQuestion):\n",
    "\n",
    "        currQuestion = ' '.join([word for word in currQuestion.split() if word not in ('object','used','usually','type')])\n",
    "        rowsAffected += 1\n",
    "        \n",
    "        questionList_test[index] = currQuestion\n",
    "    \n",
    "print(f'\\nTotal {rowsAffected} questions affected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea97f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDictionary = {'questions':questionList_test, 'labels':labels_test, 'scores':scores_test, 'images':imgPathList_test}\n",
    "word_removed_test_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_removed_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_removed_test_set = word_removed_test_set.cast_column(\"images\", datasets.Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b73dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1038\n",
    "word_removed_test_set[index]['questions'], modified_test_set[index]['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4af13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_removed_test_set_object = cric_dataset(word_removed_test_set, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns report on the Test Set\n",
    "\n",
    "misclassifiedIndex = []\n",
    "def removeWordsAndGenReport():\n",
    "    \n",
    "    matchScore, loopCounter = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    for index in tqdm(range(0,71860)):\n",
    "        \n",
    "        loopCounter += 1                            \n",
    "\n",
    "        example = word_removed_test_set_object[index]\n",
    "        example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n",
    "        outputs = model(**example)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predicted_classes = torch.sigmoid(logits)\n",
    "        ans = reverse_mapping[torch.argmax(predicted_classes).item()]\n",
    "        \n",
    "        # print('Predicted Ans:', ans,'\\n')\n",
    "        \n",
    "        probs, classes = torch.topk(predicted_classes, 4)\n",
    "\n",
    "        for prob, class_idx in zip(probs.squeeze().tolist(), classes.squeeze().tolist()):\n",
    "            print(end='')\n",
    "    \n",
    "        # accuracy score\n",
    "        \n",
    "        if answerList_test[index] == ans:\n",
    "            matchScore += 1\n",
    "        \n",
    "        else:\n",
    "            misclassifiedIndex.append(index)\n",
    "    \n",
    "    print(f'\\nTotal {loopCounter} questions found')\n",
    "    print(f'\\nCorrectly Classified {matchScore}')\n",
    "    print(f'\\nMistakenly Classified {len(misclassifiedIndex)}')\n",
    "\n",
    "    return ((matchScore/loopCounter)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeWordsAndGenReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bcdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
